This highlights a **logical vulnerability**. At first glance, the patch might appear to be a mere programming rollback or a minor correction. However, thanks to our extensive collection of **ground truth** data, the LLM in **Stage 1 (security-agnostic classification)** successfully identified it as **security-relevant**.

Furthermore, the **Agent** effectively reproduced the vulnerability scenario by seeking information from both the **caller** and **callee** functions, and subsequently constructing an **attack vector**.

Interestingly, we observed that CVE descriptions often abstract to the highest-level method, **overlooking the actual locus of the vulnerability**. This makes it difficult for human experts to reproduce the issue (in this particular case, tracing from `Criteria.parse()` required following 13 layers!). Similarly, this abstraction also causes significant **hallucinations** in models. While human experts can leverage runtime environments and Proof-of-Concepts (POCs) for breakpoint debugging, the Agent is limited to **static semantic understanding**. We have also documented instances where the Agent exhibited hallucination under these circumstances.
