{
    "cve_id": "CVE-2014-8369",
    "cwe_ids": [
        "CWE-119"
    ],
    "cvss_vector": "AV:L/AC:L/Au:N/C:P/I:P/A:P",
    "cvss_is_v3": false,
    "repo_name": "torvalds/linux",
    "commit_msg": "kvm: fix excessive pages un-pinning in kvm_iommu_map error path.\n\nThe third parameter of kvm_unpin_pages() when called from\nkvm_iommu_map_pages() is wrong, it should be the number of pages to un-pin\nand not the page size.\n\nThis error was facilitated with an inconsistent API: kvm_pin_pages() takes\na size, but kvn_unpin_pages() takes a number of pages, so fix the problem\nby matching the two.\n\nThis was introduced by commit 350b8bd (\"kvm: iommu: fix the third parameter\nof kvm_iommu_put_pages (CVE-2014-3601)\"), which fixes the lack of\nun-pinning for pages intended to be un-pinned (i.e. memory leak) but\nunfortunately potentially aggravated the number of pages we un-pin that\nshould have stayed pinned. As far as I understand though, the same\npractical mitigations apply.\n\nThis issue was found during review of Red Hat 6.6 patches to prepare\nKsplice rebootless updates.\n\nThanks to Vegard for his time on a late Friday evening to help me in\nunderstanding this code.\n\nFixes: 350b8bd (\"kvm: iommu: fix the third parameter of... (CVE-2014-3601)\")\nCc: stable@vger.kernel.org\nSigned-off-by: Quentin Casasnovas <quentin.casasnovas@oracle.com>\nSigned-off-by: Vegard Nossum <vegard.nossum@oracle.com>\nSigned-off-by: Jamie Iles <jamie.iles@oracle.com>\nReviewed-by: Sasha Levin <sasha.levin@oracle.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
    "commit_hash": "3d32e4dbe71374a6780eaf51d719d76f9a9bf22f",
    "git_url": "https://github.com/torvalds/linux/commit/3d32e4dbe71374a6780eaf51d719d76f9a9bf22f",
    "file_path": "virt/kvm/iommu.c",
    "func_name": "kvm_iommu_map_pages",
    "func_before": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tgfn_t gfn, end_gfn;\n\tpfn_t pfn;\n\tint r = 0;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint flags;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tgfn     = slot->base_gfn;\n\tend_gfn = gfn + slot->npages;\n\n\tflags = IOMMU_READ;\n\tif (!(slot->flags & KVM_MEM_READONLY))\n\t\tflags |= IOMMU_WRITE;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tflags |= IOMMU_CACHE;\n\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long page_size;\n\n\t\t/* Check if already mapped */\n\t\tif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the page size we could use to map */\n\t\tpage_size = kvm_host_page_size(kvm, gfn);\n\n\t\t/* Make sure the page_size does not exceed the memslot */\n\t\twhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure gfn is aligned to the page size we want to map */\n\t\twhile ((gfn << PAGE_SHIFT) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure hva is aligned to the page size we want to map */\n\t\twhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/*\n\t\t * Pin all pages we are about to map in memory. This is\n\t\t * important because we unmap and unpin in 4kb steps later.\n\t\t */\n\t\tpfn = kvm_pin_pages(slot, gfn, page_size);\n\t\tif (is_error_noslot_pfn(pfn)) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Map into IO address space */\n\t\tr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\n\t\t\t      page_size, flags);\n\t\tif (r) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n\t\t\tkvm_unpin_pages(kvm, pfn, page_size);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tgfn += page_size >> PAGE_SHIFT;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\n\treturn r;\n}",
    "abstract_func_before": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *VAR_0)\n{\n\tgfn_t VAR_1, VAR_2;\n\tpfn_t VAR_3;\n\tint VAR_4 = 0;\n\tstruct iommu_domain *VAR_5 = kvm->arch.iommu_domain;\n\tint VAR_6;\n\n\t/* COMMENT_0 */\n\tif (!VAR_5)\n\t\treturn 0;\n\n\tVAR_1     = VAR_0->base_gfn;\n\tVAR_2 = VAR_1 + VAR_0->npages;\n\n\tVAR_6 = VAR_7;\n\tif (!(VAR_0->flags & VAR_8))\n\t\tVAR_6 |= VAR_9;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tVAR_6 |= VAR_10;\n\n\n\twhile (VAR_1 < VAR_2) {\n\t\tunsigned long VAR_11;\n\n\t\t/* COMMENT_1 */\n\t\tif (iommu_iova_to_phys(VAR_5, gfn_to_gpa(VAR_1))) {\n\t\t\tVAR_1 += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* COMMENT_2 */\n\t\tVAR_11 = kvm_host_page_size(kvm, VAR_1);\n\n\t\t/* COMMENT_3 */\n\t\twhile ((VAR_1 + (VAR_11 >> VAR_12)) > VAR_2)\n\t\t\tVAR_11 >>= 1;\n\n\t\t/* COMMENT_4 */\n\t\twhile ((VAR_1 << VAR_12) & (VAR_11 - 1))\n\t\t\tVAR_11 >>= 1;\n\n\t\t/* COMMENT_5 */\n\t\twhile (__gfn_to_hva_memslot(VAR_0, VAR_1) & (VAR_11 - 1))\n\t\t\tVAR_11 >>= 1;\n\n\t\t/* COMMENT_6 */\n                                                         \n                                                             \n     \n\t\tVAR_3 = kvm_pin_pages(VAR_0, VAR_1, VAR_11);\n\t\tif (is_error_noslot_pfn(VAR_3)) {\n\t\t\tVAR_1 += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* COMMENT_10 */\n\t\tVAR_4 = iommu_map(VAR_5, gfn_to_gpa(VAR_1), pfn_to_hpa(VAR_3),\n\t\t\t      VAR_11, VAR_6);\n\t\tif (VAR_4) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", VAR_3);\n\t\t\tkvm_unpin_pages(kvm, VAR_3, VAR_11);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tVAR_1 += VAR_11 >> VAR_12;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, VAR_0->base_gfn, VAR_1 - VAR_0->base_gfn);\n\treturn VAR_4;\n}",
    "func_graph_path_before": "torvalds/linux/3d32e4dbe71374a6780eaf51d719d76f9a9bf22f/iommu.c/vul/before/0.json",
    "func": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tgfn_t gfn, end_gfn;\n\tpfn_t pfn;\n\tint r = 0;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint flags;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tgfn     = slot->base_gfn;\n\tend_gfn = gfn + slot->npages;\n\n\tflags = IOMMU_READ;\n\tif (!(slot->flags & KVM_MEM_READONLY))\n\t\tflags |= IOMMU_WRITE;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tflags |= IOMMU_CACHE;\n\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long page_size;\n\n\t\t/* Check if already mapped */\n\t\tif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the page size we could use to map */\n\t\tpage_size = kvm_host_page_size(kvm, gfn);\n\n\t\t/* Make sure the page_size does not exceed the memslot */\n\t\twhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure gfn is aligned to the page size we want to map */\n\t\twhile ((gfn << PAGE_SHIFT) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure hva is aligned to the page size we want to map */\n\t\twhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/*\n\t\t * Pin all pages we are about to map in memory. This is\n\t\t * important because we unmap and unpin in 4kb steps later.\n\t\t */\n\t\tpfn = kvm_pin_pages(slot, gfn, page_size >> PAGE_SHIFT);\n\t\tif (is_error_noslot_pfn(pfn)) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Map into IO address space */\n\t\tr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\n\t\t\t      page_size, flags);\n\t\tif (r) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n\t\t\tkvm_unpin_pages(kvm, pfn, page_size >> PAGE_SHIFT);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tgfn += page_size >> PAGE_SHIFT;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\n\treturn r;\n}",
    "abstract_func": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *VAR_0)\n{\n\tgfn_t VAR_1, VAR_2;\n\tpfn_t VAR_3;\n\tint VAR_4 = 0;\n\tstruct iommu_domain *VAR_5 = kvm->arch.iommu_domain;\n\tint VAR_6;\n\n\t/* COMMENT_0 */\n\tif (!VAR_5)\n\t\treturn 0;\n\n\tVAR_1     = VAR_0->base_gfn;\n\tVAR_2 = VAR_1 + VAR_0->npages;\n\n\tVAR_6 = VAR_7;\n\tif (!(VAR_0->flags & VAR_8))\n\t\tVAR_6 |= VAR_9;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tVAR_6 |= VAR_10;\n\n\n\twhile (VAR_1 < VAR_2) {\n\t\tunsigned long VAR_11;\n\n\t\t/* COMMENT_1 */\n\t\tif (iommu_iova_to_phys(VAR_5, gfn_to_gpa(VAR_1))) {\n\t\t\tVAR_1 += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* COMMENT_2 */\n\t\tVAR_11 = kvm_host_page_size(kvm, VAR_1);\n\n\t\t/* COMMENT_3 */\n\t\twhile ((VAR_1 + (VAR_11 >> VAR_12)) > VAR_2)\n\t\t\tVAR_11 >>= 1;\n\n\t\t/* COMMENT_4 */\n\t\twhile ((VAR_1 << VAR_12) & (VAR_11 - 1))\n\t\t\tVAR_11 >>= 1;\n\n\t\t/* COMMENT_5 */\n\t\twhile (__gfn_to_hva_memslot(VAR_0, VAR_1) & (VAR_11 - 1))\n\t\t\tVAR_11 >>= 1;\n\n\t\t/* COMMENT_6 */\n                                                         \n                                                             \n     \n\t\tVAR_3 = kvm_pin_pages(VAR_0, VAR_1, VAR_11 >> VAR_12);\n\t\tif (is_error_noslot_pfn(VAR_3)) {\n\t\t\tVAR_1 += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* COMMENT_10 */\n\t\tVAR_4 = iommu_map(VAR_5, gfn_to_gpa(VAR_1), pfn_to_hpa(VAR_3),\n\t\t\t      VAR_11, VAR_6);\n\t\tif (VAR_4) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", VAR_3);\n\t\t\tkvm_unpin_pages(kvm, VAR_3, VAR_11 >> VAR_12);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tVAR_1 += VAR_11 >> VAR_12;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, VAR_0->base_gfn, VAR_1 - VAR_0->base_gfn);\n\treturn VAR_4;\n}",
    "func_graph_path": "torvalds/linux/3d32e4dbe71374a6780eaf51d719d76f9a9bf22f/iommu.c/vul/after/0.json",
    "diff_func": "--- func_before\n+++ func_after\n@@ -48,7 +48,7 @@\n \t\t * Pin all pages we are about to map in memory. This is\n \t\t * important because we unmap and unpin in 4kb steps later.\n \t\t */\n-\t\tpfn = kvm_pin_pages(slot, gfn, page_size);\n+\t\tpfn = kvm_pin_pages(slot, gfn, page_size >> PAGE_SHIFT);\n \t\tif (is_error_noslot_pfn(pfn)) {\n \t\t\tgfn += 1;\n \t\t\tcontinue;\n@@ -60,7 +60,7 @@\n \t\tif (r) {\n \t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n \t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n-\t\t\tkvm_unpin_pages(kvm, pfn, page_size);\n+\t\t\tkvm_unpin_pages(kvm, pfn, page_size >> PAGE_SHIFT);\n \t\t\tgoto unmap_pages;\n \t\t}\n ",
    "diff_line_info": {
        "deleted_lines": [
            "\t\tpfn = kvm_pin_pages(slot, gfn, page_size);",
            "\t\t\tkvm_unpin_pages(kvm, pfn, page_size);"
        ],
        "added_lines": [
            "\t\tpfn = kvm_pin_pages(slot, gfn, page_size >> PAGE_SHIFT);",
            "\t\t\tkvm_unpin_pages(kvm, pfn, page_size >> PAGE_SHIFT);"
        ]
    },
    "is_vul": true,
    "pr_url": null,
    "description": "no more info"
}