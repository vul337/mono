{
    "cve_id": "CVE-2020-25601",
    "cwe_ids": [
        "CWE-Other"
    ],
    "cvss_vector": "AV:L/AC:L/Au:N/C:N/I:N/A:C",
    "cvss_is_v3": false,
    "repo_name": "xen-project/xen",
    "commit_msg": "evtchn: arrange for preemption in evtchn_reset()\n\nLike for evtchn_destroy() looping over all possible event channels to\nclose them can take a significant amount of time. Unlike done there, we\ncan't alter domain properties (i.e. d->valid_evtchns) here. Borrow, in a\nlightweight form, the paging domctl continuation concept, redirecting\nthe continuations to different sub-ops. Just like there this is to be\nable to allow for predictable overall results of the involved sub-ops:\nRacing requests should either complete or be refused.\n\nNote that a domain can't interfere with an already started (by a remote\ndomain) reset, due to being paused. It can prevent a remote reset from\nhappening by leaving a reset unfinished, but that's only going to affect\nitself.\n\nThis is part of XSA-344.\n\nSigned-off-by: Jan Beulich <jbeulich@suse.com>\nAcked-by: Julien Grall <jgrall@amazon.com>\nReviewed-by: Stefano Stabellini <sstabellini@kernel.org>",
    "commit_hash": "2785b2a9e04abc148e1c5259f4faee708ea356f4",
    "git_url": "https://github.com/xen-project/xen/commit/2785b2a9e04abc148e1c5259f4faee708ea356f4",
    "file_path": "xen/common/domctl.c",
    "func_name": "do_domctl",
    "func_before": "long do_domctl(XEN_GUEST_HANDLE_PARAM(xen_domctl_t) u_domctl)\n{\n    long ret = 0;\n    bool_t copyback = 0;\n    struct xen_domctl curop, *op = &curop;\n    struct domain *d;\n\n    if ( copy_from_guest(op, u_domctl, 1) )\n        return -EFAULT;\n\n    if ( op->interface_version != XEN_DOMCTL_INTERFACE_VERSION )\n        return -EACCES;\n\n    switch ( op->cmd )\n    {\n    case XEN_DOMCTL_assign_device:\n    case XEN_DOMCTL_deassign_device:\n        if ( op->domain == DOMID_IO )\n        {\n            d = dom_io;\n            break;\n        }\n        else if ( op->domain == DOMID_INVALID )\n            return -ESRCH;\n        /* fall through */\n    case XEN_DOMCTL_test_assign_device:\n    case XEN_DOMCTL_vm_event_op:\n        if ( op->domain == DOMID_INVALID )\n        {\n    case XEN_DOMCTL_createdomain:\n    case XEN_DOMCTL_gdbsx_guestmemio:\n            d = NULL;\n            break;\n        }\n        /* fall through */\n    default:\n        d = rcu_lock_domain_by_id(op->domain);\n        if ( !d && op->cmd != XEN_DOMCTL_getdomaininfo )\n            return -ESRCH;\n    }\n\n    ret = xsm_domctl(XSM_OTHER, d, op->cmd);\n    if ( ret )\n        goto domctl_out_unlock_domonly;\n\n    if ( !domctl_lock_acquire() )\n    {\n        if ( d && d != dom_io )\n            rcu_unlock_domain(d);\n        return hypercall_create_continuation(\n            __HYPERVISOR_domctl, \"h\", u_domctl);\n    }\n\n    switch ( op->cmd )\n    {\n\n    case XEN_DOMCTL_setvcpucontext:\n    {\n        vcpu_guest_context_u c = { .nat = NULL };\n        unsigned int vcpu = op->u.vcpucontext.vcpu;\n        struct vcpu *v;\n\n        ret = -EINVAL;\n        if ( (d == current->domain) || /* no domain_pause() */\n             (vcpu >= d->max_vcpus) || ((v = d->vcpu[vcpu]) == NULL) )\n            break;\n\n        if ( guest_handle_is_null(op->u.vcpucontext.ctxt) )\n        {\n            ret = vcpu_reset(v);\n            if ( ret == -ERESTART )\n                ret = hypercall_create_continuation(\n                          __HYPERVISOR_domctl, \"h\", u_domctl);\n            break;\n        }\n\n#ifdef CONFIG_COMPAT\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        ret = -ENOMEM;\n        if ( (c.nat = alloc_vcpu_guest_context()) == NULL )\n            break;\n\n#ifdef CONFIG_COMPAT\n        if ( !is_pv_32bit_domain(d) )\n            ret = copy_from_guest(c.nat, op->u.vcpucontext.ctxt, 1);\n        else\n            ret = copy_from_guest(c.cmp,\n                                  guest_handle_cast(op->u.vcpucontext.ctxt,\n                                                    void), 1);\n#else\n        ret = copy_from_guest(c.nat, op->u.vcpucontext.ctxt, 1);\n#endif\n        ret = ret ? -EFAULT : 0;\n\n        if ( ret == 0 )\n        {\n            domain_pause(d);\n            ret = arch_set_info_guest(v, c);\n            domain_unpause(d);\n\n            if ( ret == -ERESTART )\n                ret = hypercall_create_continuation(\n                          __HYPERVISOR_domctl, \"h\", u_domctl);\n        }\n\n        free_vcpu_guest_context(c.nat);\n        break;\n    }\n\n    case XEN_DOMCTL_pausedomain:\n        ret = -EINVAL;\n        if ( d != current->domain )\n            ret = domain_pause_by_systemcontroller(d);\n        break;\n\n    case XEN_DOMCTL_unpausedomain:\n        ret = domain_unpause_by_systemcontroller(d);\n        break;\n\n    case XEN_DOMCTL_resumedomain:\n        if ( d == current->domain ) /* no domain_pause() */\n            ret = -EINVAL;\n        else\n            domain_resume(d);\n        break;\n\n    case XEN_DOMCTL_createdomain:\n    {\n        domid_t        dom;\n        static domid_t rover = 0;\n\n        dom = op->domain;\n        if ( (dom > 0) && (dom < DOMID_FIRST_RESERVED) )\n        {\n            ret = -EEXIST;\n            if ( !is_free_domid(dom) )\n                break;\n        }\n        else\n        {\n            for ( dom = rover + 1; dom != rover; dom++ )\n            {\n                if ( dom == DOMID_FIRST_RESERVED )\n                    dom = 1;\n                if ( is_free_domid(dom) )\n                    break;\n            }\n\n            ret = -ENOMEM;\n            if ( dom == rover )\n                break;\n\n            rover = dom;\n        }\n\n        d = domain_create(dom, &op->u.createdomain, false);\n        if ( IS_ERR(d) )\n        {\n            ret = PTR_ERR(d);\n            d = NULL;\n            break;\n        }\n\n        ret = 0;\n        op->domain = d->domain_id;\n        copyback = 1;\n        d = NULL;\n        break;\n    }\n\n    case XEN_DOMCTL_max_vcpus:\n    {\n        unsigned int i, max = op->u.max_vcpus.max;\n\n        ret = -EINVAL;\n        if ( (d == current->domain) || /* no domain_pause() */\n             (max != d->max_vcpus) )   /* max_vcpus set up in createdomain */\n            break;\n\n        /* Needed, for example, to ensure writable p.t. state is synced. */\n        domain_pause(d);\n\n        ret = -ENOMEM;\n\n        for ( i = 0; i < max; i++ )\n        {\n            if ( d->vcpu[i] != NULL )\n                continue;\n\n            if ( vcpu_create(d, i) == NULL )\n                goto maxvcpu_out;\n        }\n\n        domain_update_node_affinity(d);\n        ret = 0;\n\n    maxvcpu_out:\n        domain_unpause(d);\n        break;\n    }\n\n    case XEN_DOMCTL_soft_reset:\n        if ( d == current->domain ) /* no domain_pause() */\n        {\n            ret = -EINVAL;\n            break;\n        }\n        ret = domain_soft_reset(d);\n        break;\n\n    case XEN_DOMCTL_destroydomain:\n        domctl_lock_release();\n        domain_lock(d);\n        ret = domain_kill(d);\n        domain_unlock(d);\n        if ( ret == -ERESTART )\n            ret = hypercall_create_continuation(\n                __HYPERVISOR_domctl, \"h\", u_domctl);\n        goto domctl_out_unlock_domonly;\n\n    case XEN_DOMCTL_setnodeaffinity:\n    {\n        nodemask_t new_affinity;\n\n        ret = xenctl_bitmap_to_nodemask(&new_affinity,\n                                        &op->u.nodeaffinity.nodemap);\n        if ( !ret )\n            ret = domain_set_node_affinity(d, &new_affinity);\n        break;\n    }\n\n    case XEN_DOMCTL_getnodeaffinity:\n        ret = nodemask_to_xenctl_bitmap(&op->u.nodeaffinity.nodemap,\n                                        &d->node_affinity);\n        break;\n\n    case XEN_DOMCTL_setvcpuaffinity:\n    case XEN_DOMCTL_getvcpuaffinity:\n        ret = vcpu_affinity_domctl(d, op->cmd, &op->u.vcpuaffinity);\n        break;\n\n    case XEN_DOMCTL_scheduler_op:\n        ret = sched_adjust(d, &op->u.scheduler_op);\n        copyback = 1;\n        break;\n\n    case XEN_DOMCTL_getdomaininfo:\n    {\n        domid_t dom = DOMID_INVALID;\n\n        if ( !d )\n        {\n            ret = -EINVAL;\n            if ( op->domain >= DOMID_FIRST_RESERVED )\n                break;\n\n            rcu_read_lock(&domlist_read_lock);\n\n            dom = op->domain;\n            for_each_domain ( d )\n                if ( d->domain_id >= dom )\n                    break;\n        }\n\n        ret = -ESRCH;\n        if ( d == NULL )\n            goto getdomaininfo_out;\n\n        ret = xsm_getdomaininfo(XSM_HOOK, d);\n        if ( ret )\n            goto getdomaininfo_out;\n\n        getdomaininfo(d, &op->u.getdomaininfo);\n\n        op->domain = op->u.getdomaininfo.domain;\n        copyback = 1;\n\n    getdomaininfo_out:\n        /* When d was non-NULL upon entry, no cleanup is needed. */\n        if ( dom == DOMID_INVALID )\n            break;\n\n        rcu_read_unlock(&domlist_read_lock);\n        d = NULL;\n        break;\n    }\n\n    case XEN_DOMCTL_getvcpucontext:\n    {\n        vcpu_guest_context_u c = { .nat = NULL };\n        struct vcpu         *v;\n\n        ret = -EINVAL;\n        if ( op->u.vcpucontext.vcpu >= d->max_vcpus ||\n             (v = d->vcpu[op->u.vcpucontext.vcpu]) == NULL ||\n             v == current ) /* no vcpu_pause() */\n            goto getvcpucontext_out;\n\n        ret = -ENODATA;\n        if ( !v->is_initialised )\n            goto getvcpucontext_out;\n\n#ifdef CONFIG_COMPAT\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        ret = -ENOMEM;\n        if ( (c.nat = xzalloc(struct vcpu_guest_context)) == NULL )\n            goto getvcpucontext_out;\n\n        vcpu_pause(v);\n\n        arch_get_info_guest(v, c);\n        ret = 0;\n\n        vcpu_unpause(v);\n\n#ifdef CONFIG_COMPAT\n        if ( !is_pv_32bit_domain(d) )\n            ret = copy_to_guest(op->u.vcpucontext.ctxt, c.nat, 1);\n        else\n            ret = copy_to_guest(guest_handle_cast(op->u.vcpucontext.ctxt,\n                                                  void), c.cmp, 1);\n#else\n        ret = copy_to_guest(op->u.vcpucontext.ctxt, c.nat, 1);\n#endif\n\n        if ( ret )\n            ret = -EFAULT;\n        copyback = 1;\n\n    getvcpucontext_out:\n        xfree(c.nat);\n        break;\n    }\n\n    case XEN_DOMCTL_getvcpuinfo:\n    {\n        struct vcpu   *v;\n        struct vcpu_runstate_info runstate;\n\n        ret = -EINVAL;\n        if ( op->u.getvcpuinfo.vcpu >= d->max_vcpus )\n            break;\n\n        ret = -ESRCH;\n        if ( (v = d->vcpu[op->u.getvcpuinfo.vcpu]) == NULL )\n            break;\n\n        vcpu_runstate_get(v, &runstate);\n\n        op->u.getvcpuinfo.online   = !(v->pause_flags & VPF_down);\n        op->u.getvcpuinfo.blocked  = !!(v->pause_flags & VPF_blocked);\n        op->u.getvcpuinfo.running  = v->is_running;\n        op->u.getvcpuinfo.cpu_time = runstate.time[RUNSTATE_running];\n        op->u.getvcpuinfo.cpu      = v->processor;\n        ret = 0;\n        copyback = 1;\n        break;\n    }\n\n    case XEN_DOMCTL_max_mem:\n    {\n        uint64_t new_max = op->u.max_mem.max_memkb >> (PAGE_SHIFT - 10);\n\n        spin_lock(&d->page_alloc_lock);\n        /*\n         * NB. We removed a check that new_max >= current tot_pages; this means\n         * that the domain will now be allowed to \"ratchet\" down to new_max. In\n         * the meantime, while tot > max, all new allocations are disallowed.\n         */\n        d->max_pages = min(new_max, (uint64_t)(typeof(d->max_pages))-1);\n        spin_unlock(&d->page_alloc_lock);\n        break;\n    }\n\n    case XEN_DOMCTL_setdomainhandle:\n        memcpy(d->handle, op->u.setdomainhandle.handle,\n               sizeof(xen_domain_handle_t));\n        break;\n\n    case XEN_DOMCTL_setdebugging:\n        if ( unlikely(d == current->domain) ) /* no domain_pause() */\n            ret = -EINVAL;\n        else\n        {\n            domain_pause(d);\n            d->debugger_attached = !!op->u.setdebugging.enable;\n            domain_unpause(d); /* causes guest to latch new status */\n        }\n        break;\n\n    case XEN_DOMCTL_irq_permission:\n    {\n        unsigned int pirq = op->u.irq_permission.pirq, irq;\n        int allow = op->u.irq_permission.allow_access;\n\n        if ( pirq >= current->domain->nr_pirqs )\n        {\n            ret = -EINVAL;\n            break;\n        }\n        irq = pirq_access_permitted(current->domain, pirq);\n        if ( !irq || xsm_irq_permission(XSM_HOOK, d, irq, allow) )\n            ret = -EPERM;\n        else if ( allow )\n            ret = irq_permit_access(d, irq);\n        else\n            ret = irq_deny_access(d, irq);\n        break;\n    }\n\n    case XEN_DOMCTL_iomem_permission:\n    {\n        unsigned long mfn = op->u.iomem_permission.first_mfn;\n        unsigned long nr_mfns = op->u.iomem_permission.nr_mfns;\n        int allow = op->u.iomem_permission.allow_access;\n\n        ret = -EINVAL;\n        if ( (mfn + nr_mfns - 1) < mfn ) /* wrap? */\n            break;\n\n        if ( !iomem_access_permitted(current->domain,\n                                     mfn, mfn + nr_mfns - 1) ||\n             xsm_iomem_permission(XSM_HOOK, d, mfn, mfn + nr_mfns - 1, allow) )\n            ret = -EPERM;\n        else if ( allow )\n            ret = iomem_permit_access(d, mfn, mfn + nr_mfns - 1);\n        else\n            ret = iomem_deny_access(d, mfn, mfn + nr_mfns - 1);\n        if ( !ret )\n            memory_type_changed(d);\n        break;\n    }\n\n    case XEN_DOMCTL_memory_mapping:\n    {\n        unsigned long gfn = op->u.memory_mapping.first_gfn;\n        unsigned long mfn = op->u.memory_mapping.first_mfn;\n        unsigned long nr_mfns = op->u.memory_mapping.nr_mfns;\n        unsigned long mfn_end = mfn + nr_mfns - 1;\n        int add = op->u.memory_mapping.add_mapping;\n\n        ret = -EINVAL;\n        if ( mfn_end < mfn || /* wrap? */\n             ((mfn | mfn_end) >> (paddr_bits - PAGE_SHIFT)) ||\n             (gfn + nr_mfns - 1) < gfn ) /* wrap? */\n            break;\n\n#ifndef CONFIG_X86 /* XXX ARM!? */\n        ret = -E2BIG;\n        /* Must break hypercall up as this could take a while. */\n        if ( nr_mfns > 64 )\n            break;\n#endif\n\n        ret = -EPERM;\n        if ( !iomem_access_permitted(current->domain, mfn, mfn_end) ||\n             !iomem_access_permitted(d, mfn, mfn_end) )\n            break;\n\n        ret = xsm_iomem_mapping(XSM_HOOK, d, mfn, mfn_end, add);\n        if ( ret )\n            break;\n\n        if ( add )\n        {\n            printk(XENLOG_G_DEBUG\n                   \"memory_map:add: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, gfn, mfn, nr_mfns);\n\n            ret = map_mmio_regions(d, _gfn(gfn), nr_mfns, _mfn(mfn));\n            if ( ret < 0 )\n                printk(XENLOG_G_WARNING\n                       \"memory_map:fail: dom%d gfn=%lx mfn=%lx nr=%lx ret:%ld\\n\",\n                       d->domain_id, gfn, mfn, nr_mfns, ret);\n        }\n        else\n        {\n            printk(XENLOG_G_DEBUG\n                   \"memory_map:remove: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, gfn, mfn, nr_mfns);\n\n            ret = unmap_mmio_regions(d, _gfn(gfn), nr_mfns, _mfn(mfn));\n            if ( ret < 0 && is_hardware_domain(current->domain) )\n                printk(XENLOG_ERR\n                       \"memory_map: error %ld removing dom%d access to [%lx,%lx]\\n\",\n                       ret, d->domain_id, mfn, mfn_end);\n        }\n        /* Do this unconditionally to cover errors on above failure paths. */\n        memory_type_changed(d);\n        break;\n    }\n\n    case XEN_DOMCTL_settimeoffset:\n        domain_set_time_offset(d, op->u.settimeoffset.time_offset_seconds);\n        break;\n\n    case XEN_DOMCTL_set_target:\n    {\n        struct domain *e;\n\n        ret = -ESRCH;\n        e = get_domain_by_id(op->u.set_target.target);\n        if ( e == NULL )\n            break;\n\n        ret = -EINVAL;\n        if ( (d == e) || (d->target != NULL) )\n        {\n            put_domain(e);\n            break;\n        }\n\n        ret = -EOPNOTSUPP;\n        if ( is_hvm_domain(e) )\n            ret = xsm_set_target(XSM_HOOK, d, e);\n        if ( ret )\n        {\n            put_domain(e);\n            break;\n        }\n\n        /* Hold reference on @e until we destroy @d. */\n        d->target = e;\n        break;\n    }\n\n    case XEN_DOMCTL_subscribe:\n        d->suspend_evtchn = op->u.subscribe.port;\n        break;\n\n    case XEN_DOMCTL_vm_event_op:\n        ret = vm_event_domctl(d, &op->u.vm_event_op);\n        if ( ret == 0 )\n            copyback = true;\n        break;\n\n#ifdef CONFIG_MEM_ACCESS\n    case XEN_DOMCTL_set_access_required:\n        if ( unlikely(current->domain == d) ) /* no domain_pause() */\n            ret = -EPERM;\n        else\n        {\n            domain_pause(d);\n            arch_p2m_set_access_required(d,\n                op->u.access_required.access_required);\n            domain_unpause(d);\n        }\n        break;\n#endif\n\n    case XEN_DOMCTL_set_virq_handler:\n        ret = set_global_virq_handler(d, op->u.set_virq_handler.virq);\n        break;\n\n    case XEN_DOMCTL_setvnumainfo:\n    {\n        struct vnuma_info *vnuma;\n\n        vnuma = vnuma_init(&op->u.vnuma, d);\n        if ( IS_ERR(vnuma) )\n        {\n            ret = PTR_ERR(vnuma);\n            break;\n        }\n\n        /* overwrite vnuma topology for domain. */\n        write_lock(&d->vnuma_rwlock);\n        vnuma_destroy(d->vnuma);\n        d->vnuma = vnuma;\n        write_unlock(&d->vnuma_rwlock);\n\n        break;\n    }\n\n    case XEN_DOMCTL_monitor_op:\n        ret = monitor_domctl(d, &op->u.monitor_op);\n        if ( !ret )\n            copyback = 1;\n        break;\n\n    default:\n        ret = arch_do_domctl(op, d, u_domctl);\n        break;\n    }\n\n    domctl_lock_release();\n\n domctl_out_unlock_domonly:\n    if ( d && d != dom_io )\n        rcu_unlock_domain(d);\n\n    if ( copyback && __copy_to_guest(u_domctl, op, 1) )\n        ret = -EFAULT;\n\n    return ret;\n}",
    "abstract_func_before": "long do_domctl(VAR_0(xen_domctl_t) VAR_1)\n{\n    long VAR_2 = 0;\n    bool_t VAR_3 = 0;\n    struct xen_domctl VAR_4, *VAR_5 = &VAR_4;\n    struct domain *VAR_6;\n\n    if ( copy_from_guest(VAR_5, VAR_1, 1) )\n        return -VAR_7;\n\n    if ( VAR_5->interface_version != VAR_8 )\n        return -VAR_9;\n\n    switch ( VAR_5->cmd )\n    {\n    case VAR_10:\n    case VAR_11:\n        if ( VAR_5->domain == VAR_12 )\n        {\n            VAR_6 = VAR_13;\n            break;\n        }\n        else if ( VAR_5->domain == VAR_14 )\n            return -VAR_15;\n        /* COMMENT_0 */\n    case VAR_16:\n    case VAR_17:\n        if ( VAR_5->domain == VAR_14 )\n        {\n    case VAR_18:\n    case VAR_19:\n            VAR_6 = NULL;\n            break;\n        }\n        /* COMMENT_0 */\n    default:\n        VAR_6 = rcu_lock_domain_by_id(VAR_5->domain);\n        if ( !VAR_6 && VAR_5->cmd != VAR_20 )\n            return -VAR_15;\n    }\n\n    VAR_2 = xsm_domctl(VAR_21, VAR_6, VAR_5->cmd);\n    if ( VAR_2 )\n        goto domctl_out_unlock_domonly;\n\n    if ( !domctl_lock_acquire() )\n    {\n        if ( VAR_6 && VAR_6 != VAR_13 )\n            rcu_unlock_domain(VAR_6);\n        return hypercall_create_continuation(\n            VAR_22, \"h\", VAR_1);\n    }\n\n    switch ( VAR_5->cmd )\n    {\n\n    case VAR_23:\n    {\n        vcpu_guest_context_u VAR_24 = { .nat = NULL };\n        unsigned int VAR_25 = VAR_5->u.vcpucontext.vcpu;\n        struct vcpu *VAR_26;\n\n        VAR_2 = -VAR_27;\n        if ( (VAR_6 == VAR_28->domain) || /* COMMENT_1 */\n             (vcpu >= VAR_6->max_vcpus) || ((VAR_26 = VAR_6->vcpu[vcpu]) == NULL) )\n            break;\n\n        if ( guest_handle_is_null(VAR_5->u.vcpucontext.ctxt) )\n        {\n            VAR_2 = vcpu_reset(VAR_26);\n            if ( VAR_2 == -VAR_29 )\n                VAR_2 = hypercall_create_continuation(\n                          VAR_22, \"h\", VAR_1);\n            break;\n        }\n\n#ifdef VAR_30\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        VAR_2 = -VAR_31;\n        if ( (VAR_24.nat = alloc_vcpu_guest_context()) == NULL )\n            break;\n\n#ifdef VAR_30\n        if ( !is_pv_32bit_domain(VAR_6) )\n            VAR_2 = copy_from_guest(VAR_24.nat, VAR_5->u.vcpucontext.ctxt, 1);\n        else\n            VAR_2 = copy_from_guest(VAR_24.cmp,\n                                  guest_handle_cast(VAR_5->u.vcpucontext.ctxt,\n                                                    VAR_32), 1);\n#else\n        VAR_2 = copy_from_guest(VAR_24.nat, VAR_5->u.vcpucontext.ctxt, 1);\n#endif\n        VAR_2 = VAR_2 ? -VAR_7 : 0;\n\n        if ( VAR_2 == 0 )\n        {\n            domain_pause(VAR_6);\n            VAR_2 = arch_set_info_guest(VAR_26, VAR_24);\n            domain_unpause(VAR_6);\n\n            if ( VAR_2 == -VAR_29 )\n                VAR_2 = hypercall_create_continuation(\n                          VAR_22, \"h\", VAR_1);\n        }\n\n        free_vcpu_guest_context(VAR_24.nat);\n        break;\n    }\n\n    case VAR_33:\n        VAR_2 = -VAR_27;\n        if ( VAR_6 != VAR_28->domain )\n            VAR_2 = domain_pause_by_systemcontroller(VAR_6);\n        break;\n\n    case VAR_34:\n        VAR_2 = domain_unpause_by_systemcontroller(VAR_6);\n        break;\n\n    case VAR_35:\n        if ( VAR_6 == VAR_28->domain ) /* COMMENT_1 */\n            VAR_2 = -VAR_27;\n        else\n            domain_resume(VAR_6);\n        break;\n\n    case VAR_18:\n    {\n        domid_t        VAR_36;\n        static domid_t VAR_37 = 0;\n\n        VAR_36 = VAR_5->domain;\n        if ( (VAR_36 > 0) && (VAR_36 < VAR_38) )\n        {\n            VAR_2 = -VAR_39;\n            if ( !is_free_domid(VAR_36) )\n                break;\n        }\n        else\n        {\n            for ( VAR_36 = VAR_37 + 1; VAR_36 != VAR_37; VAR_36++ )\n            {\n                if ( VAR_36 == VAR_38 )\n                    VAR_36 = 1;\n                if ( is_free_domid(VAR_36) )\n                    break;\n            }\n\n            VAR_2 = -VAR_31;\n            if ( VAR_36 == VAR_37 )\n                break;\n\n            VAR_37 = VAR_36;\n        }\n\n        VAR_6 = domain_create(VAR_36, &VAR_5->u.createdomain, false);\n        if ( IS_ERR(VAR_6) )\n        {\n            VAR_2 = PTR_ERR(VAR_6);\n            VAR_6 = NULL;\n            break;\n        }\n\n        VAR_2 = 0;\n        VAR_5->domain = VAR_6->domain_id;\n        VAR_3 = 1;\n        VAR_6 = NULL;\n        break;\n    }\n\n    case VAR_40:\n    {\n        unsigned int VAR_41, VAR_42 = VAR_5->u.max_vcpus.max;\n\n        VAR_2 = -VAR_27;\n        if ( (VAR_6 == VAR_28->domain) || /* COMMENT_1 */\n             (VAR_42 != VAR_6->max_vcpus) )   /* COMMENT_2 */\n            break;\n\n        /* COMMENT_3 */\n        domain_pause(VAR_6);\n\n        VAR_2 = -VAR_31;\n\n        for ( VAR_41 = 0; VAR_41 < VAR_42; VAR_41++ )\n        {\n            if ( VAR_6->vcpu[VAR_41] != NULL )\n                continue;\n\n            if ( vcpu_create(VAR_6, VAR_41) == NULL )\n                goto maxvcpu_out;\n        }\n\n        domain_update_node_affinity(VAR_6);\n        VAR_2 = 0;\n\n    maxvcpu_out:\n        domain_unpause(VAR_6);\n        break;\n    }\n\n    case VAR_43:\n        if ( VAR_6 == VAR_28->domain ) /* COMMENT_1 */\n        {\n            VAR_2 = -VAR_27;\n            break;\n        }\n        VAR_2 = domain_soft_reset(VAR_6);\n        break;\n\n    case VAR_44:\n        domctl_lock_release();\n        domain_lock(VAR_6);\n        VAR_2 = domain_kill(VAR_6);\n        domain_unlock(VAR_6);\n        if ( VAR_2 == -VAR_29 )\n            VAR_2 = hypercall_create_continuation(\n                VAR_22, \"h\", VAR_1);\n        goto domctl_out_unlock_domonly;\n\n    case VAR_45:\n    {\n        nodemask_t VAR_46;\n\n        VAR_2 = xenctl_bitmap_to_nodemask(&VAR_46,\n                                        &VAR_5->u.nodeaffinity.nodemap);\n        if ( !VAR_2 )\n            VAR_2 = domain_set_node_affinity(VAR_6, &VAR_46);\n        break;\n    }\n\n    case VAR_47:\n        VAR_2 = nodemask_to_xenctl_bitmap(&VAR_5->u.nodeaffinity.nodemap,\n                                        &VAR_6->node_affinity);\n        break;\n\n    case VAR_48:\n    case VAR_49:\n        VAR_2 = vcpu_affinity_domctl(VAR_6, VAR_5->cmd, &VAR_5->u.vcpuaffinity);\n        break;\n\n    case VAR_50:\n        VAR_2 = sched_adjust(VAR_6, &VAR_5->u.scheduler_op);\n        VAR_3 = 1;\n        break;\n\n    case VAR_20:\n    {\n        domid_t VAR_36 = VAR_14;\n\n        if ( !VAR_6 )\n        {\n            VAR_2 = -VAR_27;\n            if ( VAR_5->domain >= VAR_38 )\n                break;\n\n            rcu_read_lock(&VAR_51);\n\n            VAR_36 = VAR_5->domain;\n            VAR_52 ( d )\n                if ( d->VAR_53 >= VAR_36 )\n                    break;\n        }\n\n        VAR_2 = -VAR_15;\n        if ( d == NULL )\n            goto getdomaininfo_out;\n\n        VAR_2 = xsm_getdomaininfo(VAR_54, d);\n        if ( VAR_2 )\n            goto getdomaininfo_out;\n\n        getdomaininfo(d, &VAR_5->u.getdomaininfo);\n\n        VAR_5->domain = VAR_5->u.getdomaininfo.domain;\n        VAR_3 = 1;\n\n    getdomaininfo_out:\n        /* COMMENT_4 */\n        if ( VAR_36 == VAR_14 )\n            break;\n\n        rcu_read_unlock(&VAR_51);\n        d = NULL;\n        break;\n    }\n\n    case VAR_55:\n    {\n        vcpu_guest_context_u VAR_24 = { .nat = NULL };\n        struct vcpu         *VAR_26;\n\n        VAR_2 = -VAR_27;\n        if ( VAR_5->u.vcpucontext.vcpu >= d->max_vcpus ||\n             (VAR_26 = d->vcpu[VAR_5->u.vcpucontext.vcpu]) == NULL ||\n             VAR_26 == VAR_28 ) /* COMMENT_5 */\n            goto getvcpucontext_out;\n\n        VAR_2 = -VAR_56;\n        if ( !VAR_26->is_initialised )\n            goto getvcpucontext_out;\n\n#ifdef VAR_30\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        VAR_2 = -VAR_31;\n        if ( (VAR_24.nat = xzalloc(struct vcpu_guest_context)) == NULL )\n            goto getvcpucontext_out;\n\n        vcpu_pause(VAR_26);\n\n        arch_get_info_guest(VAR_26, VAR_24);\n        VAR_2 = 0;\n\n        vcpu_unpause(VAR_26);\n\n#ifdef VAR_30\n        if ( !is_pv_32bit_domain(d) )\n            VAR_2 = copy_to_guest(VAR_5->u.vcpucontext.ctxt, VAR_24.nat, 1);\n        else\n            VAR_2 = copy_to_guest(guest_handle_cast(VAR_5->u.vcpucontext.ctxt,\n                                                  VAR_32), VAR_24.cmp, 1);\n#else\n        VAR_2 = copy_to_guest(VAR_5->u.vcpucontext.ctxt, VAR_24.nat, 1);\n#endif\n\n        if ( VAR_2 )\n            VAR_2 = -VAR_7;\n        VAR_3 = 1;\n\n    getvcpucontext_out:\n        xfree(VAR_24.nat);\n        break;\n    }\n\n    case VAR_57:\n    {\n        struct vcpu   *VAR_26;\n        struct vcpu_runstate_info VAR_58;\n\n        VAR_2 = -VAR_27;\n        if ( VAR_5->u.getvcpuinfo.vcpu >= d->max_vcpus )\n            break;\n\n        VAR_2 = -VAR_15;\n        if ( (VAR_26 = d->vcpu[VAR_5->u.getvcpuinfo.vcpu]) == NULL )\n            break;\n\n        vcpu_runstate_get(VAR_26, &VAR_58);\n\n        VAR_5->u.getvcpuinfo.online   = !(VAR_26->pause_flags & VAR_59);\n        VAR_5->u.getvcpuinfo.blocked  = !!(VAR_26->pause_flags & VAR_60);\n        VAR_5->u.getvcpuinfo.running  = VAR_26->is_running;\n        VAR_5->u.getvcpuinfo.cpu_time = VAR_58.time[VAR_61];\n        VAR_5->u.getvcpuinfo.cpu      = VAR_26->processor;\n        VAR_2 = 0;\n        VAR_3 = 1;\n        break;\n    }\n\n    case VAR_62:\n    {\n        uint64_t VAR_63 = VAR_5->u.max_mem.max_memkb >> (VAR_64 - 10);\n\n        spin_lock(&d->page_alloc_lock);\n        /* COMMENT_6 */\n                                                                               \n                                                                               \n                                                                             \n           \n        d->max_pages = min(VAR_63, (uint64_t)(typeof(d->max_pages))-1);\n        spin_unlock(&d->page_alloc_lock);\n        break;\n    }\n\n    case VAR_65:\n        memcpy(d->handle, VAR_5->u.setdomainhandle.handle,\n               sizeof(VAR_66));\n        break;\n\n    case VAR_67:\n        if ( unlikely(d == VAR_28->domain) ) /* COMMENT_1 */\n            VAR_2 = -VAR_27;\n        else\n        {\n            domain_pause(d);\n            d->debugger_attached = !!VAR_5->u.setdebugging.enable;\n            domain_unpause(d); /* COMMENT_11 */\n        }\n        break;\n\n    case VAR_68:\n    {\n        unsigned int VAR_69 = VAR_5->u.irq_permission.pirq, VAR_70;\n        int VAR_71 = VAR_5->u.irq_permission.allow_access;\n\n        if ( VAR_69 >= VAR_28->domain->nr_pirqs )\n        {\n            VAR_2 = -VAR_27;\n            break;\n        }\n        VAR_70 = pirq_access_permitted(VAR_28->domain, VAR_69);\n        if ( !VAR_70 || xsm_irq_permission(VAR_54, d, VAR_70, VAR_71) )\n            VAR_2 = -VAR_72;\n        else if ( VAR_71 )\n            VAR_2 = irq_permit_access(d, VAR_70);\n        else\n            VAR_2 = irq_deny_access(d, VAR_70);\n        break;\n    }\n\n    case VAR_73:\n    {\n        unsigned long VAR_74 = VAR_5->u.iomem_permission.first_mfn;\n        unsigned long VAR_75 = VAR_5->u.iomem_permission.nr_mfns;\n        int VAR_71 = VAR_5->u.iomem_permission.allow_access;\n\n        VAR_2 = -VAR_27;\n        if ( (VAR_74 + VAR_75 - 1) < VAR_74 ) /* COMMENT_12 */\n            break;\n\n        if ( !iomem_access_permitted(VAR_28->domain,\n                                     VAR_74, VAR_74 + VAR_75 - 1) ||\n             xsm_iomem_permission(VAR_54, d, VAR_74, VAR_74 + VAR_75 - 1, VAR_71) )\n            VAR_2 = -VAR_72;\n        else if ( VAR_71 )\n            VAR_2 = iomem_permit_access(d, VAR_74, VAR_74 + VAR_75 - 1);\n        else\n            VAR_2 = iomem_deny_access(d, VAR_74, VAR_74 + VAR_75 - 1);\n        if ( !VAR_2 )\n            memory_type_changed(d);\n        break;\n    }\n\n    case VAR_76:\n    {\n        unsigned long VAR_77 = VAR_5->u.memory_mapping.first_gfn;\n        unsigned long VAR_74 = VAR_5->u.memory_mapping.first_mfn;\n        unsigned long VAR_75 = VAR_5->u.memory_mapping.nr_mfns;\n        unsigned long VAR_78 = VAR_74 + VAR_75 - 1;\n        int VAR_79 = VAR_5->u.memory_mapping.add_mapping;\n\n        VAR_2 = -VAR_27;\n        if ( VAR_78 < VAR_74 || /* COMMENT_12 */\n             ((VAR_74 | VAR_78) >> (VAR_80 - VAR_64)) ||\n             (VAR_77 + VAR_75 - 1) < VAR_77 ) /* COMMENT_12 */\n            break;\n\n#ifndef VAR_81 /* COMMENT_13 */\n        VAR_2 = -VAR_82;\n        /* COMMENT_14 */\n        if ( VAR_75 > 64 )\n            break;\n#endif\n\n        VAR_2 = -VAR_72;\n        if ( !iomem_access_permitted(VAR_28->domain, VAR_74, VAR_78) ||\n             !iomem_access_permitted(d, VAR_74, VAR_78) )\n            break;\n\n        VAR_2 = xsm_iomem_mapping(VAR_54, d, VAR_74, VAR_78, VAR_79);\n        if ( VAR_2 )\n            break;\n\n        if ( VAR_79 )\n        {\n            VAR_83(VAR_84\n                   \"memory_map:add: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, VAR_77, VAR_74, VAR_75);\n\n            VAR_2 = map_mmio_regions(d, _gfn(VAR_77), VAR_75, _mfn(VAR_74));\n            if ( VAR_2 < 0 )\n                VAR_83(XENLOG_G_WARNING\n                       \"memory_map:fail: dom%d gfn=%lx mfn=%lx nr=%lx ret:%ld\\n\",\n                       d->domain_id, VAR_77, VAR_74, VAR_75, VAR_2);\n        }\n        else\n        {\n            VAR_83(VAR_84\n                   \"memory_map:remove: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, VAR_77, VAR_74, VAR_75);\n\n            VAR_2 = unmap_mmio_regions(d, _gfn(VAR_77), VAR_75, _mfn(VAR_74));\n            if ( VAR_2 < 0 && is_hardware_domain(VAR_28->domain) )\n                VAR_83(XENLOG_ERR\n                       \"memory_map: error %ld removing dom%d access to [%lx,%lx]\\n\",\n                       VAR_2, d->domain_id, VAR_74, VAR_78);\n        }\n        /* COMMENT_15 */\n        memory_type_changed(d);\n        break;\n    }\n\n    case VAR_85:\n        domain_set_time_offset(d, VAR_5->u.settimeoffset.time_offset_seconds);\n        break;\n\n    case VAR_86:\n    {\n        struct domain *VAR_87;\n\n        VAR_2 = -VAR_15;\n        VAR_87 = get_domain_by_id(VAR_5->u.set_target.target);\n        if ( VAR_87 == NULL )\n            break;\n\n        VAR_2 = -VAR_27;\n        if ( (d == VAR_87) || (d->target != NULL) )\n        {\n            put_domain(VAR_87);\n            break;\n        }\n\n        VAR_2 = -VAR_88;\n        if ( is_hvm_domain(VAR_87) )\n            VAR_2 = xsm_set_target(VAR_54, d, VAR_87);\n        if ( VAR_2 )\n        {\n            put_domain(VAR_87);\n            break;\n        }\n\n        /* COMMENT_16 */\n        d->target = VAR_87;\n        break;\n    }\n\n    case VAR_89:\n        d->suspend_evtchn = VAR_5->u.subscribe.port;\n        break;\n\n    case VAR_17:\n        VAR_2 = vm_event_domctl(d, &VAR_5->u.vm_event_op);\n        if ( VAR_2 == 0 )\n            VAR_3 = true;\n        break;\n\n#ifdef VAR_90\n    case VAR_91:\n        if ( unlikely(VAR_28->domain == d) ) /* COMMENT_1 */\n            VAR_2 = -VAR_72;\n        else\n        {\n            domain_pause(d);\n            arch_p2m_set_access_required(d,\n                VAR_5->u.access_required.access_required);\n            domain_unpause(d);\n        }\n        break;\n#endif\n\n    case VAR_92:\n        VAR_2 = set_global_virq_handler(d, VAR_5->u.set_virq_handler.virq);\n        break;\n\n    case VAR_93:\n    {\n        struct vnuma_info *VAR_94;\n\n        VAR_94 = vnuma_init(&VAR_5->u.vnuma, d);\n        if ( IS_ERR(VAR_94) )\n        {\n            VAR_2 = PTR_ERR(VAR_94);\n            break;\n        }\n\n        /* COMMENT_17 */\n        write_lock(&d->vnuma_rwlock);\n        vnuma_destroy(d->vnuma);\n        d->vnuma = VAR_94;\n        write_unlock(&d->vnuma_rwlock);\n\n        break;\n    }\n\n    case VAR_95:\n        VAR_2 = monitor_domctl(d, &VAR_5->u.monitor_op);\n        if ( !VAR_2 )\n            VAR_3 = 1;\n        break;\n\n    default:\n        VAR_2 = arch_do_domctl(VAR_5, d, VAR_1);\n        break;\n    }\n\n    domctl_lock_release();\n\n domctl_out_unlock_domonly:\n    if ( d && d != VAR_13 )\n        rcu_unlock_domain(d);\n\n    if ( VAR_3 && __copy_to_guest(VAR_1, VAR_5, 1) )\n        VAR_2 = -VAR_7;\n\n    return VAR_2;\n}",
    "func_graph_path_before": null,
    "func": "long do_domctl(XEN_GUEST_HANDLE_PARAM(xen_domctl_t) u_domctl)\n{\n    long ret = 0;\n    bool_t copyback = 0;\n    struct xen_domctl curop, *op = &curop;\n    struct domain *d;\n\n    if ( copy_from_guest(op, u_domctl, 1) )\n        return -EFAULT;\n\n    if ( op->interface_version != XEN_DOMCTL_INTERFACE_VERSION )\n        return -EACCES;\n\n    switch ( op->cmd )\n    {\n    case XEN_DOMCTL_assign_device:\n    case XEN_DOMCTL_deassign_device:\n        if ( op->domain == DOMID_IO )\n        {\n            d = dom_io;\n            break;\n        }\n        else if ( op->domain == DOMID_INVALID )\n            return -ESRCH;\n        /* fall through */\n    case XEN_DOMCTL_test_assign_device:\n    case XEN_DOMCTL_vm_event_op:\n        if ( op->domain == DOMID_INVALID )\n        {\n    case XEN_DOMCTL_createdomain:\n    case XEN_DOMCTL_gdbsx_guestmemio:\n            d = NULL;\n            break;\n        }\n        /* fall through */\n    default:\n        d = rcu_lock_domain_by_id(op->domain);\n        if ( !d && op->cmd != XEN_DOMCTL_getdomaininfo )\n            return -ESRCH;\n    }\n\n    ret = xsm_domctl(XSM_OTHER, d, op->cmd);\n    if ( ret )\n        goto domctl_out_unlock_domonly;\n\n    if ( !domctl_lock_acquire() )\n    {\n        if ( d && d != dom_io )\n            rcu_unlock_domain(d);\n        return hypercall_create_continuation(\n            __HYPERVISOR_domctl, \"h\", u_domctl);\n    }\n\n    switch ( op->cmd )\n    {\n\n    case XEN_DOMCTL_setvcpucontext:\n    {\n        vcpu_guest_context_u c = { .nat = NULL };\n        unsigned int vcpu = op->u.vcpucontext.vcpu;\n        struct vcpu *v;\n\n        ret = -EINVAL;\n        if ( (d == current->domain) || /* no domain_pause() */\n             (vcpu >= d->max_vcpus) || ((v = d->vcpu[vcpu]) == NULL) )\n            break;\n\n        if ( guest_handle_is_null(op->u.vcpucontext.ctxt) )\n        {\n            ret = vcpu_reset(v);\n            if ( ret == -ERESTART )\n                ret = hypercall_create_continuation(\n                          __HYPERVISOR_domctl, \"h\", u_domctl);\n            break;\n        }\n\n#ifdef CONFIG_COMPAT\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        ret = -ENOMEM;\n        if ( (c.nat = alloc_vcpu_guest_context()) == NULL )\n            break;\n\n#ifdef CONFIG_COMPAT\n        if ( !is_pv_32bit_domain(d) )\n            ret = copy_from_guest(c.nat, op->u.vcpucontext.ctxt, 1);\n        else\n            ret = copy_from_guest(c.cmp,\n                                  guest_handle_cast(op->u.vcpucontext.ctxt,\n                                                    void), 1);\n#else\n        ret = copy_from_guest(c.nat, op->u.vcpucontext.ctxt, 1);\n#endif\n        ret = ret ? -EFAULT : 0;\n\n        if ( ret == 0 )\n        {\n            domain_pause(d);\n            ret = arch_set_info_guest(v, c);\n            domain_unpause(d);\n\n            if ( ret == -ERESTART )\n                ret = hypercall_create_continuation(\n                          __HYPERVISOR_domctl, \"h\", u_domctl);\n        }\n\n        free_vcpu_guest_context(c.nat);\n        break;\n    }\n\n    case XEN_DOMCTL_pausedomain:\n        ret = -EINVAL;\n        if ( d != current->domain )\n            ret = domain_pause_by_systemcontroller(d);\n        break;\n\n    case XEN_DOMCTL_unpausedomain:\n        ret = domain_unpause_by_systemcontroller(d);\n        break;\n\n    case XEN_DOMCTL_resumedomain:\n        if ( d == current->domain ) /* no domain_pause() */\n            ret = -EINVAL;\n        else\n            domain_resume(d);\n        break;\n\n    case XEN_DOMCTL_createdomain:\n    {\n        domid_t        dom;\n        static domid_t rover = 0;\n\n        dom = op->domain;\n        if ( (dom > 0) && (dom < DOMID_FIRST_RESERVED) )\n        {\n            ret = -EEXIST;\n            if ( !is_free_domid(dom) )\n                break;\n        }\n        else\n        {\n            for ( dom = rover + 1; dom != rover; dom++ )\n            {\n                if ( dom == DOMID_FIRST_RESERVED )\n                    dom = 1;\n                if ( is_free_domid(dom) )\n                    break;\n            }\n\n            ret = -ENOMEM;\n            if ( dom == rover )\n                break;\n\n            rover = dom;\n        }\n\n        d = domain_create(dom, &op->u.createdomain, false);\n        if ( IS_ERR(d) )\n        {\n            ret = PTR_ERR(d);\n            d = NULL;\n            break;\n        }\n\n        ret = 0;\n        op->domain = d->domain_id;\n        copyback = 1;\n        d = NULL;\n        break;\n    }\n\n    case XEN_DOMCTL_max_vcpus:\n    {\n        unsigned int i, max = op->u.max_vcpus.max;\n\n        ret = -EINVAL;\n        if ( (d == current->domain) || /* no domain_pause() */\n             (max != d->max_vcpus) )   /* max_vcpus set up in createdomain */\n            break;\n\n        /* Needed, for example, to ensure writable p.t. state is synced. */\n        domain_pause(d);\n\n        ret = -ENOMEM;\n\n        for ( i = 0; i < max; i++ )\n        {\n            if ( d->vcpu[i] != NULL )\n                continue;\n\n            if ( vcpu_create(d, i) == NULL )\n                goto maxvcpu_out;\n        }\n\n        domain_update_node_affinity(d);\n        ret = 0;\n\n    maxvcpu_out:\n        domain_unpause(d);\n        break;\n    }\n\n    case XEN_DOMCTL_soft_reset:\n    case XEN_DOMCTL_soft_reset_cont:\n        if ( d == current->domain ) /* no domain_pause() */\n        {\n            ret = -EINVAL;\n            break;\n        }\n        ret = domain_soft_reset(d, op->cmd == XEN_DOMCTL_soft_reset_cont);\n        if ( ret == -ERESTART )\n        {\n            op->cmd = XEN_DOMCTL_soft_reset_cont;\n            if ( !__copy_field_to_guest(u_domctl, op, cmd) )\n                ret = hypercall_create_continuation(__HYPERVISOR_domctl,\n                                                    \"h\", u_domctl);\n            else\n                ret = -EFAULT;\n        }\n        break;\n\n    case XEN_DOMCTL_destroydomain:\n        domctl_lock_release();\n        domain_lock(d);\n        ret = domain_kill(d);\n        domain_unlock(d);\n        if ( ret == -ERESTART )\n            ret = hypercall_create_continuation(\n                __HYPERVISOR_domctl, \"h\", u_domctl);\n        goto domctl_out_unlock_domonly;\n\n    case XEN_DOMCTL_setnodeaffinity:\n    {\n        nodemask_t new_affinity;\n\n        ret = xenctl_bitmap_to_nodemask(&new_affinity,\n                                        &op->u.nodeaffinity.nodemap);\n        if ( !ret )\n            ret = domain_set_node_affinity(d, &new_affinity);\n        break;\n    }\n\n    case XEN_DOMCTL_getnodeaffinity:\n        ret = nodemask_to_xenctl_bitmap(&op->u.nodeaffinity.nodemap,\n                                        &d->node_affinity);\n        break;\n\n    case XEN_DOMCTL_setvcpuaffinity:\n    case XEN_DOMCTL_getvcpuaffinity:\n        ret = vcpu_affinity_domctl(d, op->cmd, &op->u.vcpuaffinity);\n        break;\n\n    case XEN_DOMCTL_scheduler_op:\n        ret = sched_adjust(d, &op->u.scheduler_op);\n        copyback = 1;\n        break;\n\n    case XEN_DOMCTL_getdomaininfo:\n    {\n        domid_t dom = DOMID_INVALID;\n\n        if ( !d )\n        {\n            ret = -EINVAL;\n            if ( op->domain >= DOMID_FIRST_RESERVED )\n                break;\n\n            rcu_read_lock(&domlist_read_lock);\n\n            dom = op->domain;\n            for_each_domain ( d )\n                if ( d->domain_id >= dom )\n                    break;\n        }\n\n        ret = -ESRCH;\n        if ( d == NULL )\n            goto getdomaininfo_out;\n\n        ret = xsm_getdomaininfo(XSM_HOOK, d);\n        if ( ret )\n            goto getdomaininfo_out;\n\n        getdomaininfo(d, &op->u.getdomaininfo);\n\n        op->domain = op->u.getdomaininfo.domain;\n        copyback = 1;\n\n    getdomaininfo_out:\n        /* When d was non-NULL upon entry, no cleanup is needed. */\n        if ( dom == DOMID_INVALID )\n            break;\n\n        rcu_read_unlock(&domlist_read_lock);\n        d = NULL;\n        break;\n    }\n\n    case XEN_DOMCTL_getvcpucontext:\n    {\n        vcpu_guest_context_u c = { .nat = NULL };\n        struct vcpu         *v;\n\n        ret = -EINVAL;\n        if ( op->u.vcpucontext.vcpu >= d->max_vcpus ||\n             (v = d->vcpu[op->u.vcpucontext.vcpu]) == NULL ||\n             v == current ) /* no vcpu_pause() */\n            goto getvcpucontext_out;\n\n        ret = -ENODATA;\n        if ( !v->is_initialised )\n            goto getvcpucontext_out;\n\n#ifdef CONFIG_COMPAT\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        ret = -ENOMEM;\n        if ( (c.nat = xzalloc(struct vcpu_guest_context)) == NULL )\n            goto getvcpucontext_out;\n\n        vcpu_pause(v);\n\n        arch_get_info_guest(v, c);\n        ret = 0;\n\n        vcpu_unpause(v);\n\n#ifdef CONFIG_COMPAT\n        if ( !is_pv_32bit_domain(d) )\n            ret = copy_to_guest(op->u.vcpucontext.ctxt, c.nat, 1);\n        else\n            ret = copy_to_guest(guest_handle_cast(op->u.vcpucontext.ctxt,\n                                                  void), c.cmp, 1);\n#else\n        ret = copy_to_guest(op->u.vcpucontext.ctxt, c.nat, 1);\n#endif\n\n        if ( ret )\n            ret = -EFAULT;\n        copyback = 1;\n\n    getvcpucontext_out:\n        xfree(c.nat);\n        break;\n    }\n\n    case XEN_DOMCTL_getvcpuinfo:\n    {\n        struct vcpu   *v;\n        struct vcpu_runstate_info runstate;\n\n        ret = -EINVAL;\n        if ( op->u.getvcpuinfo.vcpu >= d->max_vcpus )\n            break;\n\n        ret = -ESRCH;\n        if ( (v = d->vcpu[op->u.getvcpuinfo.vcpu]) == NULL )\n            break;\n\n        vcpu_runstate_get(v, &runstate);\n\n        op->u.getvcpuinfo.online   = !(v->pause_flags & VPF_down);\n        op->u.getvcpuinfo.blocked  = !!(v->pause_flags & VPF_blocked);\n        op->u.getvcpuinfo.running  = v->is_running;\n        op->u.getvcpuinfo.cpu_time = runstate.time[RUNSTATE_running];\n        op->u.getvcpuinfo.cpu      = v->processor;\n        ret = 0;\n        copyback = 1;\n        break;\n    }\n\n    case XEN_DOMCTL_max_mem:\n    {\n        uint64_t new_max = op->u.max_mem.max_memkb >> (PAGE_SHIFT - 10);\n\n        spin_lock(&d->page_alloc_lock);\n        /*\n         * NB. We removed a check that new_max >= current tot_pages; this means\n         * that the domain will now be allowed to \"ratchet\" down to new_max. In\n         * the meantime, while tot > max, all new allocations are disallowed.\n         */\n        d->max_pages = min(new_max, (uint64_t)(typeof(d->max_pages))-1);\n        spin_unlock(&d->page_alloc_lock);\n        break;\n    }\n\n    case XEN_DOMCTL_setdomainhandle:\n        memcpy(d->handle, op->u.setdomainhandle.handle,\n               sizeof(xen_domain_handle_t));\n        break;\n\n    case XEN_DOMCTL_setdebugging:\n        if ( unlikely(d == current->domain) ) /* no domain_pause() */\n            ret = -EINVAL;\n        else\n        {\n            domain_pause(d);\n            d->debugger_attached = !!op->u.setdebugging.enable;\n            domain_unpause(d); /* causes guest to latch new status */\n        }\n        break;\n\n    case XEN_DOMCTL_irq_permission:\n    {\n        unsigned int pirq = op->u.irq_permission.pirq, irq;\n        int allow = op->u.irq_permission.allow_access;\n\n        if ( pirq >= current->domain->nr_pirqs )\n        {\n            ret = -EINVAL;\n            break;\n        }\n        irq = pirq_access_permitted(current->domain, pirq);\n        if ( !irq || xsm_irq_permission(XSM_HOOK, d, irq, allow) )\n            ret = -EPERM;\n        else if ( allow )\n            ret = irq_permit_access(d, irq);\n        else\n            ret = irq_deny_access(d, irq);\n        break;\n    }\n\n    case XEN_DOMCTL_iomem_permission:\n    {\n        unsigned long mfn = op->u.iomem_permission.first_mfn;\n        unsigned long nr_mfns = op->u.iomem_permission.nr_mfns;\n        int allow = op->u.iomem_permission.allow_access;\n\n        ret = -EINVAL;\n        if ( (mfn + nr_mfns - 1) < mfn ) /* wrap? */\n            break;\n\n        if ( !iomem_access_permitted(current->domain,\n                                     mfn, mfn + nr_mfns - 1) ||\n             xsm_iomem_permission(XSM_HOOK, d, mfn, mfn + nr_mfns - 1, allow) )\n            ret = -EPERM;\n        else if ( allow )\n            ret = iomem_permit_access(d, mfn, mfn + nr_mfns - 1);\n        else\n            ret = iomem_deny_access(d, mfn, mfn + nr_mfns - 1);\n        if ( !ret )\n            memory_type_changed(d);\n        break;\n    }\n\n    case XEN_DOMCTL_memory_mapping:\n    {\n        unsigned long gfn = op->u.memory_mapping.first_gfn;\n        unsigned long mfn = op->u.memory_mapping.first_mfn;\n        unsigned long nr_mfns = op->u.memory_mapping.nr_mfns;\n        unsigned long mfn_end = mfn + nr_mfns - 1;\n        int add = op->u.memory_mapping.add_mapping;\n\n        ret = -EINVAL;\n        if ( mfn_end < mfn || /* wrap? */\n             ((mfn | mfn_end) >> (paddr_bits - PAGE_SHIFT)) ||\n             (gfn + nr_mfns - 1) < gfn ) /* wrap? */\n            break;\n\n#ifndef CONFIG_X86 /* XXX ARM!? */\n        ret = -E2BIG;\n        /* Must break hypercall up as this could take a while. */\n        if ( nr_mfns > 64 )\n            break;\n#endif\n\n        ret = -EPERM;\n        if ( !iomem_access_permitted(current->domain, mfn, mfn_end) ||\n             !iomem_access_permitted(d, mfn, mfn_end) )\n            break;\n\n        ret = xsm_iomem_mapping(XSM_HOOK, d, mfn, mfn_end, add);\n        if ( ret )\n            break;\n\n        if ( add )\n        {\n            printk(XENLOG_G_DEBUG\n                   \"memory_map:add: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, gfn, mfn, nr_mfns);\n\n            ret = map_mmio_regions(d, _gfn(gfn), nr_mfns, _mfn(mfn));\n            if ( ret < 0 )\n                printk(XENLOG_G_WARNING\n                       \"memory_map:fail: dom%d gfn=%lx mfn=%lx nr=%lx ret:%ld\\n\",\n                       d->domain_id, gfn, mfn, nr_mfns, ret);\n        }\n        else\n        {\n            printk(XENLOG_G_DEBUG\n                   \"memory_map:remove: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, gfn, mfn, nr_mfns);\n\n            ret = unmap_mmio_regions(d, _gfn(gfn), nr_mfns, _mfn(mfn));\n            if ( ret < 0 && is_hardware_domain(current->domain) )\n                printk(XENLOG_ERR\n                       \"memory_map: error %ld removing dom%d access to [%lx,%lx]\\n\",\n                       ret, d->domain_id, mfn, mfn_end);\n        }\n        /* Do this unconditionally to cover errors on above failure paths. */\n        memory_type_changed(d);\n        break;\n    }\n\n    case XEN_DOMCTL_settimeoffset:\n        domain_set_time_offset(d, op->u.settimeoffset.time_offset_seconds);\n        break;\n\n    case XEN_DOMCTL_set_target:\n    {\n        struct domain *e;\n\n        ret = -ESRCH;\n        e = get_domain_by_id(op->u.set_target.target);\n        if ( e == NULL )\n            break;\n\n        ret = -EINVAL;\n        if ( (d == e) || (d->target != NULL) )\n        {\n            put_domain(e);\n            break;\n        }\n\n        ret = -EOPNOTSUPP;\n        if ( is_hvm_domain(e) )\n            ret = xsm_set_target(XSM_HOOK, d, e);\n        if ( ret )\n        {\n            put_domain(e);\n            break;\n        }\n\n        /* Hold reference on @e until we destroy @d. */\n        d->target = e;\n        break;\n    }\n\n    case XEN_DOMCTL_subscribe:\n        d->suspend_evtchn = op->u.subscribe.port;\n        break;\n\n    case XEN_DOMCTL_vm_event_op:\n        ret = vm_event_domctl(d, &op->u.vm_event_op);\n        if ( ret == 0 )\n            copyback = true;\n        break;\n\n#ifdef CONFIG_MEM_ACCESS\n    case XEN_DOMCTL_set_access_required:\n        if ( unlikely(current->domain == d) ) /* no domain_pause() */\n            ret = -EPERM;\n        else\n        {\n            domain_pause(d);\n            arch_p2m_set_access_required(d,\n                op->u.access_required.access_required);\n            domain_unpause(d);\n        }\n        break;\n#endif\n\n    case XEN_DOMCTL_set_virq_handler:\n        ret = set_global_virq_handler(d, op->u.set_virq_handler.virq);\n        break;\n\n    case XEN_DOMCTL_setvnumainfo:\n    {\n        struct vnuma_info *vnuma;\n\n        vnuma = vnuma_init(&op->u.vnuma, d);\n        if ( IS_ERR(vnuma) )\n        {\n            ret = PTR_ERR(vnuma);\n            break;\n        }\n\n        /* overwrite vnuma topology for domain. */\n        write_lock(&d->vnuma_rwlock);\n        vnuma_destroy(d->vnuma);\n        d->vnuma = vnuma;\n        write_unlock(&d->vnuma_rwlock);\n\n        break;\n    }\n\n    case XEN_DOMCTL_monitor_op:\n        ret = monitor_domctl(d, &op->u.monitor_op);\n        if ( !ret )\n            copyback = 1;\n        break;\n\n    default:\n        ret = arch_do_domctl(op, d, u_domctl);\n        break;\n    }\n\n    domctl_lock_release();\n\n domctl_out_unlock_domonly:\n    if ( d && d != dom_io )\n        rcu_unlock_domain(d);\n\n    if ( copyback && __copy_to_guest(u_domctl, op, 1) )\n        ret = -EFAULT;\n\n    return ret;\n}",
    "abstract_func": "long do_domctl(VAR_0(xen_domctl_t) VAR_1)\n{\n    long VAR_2 = 0;\n    bool_t VAR_3 = 0;\n    struct xen_domctl VAR_4, *VAR_5 = &VAR_4;\n    struct domain *VAR_6;\n\n    if ( copy_from_guest(VAR_5, VAR_1, 1) )\n        return -VAR_7;\n\n    if ( VAR_5->interface_version != VAR_8 )\n        return -VAR_9;\n\n    switch ( VAR_5->cmd )\n    {\n    case VAR_10:\n    case VAR_11:\n        if ( VAR_5->domain == VAR_12 )\n        {\n            VAR_6 = VAR_13;\n            break;\n        }\n        else if ( VAR_5->domain == VAR_14 )\n            return -VAR_15;\n        /* COMMENT_0 */\n    case VAR_16:\n    case VAR_17:\n        if ( VAR_5->domain == VAR_14 )\n        {\n    case VAR_18:\n    case VAR_19:\n            VAR_6 = NULL;\n            break;\n        }\n        /* COMMENT_0 */\n    default:\n        VAR_6 = rcu_lock_domain_by_id(VAR_5->domain);\n        if ( !VAR_6 && VAR_5->cmd != VAR_20 )\n            return -VAR_15;\n    }\n\n    VAR_2 = xsm_domctl(VAR_21, VAR_6, VAR_5->cmd);\n    if ( VAR_2 )\n        goto domctl_out_unlock_domonly;\n\n    if ( !domctl_lock_acquire() )\n    {\n        if ( VAR_6 && VAR_6 != VAR_13 )\n            rcu_unlock_domain(VAR_6);\n        return hypercall_create_continuation(\n            VAR_22, \"h\", VAR_1);\n    }\n\n    switch ( VAR_5->cmd )\n    {\n\n    case VAR_23:\n    {\n        vcpu_guest_context_u VAR_24 = { .nat = NULL };\n        unsigned int VAR_25 = VAR_5->u.vcpucontext.vcpu;\n        struct vcpu *VAR_26;\n\n        VAR_2 = -VAR_27;\n        if ( (VAR_6 == VAR_28->domain) || /* COMMENT_1 */\n             (vcpu >= VAR_6->max_vcpus) || ((VAR_26 = VAR_6->vcpu[vcpu]) == NULL) )\n            break;\n\n        if ( guest_handle_is_null(VAR_5->u.vcpucontext.ctxt) )\n        {\n            VAR_2 = vcpu_reset(VAR_26);\n            if ( VAR_2 == -VAR_29 )\n                VAR_2 = hypercall_create_continuation(\n                          VAR_22, \"h\", VAR_1);\n            break;\n        }\n\n#ifdef VAR_30\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        VAR_2 = -VAR_31;\n        if ( (VAR_24.nat = alloc_vcpu_guest_context()) == NULL )\n            break;\n\n#ifdef VAR_30\n        if ( !is_pv_32bit_domain(VAR_6) )\n            VAR_2 = copy_from_guest(VAR_24.nat, VAR_5->u.vcpucontext.ctxt, 1);\n        else\n            VAR_2 = copy_from_guest(VAR_24.cmp,\n                                  guest_handle_cast(VAR_5->u.vcpucontext.ctxt,\n                                                    VAR_32), 1);\n#else\n        VAR_2 = copy_from_guest(VAR_24.nat, VAR_5->u.vcpucontext.ctxt, 1);\n#endif\n        VAR_2 = VAR_2 ? -VAR_7 : 0;\n\n        if ( VAR_2 == 0 )\n        {\n            domain_pause(VAR_6);\n            VAR_2 = arch_set_info_guest(VAR_26, VAR_24);\n            domain_unpause(VAR_6);\n\n            if ( VAR_2 == -VAR_29 )\n                VAR_2 = hypercall_create_continuation(\n                          VAR_22, \"h\", VAR_1);\n        }\n\n        free_vcpu_guest_context(VAR_24.nat);\n        break;\n    }\n\n    case VAR_33:\n        VAR_2 = -VAR_27;\n        if ( VAR_6 != VAR_28->domain )\n            VAR_2 = domain_pause_by_systemcontroller(VAR_6);\n        break;\n\n    case VAR_34:\n        VAR_2 = domain_unpause_by_systemcontroller(VAR_6);\n        break;\n\n    case VAR_35:\n        if ( VAR_6 == VAR_28->domain ) /* COMMENT_1 */\n            VAR_2 = -VAR_27;\n        else\n            domain_resume(VAR_6);\n        break;\n\n    case VAR_18:\n    {\n        domid_t        VAR_36;\n        static domid_t VAR_37 = 0;\n\n        VAR_36 = VAR_5->domain;\n        if ( (VAR_36 > 0) && (VAR_36 < VAR_38) )\n        {\n            VAR_2 = -VAR_39;\n            if ( !is_free_domid(VAR_36) )\n                break;\n        }\n        else\n        {\n            for ( VAR_36 = VAR_37 + 1; VAR_36 != VAR_37; VAR_36++ )\n            {\n                if ( VAR_36 == VAR_38 )\n                    VAR_36 = 1;\n                if ( is_free_domid(VAR_36) )\n                    break;\n            }\n\n            VAR_2 = -VAR_31;\n            if ( VAR_36 == VAR_37 )\n                break;\n\n            VAR_37 = VAR_36;\n        }\n\n        VAR_6 = domain_create(VAR_36, &VAR_5->u.createdomain, false);\n        if ( IS_ERR(VAR_6) )\n        {\n            VAR_2 = PTR_ERR(VAR_6);\n            VAR_6 = NULL;\n            break;\n        }\n\n        VAR_2 = 0;\n        VAR_5->domain = VAR_6->domain_id;\n        VAR_3 = 1;\n        VAR_6 = NULL;\n        break;\n    }\n\n    case VAR_40:\n    {\n        unsigned int VAR_41, VAR_42 = VAR_5->u.max_vcpus.max;\n\n        VAR_2 = -VAR_27;\n        if ( (VAR_6 == VAR_28->domain) || /* COMMENT_1 */\n             (VAR_42 != VAR_6->max_vcpus) )   /* COMMENT_2 */\n            break;\n\n        /* COMMENT_3 */\n        domain_pause(VAR_6);\n\n        VAR_2 = -VAR_31;\n\n        for ( VAR_41 = 0; VAR_41 < VAR_42; VAR_41++ )\n        {\n            if ( VAR_6->vcpu[VAR_41] != NULL )\n                continue;\n\n            if ( vcpu_create(VAR_6, VAR_41) == NULL )\n                goto maxvcpu_out;\n        }\n\n        domain_update_node_affinity(VAR_6);\n        VAR_2 = 0;\n\n    maxvcpu_out:\n        domain_unpause(VAR_6);\n        break;\n    }\n\n    case VAR_43:\n    case VAR_44:\n        if ( VAR_6 == VAR_28->domain ) /* COMMENT_1 */\n        {\n            VAR_2 = -VAR_27;\n            break;\n        }\n        VAR_2 = domain_soft_reset(VAR_6, VAR_5->cmd == VAR_44);\n        if ( VAR_2 == -VAR_29 )\n        {\n            VAR_5->cmd = VAR_44;\n            if ( !__copy_field_to_guest(VAR_1, VAR_5, VAR_45) )\n                VAR_2 = hypercall_create_continuation(VAR_22,\n                                                    \"h\", VAR_1);\n            else\n                VAR_2 = -VAR_7;\n        }\n        break;\n\n    case VAR_46:\n        domctl_lock_release();\n        domain_lock(VAR_6);\n        VAR_2 = domain_kill(VAR_6);\n        domain_unlock(VAR_6);\n        if ( VAR_2 == -VAR_29 )\n            VAR_2 = hypercall_create_continuation(\n                VAR_22, \"h\", VAR_1);\n        goto domctl_out_unlock_domonly;\n\n    case VAR_47:\n    {\n        nodemask_t VAR_48;\n\n        VAR_2 = xenctl_bitmap_to_nodemask(&VAR_48,\n                                        &VAR_5->u.nodeaffinity.nodemap);\n        if ( !VAR_2 )\n            VAR_2 = domain_set_node_affinity(VAR_6, &VAR_48);\n        break;\n    }\n\n    case VAR_49:\n        VAR_2 = nodemask_to_xenctl_bitmap(&VAR_5->u.nodeaffinity.nodemap,\n                                        &VAR_6->node_affinity);\n        break;\n\n    case VAR_50:\n    case VAR_51:\n        VAR_2 = vcpu_affinity_domctl(VAR_6, VAR_5->cmd, &VAR_5->u.vcpuaffinity);\n        break;\n\n    case VAR_52:\n        VAR_2 = sched_adjust(VAR_6, &VAR_5->u.scheduler_op);\n        VAR_3 = 1;\n        break;\n\n    case VAR_20:\n    {\n        domid_t VAR_36 = VAR_14;\n\n        if ( !VAR_6 )\n        {\n            VAR_2 = -VAR_27;\n            if ( VAR_5->domain >= VAR_38 )\n                break;\n\n            rcu_read_lock(&VAR_53);\n\n            VAR_36 = VAR_5->domain;\n            VAR_54 ( d )\n                if ( d->VAR_55 >= VAR_36 )\n                    break;\n        }\n\n        VAR_2 = -VAR_15;\n        if ( d == NULL )\n            goto getdomaininfo_out;\n\n        VAR_2 = xsm_getdomaininfo(VAR_56, d);\n        if ( VAR_2 )\n            goto getdomaininfo_out;\n\n        getdomaininfo(d, &VAR_5->u.getdomaininfo);\n\n        VAR_5->domain = VAR_5->u.getdomaininfo.domain;\n        VAR_3 = 1;\n\n    getdomaininfo_out:\n        /* COMMENT_4 */\n        if ( VAR_36 == VAR_14 )\n            break;\n\n        rcu_read_unlock(&VAR_53);\n        d = NULL;\n        break;\n    }\n\n    case VAR_57:\n    {\n        vcpu_guest_context_u VAR_24 = { .nat = NULL };\n        struct vcpu         *VAR_26;\n\n        VAR_2 = -VAR_27;\n        if ( VAR_5->u.vcpucontext.vcpu >= d->max_vcpus ||\n             (VAR_26 = d->vcpu[VAR_5->u.vcpucontext.vcpu]) == NULL ||\n             VAR_26 == VAR_28 ) /* COMMENT_5 */\n            goto getvcpucontext_out;\n\n        VAR_2 = -VAR_58;\n        if ( !VAR_26->is_initialised )\n            goto getvcpucontext_out;\n\n#ifdef VAR_30\n        BUILD_BUG_ON(sizeof(struct vcpu_guest_context)\n                     < sizeof(struct compat_vcpu_guest_context));\n#endif\n        VAR_2 = -VAR_31;\n        if ( (VAR_24.nat = xzalloc(struct vcpu_guest_context)) == NULL )\n            goto getvcpucontext_out;\n\n        vcpu_pause(VAR_26);\n\n        arch_get_info_guest(VAR_26, VAR_24);\n        VAR_2 = 0;\n\n        vcpu_unpause(VAR_26);\n\n#ifdef VAR_30\n        if ( !is_pv_32bit_domain(d) )\n            VAR_2 = copy_to_guest(VAR_5->u.vcpucontext.ctxt, VAR_24.nat, 1);\n        else\n            VAR_2 = copy_to_guest(guest_handle_cast(VAR_5->u.vcpucontext.ctxt,\n                                                  VAR_32), VAR_24.cmp, 1);\n#else\n        VAR_2 = copy_to_guest(VAR_5->u.vcpucontext.ctxt, VAR_24.nat, 1);\n#endif\n\n        if ( VAR_2 )\n            VAR_2 = -VAR_7;\n        VAR_3 = 1;\n\n    getvcpucontext_out:\n        xfree(VAR_24.nat);\n        break;\n    }\n\n    case VAR_59:\n    {\n        struct vcpu   *VAR_26;\n        struct vcpu_runstate_info VAR_60;\n\n        VAR_2 = -VAR_27;\n        if ( VAR_5->u.getvcpuinfo.vcpu >= d->max_vcpus )\n            break;\n\n        VAR_2 = -VAR_15;\n        if ( (VAR_26 = d->vcpu[VAR_5->u.getvcpuinfo.vcpu]) == NULL )\n            break;\n\n        vcpu_runstate_get(VAR_26, &VAR_60);\n\n        VAR_5->u.getvcpuinfo.online   = !(VAR_26->pause_flags & VAR_61);\n        VAR_5->u.getvcpuinfo.blocked  = !!(VAR_26->pause_flags & VAR_62);\n        VAR_5->u.getvcpuinfo.running  = VAR_26->is_running;\n        VAR_5->u.getvcpuinfo.cpu_time = VAR_60.time[VAR_63];\n        VAR_5->u.getvcpuinfo.cpu      = VAR_26->processor;\n        VAR_2 = 0;\n        VAR_3 = 1;\n        break;\n    }\n\n    case VAR_64:\n    {\n        uint64_t VAR_65 = VAR_5->u.max_mem.max_memkb >> (VAR_66 - 10);\n\n        spin_lock(&d->page_alloc_lock);\n        /* COMMENT_6 */\n                                                                               \n                                                                               \n                                                                             \n           \n        d->max_pages = min(VAR_65, (uint64_t)(typeof(d->max_pages))-1);\n        spin_unlock(&d->page_alloc_lock);\n        break;\n    }\n\n    case VAR_67:\n        memcpy(d->handle, VAR_5->u.setdomainhandle.handle,\n               sizeof(VAR_68));\n        break;\n\n    case VAR_69:\n        if ( unlikely(d == VAR_28->domain) ) /* COMMENT_1 */\n            VAR_2 = -VAR_27;\n        else\n        {\n            domain_pause(d);\n            d->debugger_attached = !!VAR_5->u.setdebugging.enable;\n            domain_unpause(d); /* COMMENT_11 */\n        }\n        break;\n\n    case VAR_70:\n    {\n        unsigned int VAR_71 = VAR_5->u.irq_permission.pirq, VAR_72;\n        int VAR_73 = VAR_5->u.irq_permission.allow_access;\n\n        if ( VAR_71 >= VAR_28->domain->nr_pirqs )\n        {\n            VAR_2 = -VAR_27;\n            break;\n        }\n        VAR_72 = pirq_access_permitted(VAR_28->domain, VAR_71);\n        if ( !VAR_72 || xsm_irq_permission(VAR_56, d, VAR_72, VAR_73) )\n            VAR_2 = -VAR_74;\n        else if ( VAR_73 )\n            VAR_2 = irq_permit_access(d, VAR_72);\n        else\n            VAR_2 = irq_deny_access(d, VAR_72);\n        break;\n    }\n\n    case VAR_75:\n    {\n        unsigned long VAR_76 = VAR_5->u.iomem_permission.first_mfn;\n        unsigned long VAR_77 = VAR_5->u.iomem_permission.nr_mfns;\n        int VAR_73 = VAR_5->u.iomem_permission.allow_access;\n\n        VAR_2 = -VAR_27;\n        if ( (VAR_76 + VAR_77 - 1) < VAR_76 ) /* COMMENT_12 */\n            break;\n\n        if ( !iomem_access_permitted(VAR_28->domain,\n                                     VAR_76, VAR_76 + VAR_77 - 1) ||\n             xsm_iomem_permission(VAR_56, d, VAR_76, VAR_76 + VAR_77 - 1, VAR_73) )\n            VAR_2 = -VAR_74;\n        else if ( VAR_73 )\n            VAR_2 = iomem_permit_access(d, VAR_76, VAR_76 + VAR_77 - 1);\n        else\n            VAR_2 = iomem_deny_access(d, VAR_76, VAR_76 + VAR_77 - 1);\n        if ( !VAR_2 )\n            memory_type_changed(d);\n        break;\n    }\n\n    case VAR_78:\n    {\n        unsigned long VAR_79 = VAR_5->u.memory_mapping.first_gfn;\n        unsigned long VAR_76 = VAR_5->u.memory_mapping.first_mfn;\n        unsigned long VAR_77 = VAR_5->u.memory_mapping.nr_mfns;\n        unsigned long VAR_80 = VAR_76 + VAR_77 - 1;\n        int VAR_81 = VAR_5->u.memory_mapping.add_mapping;\n\n        VAR_2 = -VAR_27;\n        if ( VAR_80 < VAR_76 || /* COMMENT_12 */\n             ((VAR_76 | VAR_80) >> (VAR_82 - VAR_66)) ||\n             (VAR_79 + VAR_77 - 1) < VAR_79 ) /* COMMENT_12 */\n            break;\n\n#ifndef VAR_83 /* COMMENT_13 */\n        VAR_2 = -VAR_84;\n        /* COMMENT_14 */\n        if ( VAR_77 > 64 )\n            break;\n#endif\n\n        VAR_2 = -VAR_74;\n        if ( !iomem_access_permitted(VAR_28->domain, VAR_76, VAR_80) ||\n             !iomem_access_permitted(d, VAR_76, VAR_80) )\n            break;\n\n        VAR_2 = xsm_iomem_mapping(VAR_56, d, VAR_76, VAR_80, VAR_81);\n        if ( VAR_2 )\n            break;\n\n        if ( VAR_81 )\n        {\n            VAR_85(VAR_86\n                   \"memory_map:add: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, VAR_79, VAR_76, VAR_77);\n\n            VAR_2 = map_mmio_regions(d, _gfn(VAR_79), VAR_77, _mfn(VAR_76));\n            if ( VAR_2 < 0 )\n                VAR_85(XENLOG_G_WARNING\n                       \"memory_map:fail: dom%d gfn=%lx mfn=%lx nr=%lx ret:%ld\\n\",\n                       d->domain_id, VAR_79, VAR_76, VAR_77, VAR_2);\n        }\n        else\n        {\n            VAR_85(VAR_86\n                   \"memory_map:remove: dom%d gfn=%lx mfn=%lx nr=%lx\\n\",\n                   d->domain_id, VAR_79, VAR_76, VAR_77);\n\n            VAR_2 = unmap_mmio_regions(d, _gfn(VAR_79), VAR_77, _mfn(VAR_76));\n            if ( VAR_2 < 0 && is_hardware_domain(VAR_28->domain) )\n                VAR_85(XENLOG_ERR\n                       \"memory_map: error %ld removing dom%d access to [%lx,%lx]\\n\",\n                       VAR_2, d->domain_id, VAR_76, VAR_80);\n        }\n        /* COMMENT_15 */\n        memory_type_changed(d);\n        break;\n    }\n\n    case VAR_87:\n        domain_set_time_offset(d, VAR_5->u.settimeoffset.time_offset_seconds);\n        break;\n\n    case VAR_88:\n    {\n        struct domain *VAR_89;\n\n        VAR_2 = -VAR_15;\n        VAR_89 = get_domain_by_id(VAR_5->u.set_target.target);\n        if ( VAR_89 == NULL )\n            break;\n\n        VAR_2 = -VAR_27;\n        if ( (d == VAR_89) || (d->target != NULL) )\n        {\n            put_domain(VAR_89);\n            break;\n        }\n\n        VAR_2 = -VAR_90;\n        if ( is_hvm_domain(VAR_89) )\n            VAR_2 = xsm_set_target(VAR_56, d, VAR_89);\n        if ( VAR_2 )\n        {\n            put_domain(VAR_89);\n            break;\n        }\n\n        /* COMMENT_16 */\n        d->target = VAR_89;\n        break;\n    }\n\n    case VAR_91:\n        d->suspend_evtchn = VAR_5->u.subscribe.port;\n        break;\n\n    case VAR_17:\n        VAR_2 = vm_event_domctl(d, &VAR_5->u.vm_event_op);\n        if ( VAR_2 == 0 )\n            VAR_3 = true;\n        break;\n\n#ifdef VAR_92\n    case VAR_93:\n        if ( unlikely(VAR_28->domain == d) ) /* COMMENT_1 */\n            VAR_2 = -VAR_74;\n        else\n        {\n            domain_pause(d);\n            arch_p2m_set_access_required(d,\n                VAR_5->u.access_required.access_required);\n            domain_unpause(d);\n        }\n        break;\n#endif\n\n    case VAR_94:\n        VAR_2 = set_global_virq_handler(d, VAR_5->u.set_virq_handler.virq);\n        break;\n\n    case VAR_95:\n    {\n        struct vnuma_info *VAR_96;\n\n        VAR_96 = vnuma_init(&VAR_5->u.vnuma, d);\n        if ( IS_ERR(VAR_96) )\n        {\n            VAR_2 = PTR_ERR(VAR_96);\n            break;\n        }\n\n        /* COMMENT_17 */\n        write_lock(&d->vnuma_rwlock);\n        vnuma_destroy(d->vnuma);\n        d->vnuma = VAR_96;\n        write_unlock(&d->vnuma_rwlock);\n\n        break;\n    }\n\n    case VAR_97:\n        VAR_2 = monitor_domctl(d, &VAR_5->u.monitor_op);\n        if ( !VAR_2 )\n            VAR_3 = 1;\n        break;\n\n    default:\n        VAR_2 = arch_do_domctl(VAR_5, d, VAR_1);\n        break;\n    }\n\n    domctl_lock_release();\n\n domctl_out_unlock_domonly:\n    if ( d && d != VAR_13 )\n        rcu_unlock_domain(d);\n\n    if ( VAR_3 && __copy_to_guest(VAR_1, VAR_5, 1) )\n        VAR_2 = -VAR_7;\n\n    return VAR_2;\n}",
    "func_graph_path": null,
    "diff_func": "--- func_before\n+++ func_after\n@@ -202,12 +202,22 @@\n     }\n \n     case XEN_DOMCTL_soft_reset:\n+    case XEN_DOMCTL_soft_reset_cont:\n         if ( d == current->domain ) /* no domain_pause() */\n         {\n             ret = -EINVAL;\n             break;\n         }\n-        ret = domain_soft_reset(d);\n+        ret = domain_soft_reset(d, op->cmd == XEN_DOMCTL_soft_reset_cont);\n+        if ( ret == -ERESTART )\n+        {\n+            op->cmd = XEN_DOMCTL_soft_reset_cont;\n+            if ( !__copy_field_to_guest(u_domctl, op, cmd) )\n+                ret = hypercall_create_continuation(__HYPERVISOR_domctl,\n+                                                    \"h\", u_domctl);\n+            else\n+                ret = -EFAULT;\n+        }\n         break;\n \n     case XEN_DOMCTL_destroydomain:",
    "diff_line_info": {
        "deleted_lines": [
            "        ret = domain_soft_reset(d);"
        ],
        "added_lines": [
            "    case XEN_DOMCTL_soft_reset_cont:",
            "        ret = domain_soft_reset(d, op->cmd == XEN_DOMCTL_soft_reset_cont);",
            "        if ( ret == -ERESTART )",
            "        {",
            "            op->cmd = XEN_DOMCTL_soft_reset_cont;",
            "            if ( !__copy_field_to_guest(u_domctl, op, cmd) )",
            "                ret = hypercall_create_continuation(__HYPERVISOR_domctl,",
            "                                                    \"h\", u_domctl);",
            "            else",
            "                ret = -EFAULT;",
            "        }"
        ]
    },
    "is_vul": true,
    "pr_url": null,
    "description": "no more info"
}