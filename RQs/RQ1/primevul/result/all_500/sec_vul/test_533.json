{
  "id": 533,
  "language": "cc",
  "cwe": "",
  "commit_url": "https://github.com/ASP22SCM22S/REPO7TENSOEFLOW/commit/e21af685e1828f7ca65038307df5cc06de4479e8",
  "commit_sha": "e21af685e1828f7ca65038307df5cc06de4479e8",
  "commit_msg": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be",
  "pr_url": null,
  "pr_info": null,
  "file_name": "tensorflow/compiler/jit/xla_platform_info.cc",
  "func_name": "",
  "raw_func_from_json": "Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n                                const XlaPlatformInfo& platform_info,\n                                XlaCompilationCache** cache) {\n  if (platform_info.xla_device_metadata()) {\n    *cache = new XlaCompilationCache(\n        platform_info.xla_device_metadata()->client(),\n        platform_info.xla_device_metadata()->jit_device_type());\n    return Status::OK();\n  }\n\n  auto platform =\n      se::MultiPlatformManager::PlatformWithId(platform_info.platform_id());\n  if (!platform.ok()) {\n    return platform.status();\n  }\n\n  StatusOr<xla::Compiler*> compiler_for_platform =\n      xla::Compiler::GetForPlatform(platform.ValueOrDie());\n  if (!compiler_for_platform.ok()) {\n    // In some rare cases (usually in unit tests with very small clusters) we\n    // may end up transforming an XLA cluster with at least one GPU operation\n    // (which would normally force the cluster to be compiled using XLA:GPU)\n    // into an XLA cluster with no GPU operations (i.e. containing only CPU\n    // operations).  Such a cluster can fail compilation (in way that\n    // MarkForCompilation could not have detected) if the CPU JIT is not linked\n    // in.\n    //\n    // So bail out of _XlaCompile in this case, and let the executor handle the\n    // situation for us.\n    const Status& status = compiler_for_platform.status();\n    if (status.code() == error::NOT_FOUND) {\n      return errors::Unimplemented(\"Could not find compiler for platform \",\n                                   platform.ValueOrDie()->Name(), \": \",\n                                   status.ToString());\n    }\n  }\n\n  xla::LocalClientOptions client_options;\n  client_options.set_platform(platform.ValueOrDie());\n  client_options.set_intra_op_parallelism_threads(\n      device->tensorflow_cpu_worker_threads()->num_threads);\n\n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n                      ParseVisibleDeviceList(allowed_gpus));\n  client_options.set_allowed_devices(gpu_ids);\n\n  auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n  if (!client.ok()) {\n    return client.status();\n  }\n  const XlaOpRegistry::DeviceRegistration* registration;\n  if (!XlaOpRegistry::GetCompilationDevice(platform_info.device_type().type(),\n                                           &registration)) {\n    return errors::InvalidArgument(\"No JIT device registered for \",\n                                   platform_info.device_type().type());\n  }\n  *cache = new XlaCompilationCache(\n      client.ValueOrDie(), DeviceType(registration->compilation_device_name));\n  return Status::OK();\n}",
  "diff_func": "@@ -82,11 +82,13 @@ Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n   client_options.set_intra_op_parallelism_threads(\n       device->tensorflow_cpu_worker_threads()->num_threads);\n \n-  string allowed_gpus =\n-      flr->config_proto()->gpu_options().visible_device_list();\n-  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n-                      ParseVisibleDeviceList(allowed_gpus));\n-  client_options.set_allowed_devices(gpu_ids);\n+  if (flr->config_proto()) {\n+    string allowed_gpus =\n+        flr->config_proto()->gpu_options().visible_device_list();\n+    TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n+                        ParseVisibleDeviceList(allowed_gpus));\n+    client_options.set_allowed_devices(gpu_ids);\n+  }\n \n   auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n   if (!client.ok()) {",
  "func": "Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n                                const XlaPlatformInfo& platform_info,\n                                XlaCompilationCache** cache) {\n  if (platform_info.xla_device_metadata()) {\n    *cache = new XlaCompilationCache(\n        platform_info.xla_device_metadata()->client(),\n        platform_info.xla_device_metadata()->jit_device_type());\n    return Status::OK();\n  }\n\n  auto platform =\n      se::MultiPlatformManager::PlatformWithId(platform_info.platform_id());\n  if (!platform.ok()) {\n    return platform.status();\n  }\n\n  StatusOr<xla::Compiler*> compiler_for_platform =\n      xla::Compiler::GetForPlatform(platform.ValueOrDie());\n  if (!compiler_for_platform.ok()) {\n    // In some rare cases (usually in unit tests with very small clusters) we\n    // may end up transforming an XLA cluster with at least one GPU operation\n    // (which would normally force the cluster to be compiled using XLA:GPU)\n    // into an XLA cluster with no GPU operations (i.e. containing only CPU\n    // operations).  Such a cluster can fail compilation (in way that\n    // MarkForCompilation could not have detected) if the CPU JIT is not linked\n    // in.\n    //\n    // So bail out of _XlaCompile in this case, and let the executor handle the\n    // situation for us.\n    const Status& status = compiler_for_platform.status();\n    if (status.code() == error::NOT_FOUND) {\n      return errors::Unimplemented(\"Could not find compiler for platform \",\n                                   platform.ValueOrDie()->Name(), \": \",\n                                   status.ToString());\n    }\n  }\n\n  xla::LocalClientOptions client_options;\n  client_options.set_platform(platform.ValueOrDie());\n  client_options.set_intra_op_parallelism_threads(\n      device->tensorflow_cpu_worker_threads()->num_threads);\n\n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n                      ParseVisibleDeviceList(allowed_gpus));\n  client_options.set_allowed_devices(gpu_ids);\n\n  auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n  if (!client.ok()) {\n    return client.status();\n  }\n  const XlaOpRegistry::DeviceRegistration* registration;\n  if (!XlaOpRegistry::GetCompilationDevice(platform_info.device_type().type(),\n                                           &registration)) {\n    return errors::InvalidArgument(\"No JIT device registered for \",\n                                   platform_info.device_type().type());\n  }\n  *cache = new XlaCompilationCache(\n      client.ValueOrDie(), DeviceType(registration->compilation_device_name));\n  return Status::OK();\n}",
  "project": "tensorflow",
  "hash": 186510393432452834538936646068986071997,
  "size": 62,
  "commit_id": "e21af685e1828f7ca65038307df5cc06de4479e8",
  "message": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be",
  "target": 1,
  "dataset": "other",
  "idx": 195040,
  "Bug Filter": "Security Vulnerability Fix\n\nConfidence Score: 0.95\n\n**Step-by-Step Explanation:**\n\n1. **Patch Analysis**: The code change introduces a null check to prevent dereferencing a null pointer, which could cause a crash.\n\n2. **Security Assessment**: The fix addresses a null pointer dereference, a common security issue that can lead to crashes (DoS) or potential exploitation.\n\n3. **Classification**: The patch resolves a security vulnerability by preventing unauthorized access to a null pointer, affecting system availability.\n\n4. **Confidence**: High confidence due to clear code evidence of a security fix.",
  "Bug Filter Confidence": 0.95,
  "Bug Filter Response": "\n\n**Final Output:**\n\nAnalysis: Step 1: The patch addresses a null pointer dereference in BuildXlaCompilationCache by adding a null check before accessing gpu_options(). This prevents a crash when ConfigProto is not used, which could be triggered by an attacker, leading to a DoS.\n\nFinal Classification: Security Vulnerability Fix\n\nConfidence Score: 0.95\n\n**Step-by-Step Explanation:**\n\n1. **Patch Analysis**: The code change introduces a null check to prevent dereferencing a null pointer, which could cause a crash.\n\n2. **Security Assessment**: The fix addresses a null pointer dereference, a common security issue that can lead to crashes (DoS) or potential exploitation.\n\n3. **Classification**: The patch resolves a security vulnerability by preventing unauthorized access to a null pointer, affecting system availability.\n\n4. **Confidence**: High confidence due to clear code evidence of a security fix."
}