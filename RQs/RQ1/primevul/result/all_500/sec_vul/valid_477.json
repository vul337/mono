{
  "id": 477,
  "language": "cc",
  "cwe": "",
  "commit_url": "https://github.com/prividentity/tensorflow/commit/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7",
  "commit_sha": "a74768f8e4efbda4def9f16ee7e13cf3922ac5f7",
  "commit_msg": "Prevent heap OOB error in `MaxPoolGrad`\n\nPiperOrigin-RevId: 372424854\nChange-Id: Idac0f23867ad8b0601cafbaaa52d5e64269e63a7",
  "pr_url": null,
  "pr_info": null,
  "file_name": "tensorflow/core/kernels/maxpooling_op.cc",
  "func_name": "",
  "raw_func_from_json": "static void SpatialMaxPoolWithArgMaxHelper(\n    OpKernelContext* context, Tensor* output, Tensor* output_arg_max,\n    Tensor* input_backprop, const Tensor& tensor_in, const Tensor& out_backprop,\n    const PoolParameters& params, const bool include_batch_in_index) {\n  if (input_backprop != nullptr) {\n    OP_REQUIRES(\n        context, include_batch_in_index,\n        errors::Internal(\n            \"SpatialMaxPoolWithArgMaxHelper requires include_batch_in_index \"\n            \"to be True when input_backprop != nullptr\"));\n    OP_REQUIRES(\n        context, (std::is_same<Targmax, int64>::value),\n        errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                         \"to be int64 when input_backprop != nullptr\"));\n  }\n\n  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      ConstEigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<Targmax, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenIndexMatrixMap;\n\n  ConstEigenMatrixMap in_mat(\n      tensor_in.flat<T>().data(), params.depth,\n      params.tensor_in_cols * params.tensor_in_rows * params.tensor_in_batch);\n  EigenMatrixMap out_mat(\n      output->flat<T>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n  EigenIndexMatrixMap out_arg_max_mat(\n      output_arg_max->flat<Targmax>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *(context->device()->tensorflow_cpu_worker_threads());\n\n  // The following code basically does the following:\n  // 1. Flattens the input and output tensors into two dimensional arrays.\n  //    tensor_in_as_matrix:\n  //      depth by (tensor_in_cols * tensor_in_rows * tensor_in_batch)\n  //    output_as_matrix:\n  //      depth by (out_width * out_height * tensor_in_batch)\n  //\n  // 2. Walks through the set of columns in the flattened tensor_in_as_matrix,\n  //    and updates the corresponding column(s) in output_as_matrix with the\n  //    max value.\n  auto shard = [&params, &in_mat, &out_mat, &out_arg_max_mat, &input_backprop,\n                &output_arg_max, &out_backprop,\n                include_batch_in_index](int64 start, int64 limit) {\n    const int32 depth = params.depth;\n    const int32 in_rows = params.tensor_in_rows;\n    const int32 in_cols = params.tensor_in_cols;\n    const int32 pad_top = params.pad_top;\n    const int32 pad_left = params.pad_left;\n    const int32 window_rows = params.window_rows;\n    const int32 window_cols = params.window_cols;\n    const int32 row_stride = params.row_stride;\n    const int32 col_stride = params.col_stride;\n    const int32 out_height = params.out_height;\n    const int32 out_width = params.out_width;\n\n    {\n      // Initializes the output tensor with MIN<T>.\n      const int32 output_image_size = out_height * out_width * depth;\n      EigenMatrixMap out_shard(out_mat.data() + start * output_image_size, 1,\n                               (limit - start) * output_image_size);\n      out_shard.setConstant(Eigen::NumTraits<T>::lowest());\n      EigenIndexMatrixMap out_arg_max_shard(\n          out_arg_max_mat.data() + start * output_image_size, 1,\n          (limit - start) * output_image_size);\n      out_arg_max_shard.setConstant(kInvalidMaxPoolingIndex);\n    }\n\n    for (int64 b = start; b < limit; ++b) {\n      for (int h = 0; h < in_rows; ++h) {\n        for (int w = 0; w < in_cols; ++w) {\n          // (h_start, h_end) * (w_start, w_end) is the range that the input\n          // vector projects to.\n          const int hpad = h + pad_top;\n          const int wpad = w + pad_left;\n          const int h_start =\n              (hpad < window_rows) ? 0 : (hpad - window_rows) / row_stride + 1;\n          const int h_end = std::min(hpad / row_stride + 1, out_height);\n          const int w_start =\n              (wpad < window_cols) ? 0 : (wpad - window_cols) / col_stride + 1;\n          const int w_end = std::min(wpad / col_stride + 1, out_width);\n          // compute elementwise max\n          const int64 in_index = (b * in_rows + h) * in_cols + w;\n          for (int ph = h_start; ph < h_end; ++ph) {\n            const int64 out_index_base = (b * out_height + ph) * out_width;\n            for (int pw = w_start; pw < w_end; ++pw) {\n              const int64 out_index = out_index_base + pw;\n              /// NOTES(zhengxq): not using the eigen matrix operation for\n              /// now.\n              for (int d = 0; d < depth; ++d) {\n                const T& input_ref = in_mat.coeffRef(d, in_index);\n                T& output_ref = out_mat.coeffRef(d, out_index);\n                Targmax& out_arg_max_ref =\n                    out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  if (include_batch_in_index) {\n                    out_arg_max_ref = in_index * depth + d;\n                  } else {\n                    out_arg_max_ref = (h * in_cols + w) * depth + d;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (input_backprop != nullptr) {\n      auto input_backprop_flat = input_backprop->flat<T>();\n      auto out_arg_max_flat = output_arg_max->flat<int64>();\n      auto out_backprop_flat = out_backprop.flat<T>();\n\n      // Initialize output to 0.\n      const int64 in_size = in_rows * in_cols * depth;\n      const int64 in_start = start * in_size;\n      const int64 in_end = limit * in_size;\n      EigenMatrixMap in_shard(input_backprop_flat.data() + in_start, 1,\n                              in_end - in_start);\n      in_shard.setConstant(T(0));\n\n      // Backpropagate.\n      const int out_size = out_height * out_width * depth;\n      const int out_start = start * out_size;\n      const int out_end = limit * out_size;\n      for (int index = out_start; index < out_end; ++index) {\n        int input_backprop_index = out_arg_max_flat(index);\n        // Although this check is in the inner loop, it is worth its value\n        // so we don't end up with memory corruptions. Our benchmark shows that\n        // the performance impact is quite small\n        // CHECK(input_backprop_index >= in_start && input_backprop_index <\n        // in_end)\n        FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\n        input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n      }\n    }\n  };\n\n  const int64 shard_cost = params.tensor_in_rows * params.tensor_in_cols *\n                           params.depth * params.window_rows *\n                           params.window_cols;\n  Shard(worker_threads.num_threads, worker_threads.workers,\n        params.tensor_in_batch, shard_cost, shard);\n}",
  "diff_func": "@@ -199,7 +199,9 @@ static void SpatialMaxPoolWithArgMaxHelper(\n         // CHECK(input_backprop_index >= in_start && input_backprop_index <\n         // in_end)\n         FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\n-        input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n+        if (index < out_backprop.NumElements()) {\n+          input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n+        }\n       }\n     }\n   };",
  "func": "static void SpatialMaxPoolWithArgMaxHelper(\n    OpKernelContext* context, Tensor* output, Tensor* output_arg_max,\n    Tensor* input_backprop, const Tensor& tensor_in, const Tensor& out_backprop,\n    const PoolParameters& params, const bool include_batch_in_index) {\n  if (input_backprop != nullptr) {\n    OP_REQUIRES(\n        context, include_batch_in_index,\n        errors::Internal(\n            \"SpatialMaxPoolWithArgMaxHelper requires include_batch_in_index \"\n            \"to be True when input_backprop != nullptr\"));\n    OP_REQUIRES(\n        context, (std::is_same<Targmax, int64>::value),\n        errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                         \"to be int64 when input_backprop != nullptr\"));\n  }\n\n  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      ConstEigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<Targmax, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenIndexMatrixMap;\n\n  ConstEigenMatrixMap in_mat(\n      tensor_in.flat<T>().data(), params.depth,\n      params.tensor_in_cols * params.tensor_in_rows * params.tensor_in_batch);\n  EigenMatrixMap out_mat(\n      output->flat<T>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n  EigenIndexMatrixMap out_arg_max_mat(\n      output_arg_max->flat<Targmax>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *(context->device()->tensorflow_cpu_worker_threads());\n\n  // The following code basically does the following:\n  // 1. Flattens the input and output tensors into two dimensional arrays.\n  //    tensor_in_as_matrix:\n  //      depth by (tensor_in_cols * tensor_in_rows * tensor_in_batch)\n  //    output_as_matrix:\n  //      depth by (out_width * out_height * tensor_in_batch)\n  //\n  // 2. Walks through the set of columns in the flattened tensor_in_as_matrix,\n  //    and updates the corresponding column(s) in output_as_matrix with the\n  //    max value.\n  auto shard = [&params, &in_mat, &out_mat, &out_arg_max_mat, &input_backprop,\n                &output_arg_max, &out_backprop,\n                include_batch_in_index](int64 start, int64 limit) {\n    const int32 depth = params.depth;\n    const int32 in_rows = params.tensor_in_rows;\n    const int32 in_cols = params.tensor_in_cols;\n    const int32 pad_top = params.pad_top;\n    const int32 pad_left = params.pad_left;\n    const int32 window_rows = params.window_rows;\n    const int32 window_cols = params.window_cols;\n    const int32 row_stride = params.row_stride;\n    const int32 col_stride = params.col_stride;\n    const int32 out_height = params.out_height;\n    const int32 out_width = params.out_width;\n\n    {\n      // Initializes the output tensor with MIN<T>.\n      const int32 output_image_size = out_height * out_width * depth;\n      EigenMatrixMap out_shard(out_mat.data() + start * output_image_size, 1,\n                               (limit - start) * output_image_size);\n      out_shard.setConstant(Eigen::NumTraits<T>::lowest());\n      EigenIndexMatrixMap out_arg_max_shard(\n          out_arg_max_mat.data() + start * output_image_size, 1,\n          (limit - start) * output_image_size);\n      out_arg_max_shard.setConstant(kInvalidMaxPoolingIndex);\n    }\n\n    for (int64 b = start; b < limit; ++b) {\n      for (int h = 0; h < in_rows; ++h) {\n        for (int w = 0; w < in_cols; ++w) {\n          // (h_start, h_end) * (w_start, w_end) is the range that the input\n          // vector projects to.\n          const int hpad = h + pad_top;\n          const int wpad = w + pad_left;\n          const int h_start =\n              (hpad < window_rows) ? 0 : (hpad - window_rows) / row_stride + 1;\n          const int h_end = std::min(hpad / row_stride + 1, out_height);\n          const int w_start =\n              (wpad < window_cols) ? 0 : (wpad - window_cols) / col_stride + 1;\n          const int w_end = std::min(wpad / col_stride + 1, out_width);\n          // compute elementwise max\n          const int64 in_index = (b * in_rows + h) * in_cols + w;\n          for (int ph = h_start; ph < h_end; ++ph) {\n            const int64 out_index_base = (b * out_height + ph) * out_width;\n            for (int pw = w_start; pw < w_end; ++pw) {\n              const int64 out_index = out_index_base + pw;\n              /// NOTES(zhengxq): not using the eigen matrix operation for\n              /// now.\n              for (int d = 0; d < depth; ++d) {\n                const T& input_ref = in_mat.coeffRef(d, in_index);\n                T& output_ref = out_mat.coeffRef(d, out_index);\n                Targmax& out_arg_max_ref =\n                    out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  if (include_batch_in_index) {\n                    out_arg_max_ref = in_index * depth + d;\n                  } else {\n                    out_arg_max_ref = (h * in_cols + w) * depth + d;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (input_backprop != nullptr) {\n      auto input_backprop_flat = input_backprop->flat<T>();\n      auto out_arg_max_flat = output_arg_max->flat<int64>();\n      auto out_backprop_flat = out_backprop.flat<T>();\n\n      // Initialize output to 0.\n      const int64 in_size = in_rows * in_cols * depth;\n      const int64 in_start = start * in_size;\n      const int64 in_end = limit * in_size;\n      EigenMatrixMap in_shard(input_backprop_flat.data() + in_start, 1,\n                              in_end - in_start);\n      in_shard.setConstant(T(0));\n\n      // Backpropagate.\n      const int out_size = out_height * out_width * depth;\n      const int out_start = start * out_size;\n      const int out_end = limit * out_size;\n      for (int index = out_start; index < out_end; ++index) {\n        int input_backprop_index = out_arg_max_flat(index);\n        // Although this check is in the inner loop, it is worth its value\n        // so we don't end up with memory corruptions. Our benchmark shows that\n        // the performance impact is quite small\n        // CHECK(input_backprop_index >= in_start && input_backprop_index <\n        // in_end)\n        FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\n        input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n      }\n    }\n  };\n\n  const int64 shard_cost = params.tensor_in_rows * params.tensor_in_cols *\n                           params.depth * params.window_rows *\n                           params.window_cols;\n  Shard(worker_threads.num_threads, worker_threads.workers,\n        params.tensor_in_batch, shard_cost, shard);\n}",
  "project": "tensorflow",
  "hash": 68179409679570044569453067278368921696,
  "size": 151,
  "commit_id": "a74768f8e4efbda4def9f16ee7e13cf3922ac5f7",
  "message": "Prevent heap OOB error in `MaxPoolGrad`\n\nPiperOrigin-RevId: 372424854\nChange-Id: Idac0f23867ad8b0601cafbaaa52d5e64269e63a7",
  "target": 1,
  "dataset": "other",
  "idx": 196935,
  "Bug Filter": "Security Vulnerability Fix\nConfidence Score: 0.9",
  "Bug Filter Confidence": 0.9,
  "Bug Filter Response": "\n\nThe patch addresses a heap out-of-bounds error in the `MaxPoolGrad` function by adding a bounds check. This prevents potential memory access issues that could lead to security vulnerabilities. The classification is based on the explicit fix for a security-related defect.\n\n**Final Output:**\nAnalysis: The patch adds a bounds check to prevent a heap out-of-bounds error, which is a security vulnerability. The code change ensures that memory access is within valid bounds, mitigating potential crashes or exploits.\nFinal Classification: Security Vulnerability Fix\nConfidence Score: 0.9"
}