{
  "id": 947,
  "language": "c",
  "cwe": "",
  "commit_url": "https://github.com/chipcraft-ic/toolchain-component-linux/commit/6d816e088c359866f9867057e04f244c608c42fe",
  "commit_sha": "6d816e088c359866f9867057e04f244c608c42fe",
  "commit_msg": "io_uring: hold 'ctx' reference around task_work queue + execute\n\nWe're holding the request reference, but we need to go one higher\nto ensure that the ctx remains valid after the request has finished.\nIf the ring is closed with pending task_work inflight, and the\ngiven io_kiocb finishes sync during issue, then we need a reference\nto the ring itself around the task_work execution cycle.\n\nCc: stable@vger.kernel.org # v5.7+\nReported-by: syzbot+9b260fc33297966f5a8e@syzkaller.appspotmail.com\nSigned-off-by: Jens Axboe <axboe@kernel.dk>",
  "pr_url": null,
  "pr_info": null,
  "file_name": "fs/io_uring.c",
  "func_name": "",
  "raw_func_from_json": "static void io_async_task_func(struct callback_head *cb)\n{\n\tstruct io_kiocb *req = container_of(cb, struct io_kiocb, task_work);\n\tstruct async_poll *apoll = req->apoll;\n\tstruct io_ring_ctx *ctx = req->ctx;\n\n\ttrace_io_uring_task_run(req->ctx, req->opcode, req->user_data);\n\n\tif (io_poll_rewait(req, &apoll->poll)) {\n\t\tspin_unlock_irq(&ctx->completion_lock);\n\t\treturn;\n\t}\n\n\t/* If req is still hashed, it cannot have been canceled. Don't check. */\n\tif (hash_hashed(&req->hash_node))\n\t\thash_del(&req->hash_node);\n\n\tio_poll_remove_double(req, apoll->double_poll);\n\tspin_unlock_irq(&ctx->completion_lock);\n\n\tif (!READ_ONCE(apoll->poll.canceled))\n\t\t__io_req_task_submit(req);\n\telse\n\t\t__io_req_task_cancel(req, -ECANCELED);\n\n\tkfree(apoll->double_poll);\n\tkfree(apoll);\n}",
  "diff_func": "@@ -1821,15 +1821,18 @@ static void __io_req_task_submit(struct io_kiocb *req)\n static void io_req_task_submit(struct callback_head *cb)\n {\n \tstruct io_kiocb *req = container_of(cb, struct io_kiocb, task_work);\n+\tstruct io_ring_ctx *ctx = req->ctx;\n \n \t__io_req_task_submit(req);\n+\tpercpu_ref_put(&ctx->refs);\n }\n \n static void io_req_task_queue(struct io_kiocb *req)\n {\n \tint ret;\n \n \tinit_task_work(&req->task_work, io_req_task_submit);\n+\tpercpu_ref_get(&req->ctx->refs);\n \n \tret = io_req_task_work_add(req, &req->task_work);\n \tif (unlikely(ret)) {\n@@ -2318,6 +2321,8 @@ static void io_rw_resubmit(struct callback_head *cb)\n \t\trefcount_inc(&req->refs);\n \t\tio_queue_async_work(req);\n \t}\n+\n+\tpercpu_ref_put(&ctx->refs);\n }\n #endif\n \n@@ -2330,6 +2335,8 @@ static bool io_rw_reissue(struct io_kiocb *req, long res)\n \t\treturn false;\n \n \tinit_task_work(&req->task_work, io_rw_resubmit);\n+\tpercpu_ref_get(&req->ctx->refs);\n+\n \tret = io_req_task_work_add(req, &req->task_work);\n \tif (!ret)\n \t\treturn true;\n@@ -3033,6 +3040,8 @@ static int io_async_buf_func(struct wait_queue_entry *wait, unsigned mode,\n \tlist_del_init(&wait->entry);\n \n \tinit_task_work(&req->task_work, io_req_task_submit);\n+\tpercpu_ref_get(&req->ctx->refs);\n+\n \t/* submit ref gets dropped, acquire a new one */\n \trefcount_inc(&req->refs);\n \tret = io_req_task_work_add(req, &req->task_work);\n@@ -4565,6 +4574,8 @@ static int __io_async_wake(struct io_kiocb *req, struct io_poll_iocb *poll,\n \n \treq->result = mask;\n \tinit_task_work(&req->task_work, func);\n+\tpercpu_ref_get(&req->ctx->refs);\n+\n \t/*\n \t * If this fails, then the task is exiting. When a task exits, the\n \t * work gets canceled, so just cancel this request as well instead\n@@ -4652,11 +4663,13 @@ static void io_poll_task_handler(struct io_kiocb *req, struct io_kiocb **nxt)\n static void io_poll_task_func(struct callback_head *cb)\n {\n \tstruct io_kiocb *req = container_of(cb, struct io_kiocb, task_work);\n+\tstruct io_ring_ctx *ctx = req->ctx;\n \tstruct io_kiocb *nxt = NULL;\n \n \tio_poll_task_handler(req, &nxt);\n \tif (nxt)\n \t\t__io_req_task_submit(nxt);\n+\tpercpu_ref_put(&ctx->refs);\n }\n \n static int io_poll_double_wake(struct wait_queue_entry *wait, unsigned mode,\n@@ -4752,6 +4765,7 @@ static void io_async_task_func(struct callback_head *cb)\n \n \tif (io_poll_rewait(req, &apoll->poll)) {\n \t\tspin_unlock_irq(&ctx->completion_lock);\n+\t\tpercpu_ref_put(&ctx->refs);\n \t\treturn;\n \t}\n \n@@ -4767,6 +4781,7 @@ static void io_async_task_func(struct callback_head *cb)\n \telse\n \t\t__io_req_task_cancel(req, -ECANCELED);\n \n+\tpercpu_ref_put(&ctx->refs);\n \tkfree(apoll->double_poll);\n \tkfree(apoll);\n }",
  "func": "static void io_async_task_func(struct callback_head *cb)\n{\n\tstruct io_kiocb *req = container_of(cb, struct io_kiocb, task_work);\n\tstruct async_poll *apoll = req->apoll;\n\tstruct io_ring_ctx *ctx = req->ctx;\n\n\ttrace_io_uring_task_run(req->ctx, req->opcode, req->user_data);\n\n\tif (io_poll_rewait(req, &apoll->poll)) {\n\t\tspin_unlock_irq(&ctx->completion_lock);\n\t\treturn;\n\t}\n\n\t/* If req is still hashed, it cannot have been canceled. Don't check. */\n\tif (hash_hashed(&req->hash_node))\n\t\thash_del(&req->hash_node);\n\n\tio_poll_remove_double(req, apoll->double_poll);\n\tspin_unlock_irq(&ctx->completion_lock);\n\n\tif (!READ_ONCE(apoll->poll.canceled))\n\t\t__io_req_task_submit(req);\n\telse\n\t\t__io_req_task_cancel(req, -ECANCELED);\n\n\tkfree(apoll->double_poll);\n\tkfree(apoll);\n}",
  "project": "linux",
  "hash": 73404555622332263956206411713115350167,
  "size": 28,
  "commit_id": "6d816e088c359866f9867057e04f244c608c42fe",
  "message": "io_uring: hold 'ctx' reference around task_work queue + execute\n\nWe're holding the request reference, but we need to go one higher\nto ensure that the ctx remains valid after the request has finished.\nIf the ring is closed with pending task_work inflight, and the\ngiven io_kiocb finishes sync during issue, then we need a reference\nto the ring itself around the task_work execution cycle.\n\nCc: stable@vger.kernel.org # v5.7+\nReported-by: syzbot+9b260fc33297966f5a8e@syzkaller.appspotmail.com\nSigned-off-by: Jens Axboe <axboe@kernel.dk>",
  "target": 1,
  "dataset": "other",
  "idx": 212266,
  "Bug Filter": "Security Vulnerability Fix\nConfidence Score: 0.95",
  "Bug Filter Confidence": 0.95,
  "Bug Filter Response": "\n\nThe patch addresses a reference-counting issue that could lead to a use-after-free vulnerability, ensuring the 'ctx' remains valid during task_work execution.\n\n**Final Output:**\nAnalysis: The patch adds reference counting around the 'ctx' structure to prevent a use-after-free scenario, which could lead to system instability or exploitation.\nFinal Classification: Security Vulnerability Fix\nConfidence Score: 0.95"
}