{
  "id": 455,
  "language": "cc",
  "cwe": "",
  "commit_url": "https://github.com/prividentity/tensorflow/commit/a776040a5e7ebf76eeb7eb923bf1ae417dd4d233",
  "commit_sha": "a776040a5e7ebf76eeb7eb923bf1ae417dd4d233",
  "commit_msg": "Disallow dims input of 0 in tf.raw_ops.UnravelIndex\n\nPiperOrigin-RevId: 384284198\nChange-Id: Ia1804ef1aec57b4d857ea507e6891bcccde18e9b",
  "pr_url": null,
  "pr_info": null,
  "file_name": "tensorflow/core/kernels/unravel_index_op.cc",
  "func_name": "",
  "raw_func_from_json": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices_tensor = ctx->input(0);\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(indices_tensor.shape()) ||\n                    TensorShapeUtils::IsScalar(indices_tensor.shape()),\n                errors::InvalidArgument(\n                    \"The indices can only be scalar or vector, got \\\"\",\n                    indices_tensor.shape().DebugString(), \"\\\"\"));\n\n    const Tensor& dims_tensor = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(dims_tensor.shape()),\n        errors::InvalidArgument(\"The indices can only be 1-D, got \\\"\",\n                                dims_tensor.shape().DebugString(), \"\\\"\"));\n\n    auto dims = dims_tensor.vec<Tidx>();\n\n    // Chek to make sure indices is not out of boundary\n    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n    Tidx dims_prod = dims_prod_eigen();\n    const Tidx* indices = indices_tensor.flat<Tidx>().data();\n    int64 size = indices_tensor.NumElements();\n    bool check = std::all_of(indices, indices + size,\n                             [&](Tidx index) { return index < dims_prod; });\n    OP_REQUIRES(ctx, check,\n                errors::InvalidArgument(\"index is out of bound as with dims\"));\n\n    Eigen::array<bool, 1> reverse({true});\n\n    Tensor strides_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_tensor));\n\n    auto strides = strides_tensor.vec<Tidx>();\n    strides = dims.reverse(reverse)\n                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)\n                  .reverse(reverse);\n\n    Tensor strides_shifted_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_shifted_tensor));\n\n    auto strides_shifted = strides_shifted_tensor.vec<Tidx>();\n    strides_shifted = dims.reverse(reverse)\n                          .scan(0, Eigen::internal::ProdReducer<Tidx>(), true)\n                          .reverse(reverse);\n\n    Tensor* output_tensor = nullptr;\n    if (TensorShapeUtils::IsScalar(indices_tensor.shape())) {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({dims_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->vec<Tidx>();\n\n      output = output.constant(indices_tensor.scalar<Tidx>()());\n      output = output.binaryExpr(strides, mod_op<Tidx>()) / strides_shifted;\n    } else {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0,\n                                    TensorShape({dims_tensor.NumElements(),\n                                                 indices_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->matrix<Tidx>();\n\n      Eigen::array<Eigen::Index, 2> reshape{\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1}};\n      Eigen::array<Eigen::Index, 2> bcast(\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())});\n      Eigen::array<Eigen::Index, 2> indices_reshape{\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())}};\n      Eigen::array<Eigen::Index, 2> indices_bcast(\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1});\n\n      output = indices_tensor.vec<Tidx>()\n                   .reshape(indices_reshape)\n                   .broadcast(indices_bcast);\n      output = output.binaryExpr(strides.reshape(reshape).broadcast(bcast),\n                                 mod_op<Tidx>()) /\n               strides_shifted.reshape(reshape).broadcast(bcast);\n    }\n  }",
  "diff_func": "@@ -53,6 +53,14 @@ class UnravelIndexOp : public OpKernel {\n                                 dims_tensor.shape().DebugString(), \"\\\"\"));\n \n     auto dims = dims_tensor.vec<Tidx>();\n+    // Make sure dims does not contain a zero\n+    for (int i = 0; i < dims.size(); i++) {\n+      OP_REQUIRES(\n+          ctx, dims(i) != 0,\n+          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n+                                  \"but dims contains zero at index \",\n+                                  i));\n+    }\n \n     // Chek to make sure indices is not out of boundary\n     Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();",
  "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices_tensor = ctx->input(0);\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(indices_tensor.shape()) ||\n                    TensorShapeUtils::IsScalar(indices_tensor.shape()),\n                errors::InvalidArgument(\n                    \"The indices can only be scalar or vector, got \\\"\",\n                    indices_tensor.shape().DebugString(), \"\\\"\"));\n\n    const Tensor& dims_tensor = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(dims_tensor.shape()),\n        errors::InvalidArgument(\"The indices can only be 1-D, got \\\"\",\n                                dims_tensor.shape().DebugString(), \"\\\"\"));\n\n    auto dims = dims_tensor.vec<Tidx>();\n\n    // Chek to make sure indices is not out of boundary\n    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n    Tidx dims_prod = dims_prod_eigen();\n    const Tidx* indices = indices_tensor.flat<Tidx>().data();\n    int64 size = indices_tensor.NumElements();\n    bool check = std::all_of(indices, indices + size,\n                             [&](Tidx index) { return index < dims_prod; });\n    OP_REQUIRES(ctx, check,\n                errors::InvalidArgument(\"index is out of bound as with dims\"));\n\n    Eigen::array<bool, 1> reverse({true});\n\n    Tensor strides_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_tensor));\n\n    auto strides = strides_tensor.vec<Tidx>();\n    strides = dims.reverse(reverse)\n                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)\n                  .reverse(reverse);\n\n    Tensor strides_shifted_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_shifted_tensor));\n\n    auto strides_shifted = strides_shifted_tensor.vec<Tidx>();\n    strides_shifted = dims.reverse(reverse)\n                          .scan(0, Eigen::internal::ProdReducer<Tidx>(), true)\n                          .reverse(reverse);\n\n    Tensor* output_tensor = nullptr;\n    if (TensorShapeUtils::IsScalar(indices_tensor.shape())) {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({dims_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->vec<Tidx>();\n\n      output = output.constant(indices_tensor.scalar<Tidx>()());\n      output = output.binaryExpr(strides, mod_op<Tidx>()) / strides_shifted;\n    } else {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0,\n                                    TensorShape({dims_tensor.NumElements(),\n                                                 indices_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->matrix<Tidx>();\n\n      Eigen::array<Eigen::Index, 2> reshape{\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1}};\n      Eigen::array<Eigen::Index, 2> bcast(\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())});\n      Eigen::array<Eigen::Index, 2> indices_reshape{\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())}};\n      Eigen::array<Eigen::Index, 2> indices_bcast(\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1});\n\n      output = indices_tensor.vec<Tidx>()\n                   .reshape(indices_reshape)\n                   .broadcast(indices_bcast);\n      output = output.binaryExpr(strides.reshape(reshape).broadcast(bcast),\n                                 mod_op<Tidx>()) /\n               strides_shifted.reshape(reshape).broadcast(bcast);\n    }\n  }",
  "project": "tensorflow",
  "hash": 264158770569740569963092041338700970996,
  "size": 87,
  "commit_id": "a776040a5e7ebf76eeb7eb923bf1ae417dd4d233",
  "message": "Disallow dims input of 0 in tf.raw_ops.UnravelIndex\n\nPiperOrigin-RevId: 384284198\nChange-Id: Ia1804ef1aec57b4d857ea507e6891bcccde18e9b",
  "target": 1,
  "dataset": "other",
  "idx": 196763
}