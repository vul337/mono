{
  "id": 1586,
  "language": "Java",
  "commit_url": "https://github.com/haraldk/TwelveMonkeys/commit/6840f31fa396cd07a94e84ab7cd78be2651de893",
  "commit_sha": "6840f31fa396cd07a94e84ab7cd78be2651de893",
  "commit_msg": "#712 Core: Fix possible OOM situation in new stream implementation\n\n(cherry picked from commit 8f5c1b409f0ea99de8d5a71204ccb426828a80e4)",
  "pr_url": null,
  "pr_info": "no more info",
  "file_name": "imageio/imageio-core/src/main/java/com/twelvemonkeys/imageio/stream/MemoryCache.java",
  "func_name": "IOException",
  "func_before": "byte[] fetchBlock() throws IOException {\n        long currPos = position;\n\n        long index = currPos / BLOCK_SIZE;\n\n        if (index >= Integer.MAX_VALUE) {\n            throw new IOException(\"Memory cache max size exceeded\");\n        }\n\n        while (index >= cache.size()) {\n            byte[] block;\n            try {\n                block = new byte[BLOCK_SIZE];\n            }\n            catch (OutOfMemoryError e) {\n                throw new IOException(\"No more memory for cache: \" + cache.size() * BLOCK_SIZE);\n            }\n\n            cache.add(block);\n            length += readBlock(block);\n        }\n\n        return cache.get((int) index);\n    }",
  "func_after": "byte[] fetchBlock() throws IOException {\n        long currPos = position;\n        long index = currPos / BLOCK_SIZE;\n\n        if (index >= Integer.MAX_VALUE) {\n            throw new IOException(\"Memory cache max size exceeded\");\n        }\n        if (index > maxBlock) {\n            return NULL_BLOCK;\n        }\n\n        while (index >= cache.size()) {\n            byte[] block;\n            try {\n                block = new byte[BLOCK_SIZE];\n            }\n            catch (OutOfMemoryError e) {\n                throw new IOException(\"No more memory for cache: \" + cache.size() * BLOCK_SIZE);\n            }\n\n            cache.add(block);\n            int bytesRead = readBlock(block);\n            length += bytesRead;\n\n            if (bytesRead < BLOCK_SIZE) {\n                // Last block, EOF found\n                maxBlock = (int) index;\n                return block;\n            }\n        }\n\n        return cache.get((int) index);\n    }",
  "diff_func": "--- func_before\n+++ func_after\n byte[] fetchBlock() throws IOException {\n         long currPos = position;\n-\n         long index = currPos / BLOCK_SIZE;\n \n         if (index >= Integer.MAX_VALUE) {\n             throw new IOException(\"Memory cache max size exceeded\");\n+        }\n+        if (index > maxBlock) {\n+            return NULL_BLOCK;\n         }\n \n         while (index >= cache.size()) {\n             byte[] block;\n             try {\n                 block = new byte[BLOCK_SIZE];\n             }\n             catch (OutOfMemoryError e) {\n                 throw new IOException(\"No more memory for cache: \" + cache.size() * BLOCK_SIZE);\n             }\n \n             cache.add(block);\n-            length += readBlock(block);\n+            int bytesRead = readBlock(block);\n+            length += bytesRead;\n+\n+            if (bytesRead < BLOCK_SIZE) {\n+                // Last block, EOF found\n+                maxBlock = (int) index;\n+                return block;\n+            }\n         }\n \n         return cache.get((int) index);\n     }",
  "diff_source": "custom",
  "Bug Filter": "Defect Remediation & Feature Upgrades",
  "Bug Filter Confidence": 0.85,
  "Bug Filter Response": "\n\n**Final Output:**\n\nAnalysis: The patch addresses a potential Out of Memory (OOM) issue by adding checks to prevent excessive memory usage in the stream implementation. It introduces `maxBlock` to track the end of the data stream and handles partial blocks to avoid unnecessary cache expansion. The changes aim to improve system stability by preventing resource exhaustion, which affects availability but not security.\n\nFinal Classification: Defect Remediation & Feature Upgrades\n\nConfidence Score: 0.85"
}