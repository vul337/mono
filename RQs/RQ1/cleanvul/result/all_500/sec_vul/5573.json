{
  "id": 5573,
  "language": "C/C++",
  "commit_url": "https://github.com/ClusterLabs/pacemaker/commit/d324e407c0e2695f405974d567d79eb91d0ee69a",
  "commit_sha": "d324e407c0e2695f405974d567d79eb91d0ee69a",
  "commit_msg": "High: pacemakerd vs. IPC/procfs confused deputy authenticity issue (4/4)\n\n[4/4: CPG users to be careful about now-more-probable rival processes]\n\nIn essence, this comes down to pacemaker confusing at-node CPG members\nwith effectively the only plausible to co-exist at particular node,\nwhich doesn't hold and asks for a wider reconciliation of this\nreality-check.\n\nHowever, in practical terms, since there are two factors lowering the\npriority of doing so:\n\n1/ possibly the only non-self-inflicted scenario is either that\n   some of the cluster stack processes fail -- this the problem\n   that shall rather be deferred to arranged node disarming/fencing\n   to stay on the safe side with 100% certainty, at the cost of\n   possibly long-lasting failover process at other nodes\n   (for other possibility, someone running some of these by accident\n   so they effectively become rival processes, it's like getting\n   hands cut when playing with a lawnmower in an unintended way)\n\n2/ for state tracking of the peer nodes, it may possibly cause troubles\n   in case the process observed as left wasn't the last for the\n   particular node, even if presumably just temporary, since the\n   situation may eventually resolve with imposed serialization of\n   the rival processes via API end-point singleton restriction (this\n   is also the most likely cause of why such non-final leave gets\n   observed in the first place), except in one case -- the legitimate\n   API end-point carrier won't possibly acknowledged as returned\n   by its peers, at least not immediately, unless it tries to join\n   anew, which verges on undefined behaviour (at least per corosync\n   documentation)\n\nwe make do just with a light code change so as to\n\n* limit 1/ some more with in-daemon self-check for pre-existing\n  end-point existence (this is to complement the checks already made in\n  the parent daemon prior to spawning new instances, only some moments\n  later; note that we don't have any lock file etc. mechanisms to\n  prevent parallel runs of the same daemons, and people could run these\n  on their own deliberation), and to\n\n* guard against the interferences from the rivals at the same node\n  per 2/ with ignoring their non-final leave messages altogether.\n\nNote that CPG at this point is already expected to be authenticity-safe.\n\nRegarding now-more-probable part, we actually traded the inherently racy\nprocfs scanning for something (exactly that singleton mentioned above)\nrather firm (and unfakeable), but we admittedly got lost track of\nprocesses that are after CPG membership (that is, another form of\na shared state) prior to (or in non-deterministic order allowing for\nthe same) carring about publishing the end-point.\n\nBig thanks is owed to Yan Gao of SUSE, for early discovery and reporting\nthis discrepancy arising from the earlier commits in the set.",
  "pr_url": "https://github.com/ClusterLabs/pacemaker/pull/1749",
  "pr_info": "See also:\r\nhttps://www.openwall.com/lists/oss-security/2019/04/17/1\r\n\r\nPeople are strongly suggested to get these patches in.",
  "file_name": "daemons/based/pacemaker-based.c",
  "func_name": "main",
  "func_before": "int\nmain(int argc, char **argv)\n{\n    int flag;\n    int rc = 0;\n    int index = 0;\n    int argerr = 0;\n    struct passwd *pwentry = NULL;\n\n    crm_log_preinit(NULL, argc, argv);\n    crm_set_options(NULL, \"[options]\",\n                    long_options, \"Daemon for storing and replicating the cluster configuration\");\n\n    crm_peer_init();\n\n    mainloop_add_signal(SIGTERM, cib_shutdown);\n    mainloop_add_signal(SIGPIPE, cib_enable_writes);\n\n    cib_writer = mainloop_add_trigger(G_PRIORITY_LOW, write_cib_contents, NULL);\n\n    while (1) {\n        flag = crm_get_option(argc, argv, &index);\n        if (flag == -1)\n            break;\n\n        switch (flag) {\n            case 'V':\n                crm_bump_log_level(argc, argv);\n                break;\n            case 's':\n                stand_alone = TRUE;\n                preserve_status = TRUE;\n                cib_writes_enabled = FALSE;\n\n                pwentry = getpwnam(CRM_DAEMON_USER);\n                CRM_CHECK(pwentry != NULL,\n                          crm_perror(LOG_ERR, \"Invalid uid (%s) specified\", CRM_DAEMON_USER);\n                          return CRM_EX_FATAL);\n\n                rc = setgid(pwentry->pw_gid);\n                if (rc < 0) {\n                    crm_perror(LOG_ERR, \"Could not set group to %d\", pwentry->pw_gid);\n                    return CRM_EX_FATAL;\n                }\n\n                rc = initgroups(CRM_DAEMON_USER, pwentry->pw_gid);\n                if (rc < 0) {\n                    crm_perror(LOG_ERR, \"Could not setup groups for user %d\", pwentry->pw_uid);\n                    return CRM_EX_FATAL;\n                }\n\n                rc = setuid(pwentry->pw_uid);\n                if (rc < 0) {\n                    crm_perror(LOG_ERR, \"Could not set user to %d\", pwentry->pw_uid);\n                    return CRM_EX_FATAL;\n                }\n                break;\n            case '?':          /* Help message */\n                crm_help(flag, CRM_EX_OK);\n                break;\n            case 'w':\n                cib_writes_enabled = TRUE;\n                break;\n            case 'r':\n                cib_root = optarg;\n                break;\n            case 'm':\n                cib_metadata();\n                return CRM_EX_OK;\n            default:\n                ++argerr;\n                break;\n        }\n    }\n    if (argc - optind == 1 && safe_str_eq(\"metadata\", argv[optind])) {\n        cib_metadata();\n        return CRM_EX_OK;\n    }\n\n    if (optind > argc) {\n        ++argerr;\n    }\n\n    if (argerr) {\n        crm_help('?', CRM_EX_USAGE);\n    }\n\n    crm_log_init(NULL, LOG_INFO, TRUE, FALSE, argc, argv, FALSE);\n\n    if (cib_root == NULL) {\n        cib_root = CRM_CONFIG_DIR;\n    } else {\n        crm_notice(\"Using custom config location: %s\", cib_root);\n    }\n\n    if (pcmk__daemon_can_write(cib_root, NULL) == FALSE) {\n        crm_err(\"Terminating due to bad permissions on %s\", cib_root);\n        fprintf(stderr, \"ERROR: Bad permissions on %s (see logs for details)\\n\",\n                cib_root);\n        fflush(stderr);\n        return CRM_EX_FATAL;\n    }\n\n    /* read local config file */\n    cib_init();\n\n    // This should not be reachable\n    CRM_CHECK(crm_hash_table_size(client_connections) == 0,\n              crm_warn(\"Not all clients gone at exit\"));\n    g_hash_table_foreach(client_connections, log_cib_client, NULL);\n    cib_cleanup();\n\n    crm_info(\"Done\");\n    return CRM_EX_OK;\n}",
  "func_after": "int\nmain(int argc, char **argv)\n{\n    int flag;\n    int rc = 0;\n    int index = 0;\n    int argerr = 0;\n    struct passwd *pwentry = NULL;\n    crm_ipc_t *old_instance = NULL;\n\n    crm_log_preinit(NULL, argc, argv);\n    crm_set_options(NULL, \"[options]\",\n                    long_options, \"Daemon for storing and replicating the cluster configuration\");\n\n    mainloop_add_signal(SIGTERM, cib_shutdown);\n    mainloop_add_signal(SIGPIPE, cib_enable_writes);\n\n    cib_writer = mainloop_add_trigger(G_PRIORITY_LOW, write_cib_contents, NULL);\n\n    while (1) {\n        flag = crm_get_option(argc, argv, &index);\n        if (flag == -1)\n            break;\n\n        switch (flag) {\n            case 'V':\n                crm_bump_log_level(argc, argv);\n                break;\n            case 's':\n                stand_alone = TRUE;\n                preserve_status = TRUE;\n                cib_writes_enabled = FALSE;\n\n                pwentry = getpwnam(CRM_DAEMON_USER);\n                CRM_CHECK(pwentry != NULL,\n                          crm_perror(LOG_ERR, \"Invalid uid (%s) specified\", CRM_DAEMON_USER);\n                          return CRM_EX_FATAL);\n\n                rc = setgid(pwentry->pw_gid);\n                if (rc < 0) {\n                    crm_perror(LOG_ERR, \"Could not set group to %d\", pwentry->pw_gid);\n                    return CRM_EX_FATAL;\n                }\n\n                rc = initgroups(CRM_DAEMON_USER, pwentry->pw_gid);\n                if (rc < 0) {\n                    crm_perror(LOG_ERR, \"Could not setup groups for user %d\", pwentry->pw_uid);\n                    return CRM_EX_FATAL;\n                }\n\n                rc = setuid(pwentry->pw_uid);\n                if (rc < 0) {\n                    crm_perror(LOG_ERR, \"Could not set user to %d\", pwentry->pw_uid);\n                    return CRM_EX_FATAL;\n                }\n                break;\n            case '?':          /* Help message */\n                crm_help(flag, CRM_EX_OK);\n                break;\n            case 'w':\n                cib_writes_enabled = TRUE;\n                break;\n            case 'r':\n                cib_root = optarg;\n                break;\n            case 'm':\n                cib_metadata();\n                return CRM_EX_OK;\n            default:\n                ++argerr;\n                break;\n        }\n    }\n    if (argc - optind == 1 && safe_str_eq(\"metadata\", argv[optind])) {\n        cib_metadata();\n        return CRM_EX_OK;\n    }\n\n    if (optind > argc) {\n        ++argerr;\n    }\n\n    if (argerr) {\n        crm_help('?', CRM_EX_USAGE);\n    }\n\n    crm_log_init(NULL, LOG_INFO, TRUE, FALSE, argc, argv, FALSE);\n\n    old_instance = crm_ipc_new(CIB_CHANNEL_RO, 0);\n    if (crm_ipc_connect(old_instance)) {\n        /* IPC end-point already up */\n        crm_ipc_close(old_instance);\n        crm_ipc_destroy(old_instance);\n        crm_err(\"pacemaker-based is already active, aborting startup\");\n        crm_exit(CRM_EX_OK);\n    } else {\n        /* not up or not authentic, we'll proceed either way */\n        crm_ipc_destroy(old_instance);\n        old_instance = NULL;\n    }\n\n    if (cib_root == NULL) {\n        cib_root = CRM_CONFIG_DIR;\n    } else {\n        crm_notice(\"Using custom config location: %s\", cib_root);\n    }\n\n    if (pcmk__daemon_can_write(cib_root, NULL) == FALSE) {\n        crm_err(\"Terminating due to bad permissions on %s\", cib_root);\n        fprintf(stderr, \"ERROR: Bad permissions on %s (see logs for details)\\n\",\n                cib_root);\n        fflush(stderr);\n        return CRM_EX_FATAL;\n    }\n\n    crm_peer_init();\n\n    /* read local config file */\n    cib_init();\n\n    // This should not be reachable\n    CRM_CHECK(crm_hash_table_size(client_connections) == 0,\n              crm_warn(\"Not all clients gone at exit\"));\n    g_hash_table_foreach(client_connections, log_cib_client, NULL);\n    cib_cleanup();\n\n    crm_info(\"Done\");\n    return CRM_EX_OK;\n}",
  "diff_func": "--- func_before\n+++ func_after\n int\n main(int argc, char **argv)\n {\n     int flag;\n     int rc = 0;\n     int index = 0;\n     int argerr = 0;\n     struct passwd *pwentry = NULL;\n+    crm_ipc_t *old_instance = NULL;\n \n     crm_log_preinit(NULL, argc, argv);\n     crm_set_options(NULL, \"[options]\",\n                     long_options, \"Daemon for storing and replicating the cluster configuration\");\n-\n-    crm_peer_init();\n \n     mainloop_add_signal(SIGTERM, cib_shutdown);\n     mainloop_add_signal(SIGPIPE, cib_enable_writes);\n \n     cib_writer = mainloop_add_trigger(G_PRIORITY_LOW, write_cib_contents, NULL);\n \n     while (1) {\n         flag = crm_get_option(argc, argv, &index);\n         if (flag == -1)\n             break;\n \n         switch (flag) {\n             case 'V':\n                 crm_bump_log_level(argc, argv);\n                 break;\n             case 's':\n                 stand_alone = TRUE;\n                 preserve_status = TRUE;\n                 cib_writes_enabled = FALSE;\n \n                 pwentry = getpwnam(CRM_DAEMON_USER);\n                 CRM_CHECK(pwentry != NULL,\n                           crm_perror(LOG_ERR, \"Invalid uid (%s) specified\", CRM_DAEMON_USER);\n                           return CRM_EX_FATAL);\n \n                 rc = setgid(pwentry->pw_gid);\n                 if (rc < 0) {\n                     crm_perror(LOG_ERR, \"Could not set group to %d\", pwentry->pw_gid);\n                     return CRM_EX_FATAL;\n                 }\n \n                 rc = initgroups(CRM_DAEMON_USER, pwentry->pw_gid);\n                 if (rc < 0) {\n                     crm_perror(LOG_ERR, \"Could not setup groups for user %d\", pwentry->pw_uid);\n                     return CRM_EX_FATAL;\n                 }\n \n                 rc = setuid(pwentry->pw_uid);\n                 if (rc < 0) {\n                     crm_perror(LOG_ERR, \"Could not set user to %d\", pwentry->pw_uid);\n                     return CRM_EX_FATAL;\n                 }\n                 break;\n             case '?':",
  "diff_source": "custom",
  "Bug Filter": "Security Vulnerability Fix  \nConfidence Score: 0.95",
  "Bug Filter Confidence": 0.95,
  "Bug Filter Response": "\n\n**Final Output:**\nAnalysis: The patch addresses a security issue where processes could interfere, adding checks to prevent unauthorized access. The code changes involve checking for existing instances and handling rival processes, indicating a security fix.\n\nFinal Classification: Security Vulnerability Fix  \nConfidence Score: 0.95"
}