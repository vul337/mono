{
  "id": 1448,
  "language": "Java",
  "commit_url": "https://github.com/oracle/coherence/commit/e0de9b90daee7b58f0a2893db0df1cc1a429c56b",
  "commit_sha": "e0de9b90daee7b58f0a2893db0df1cc1a429c56b",
  "commit_msg": "BUG 34248310 - [34211273->21.12.5] DENIAL OF SERVICE (OOM) (merge ce/22.06 -> ce/22.12 @ 94389)\n\n[git-p4: depot-paths = \"//dev/coherence-ce/release/coherence-ce-v21.12/\": change = 94953]",
  "pr_url": null,
  "pr_info": "no more info",
  "file_name": "prj/coherence-core/src/main/java/com/tangosol/util/SafeHashMap.java",
  "func_name": "readObject",
  "func_before": "private void readObject(ObjectInputStream in)\n            throws IOException, ClassNotFoundException\n        {\n        RESIZING = new Object();\n\n        // read map stats\n        int     cBuckets = in.readInt();\n        Entry[] aeBucket = new Entry[cBuckets];\n\n        m_aeBucket     = aeBucket;\n        m_cCapacity    = in.readInt();\n        m_flLoadFactor = in.readFloat();\n        m_flGrowthRate = in.readFloat();\n\n        int cEntries = in.readInt();\n        m_cEntries   = cEntries;\n\n        // read entries\n        for (int i = 0; i < cEntries; ++i)\n            {\n            K      oKey    = (K) in.readObject();\n            V      oValue  = (V) in.readObject();\n            int    nHash   = (oKey == null ? 0 : oKey.hashCode());\n            int    nBucket = getBucketIndex(nHash, cBuckets);\n            Entry<K, V> entry = instantiateEntry(oKey, oValue, nHash);\n\n            entry.m_eNext     = aeBucket[nBucket];\n            aeBucket[nBucket] = entry;\n            }\n        }",
  "func_after": "private void readObject(ObjectInputStream in)\n            throws IOException, ClassNotFoundException\n        {\n        RESIZING = new Object();\n\n        // read map stats\n        int  cBuckets    = in.readInt();\n        int  cCapacity   = in.readInt();\n        float flLoadFactor = in.readFloat();\n        float flGrowthRate = in.readFloat();\n        int  cEntries    = in.readInt();\n\n        if (cBuckets <= ExternalizableHelper.CHUNK_THRESHOLD)\n            {\n            m_cCapacity   = cCapacity;\n            m_flLoadFactor = flLoadFactor;\n            m_flGrowthRate = flGrowthRate;\n            m_cEntries    = cEntries;\n\n            // JEP-290 - ensure we can allocate this array\n            ExternalizableHelper.validateLoadArray(SafeHashMap.Entry[].class, cBuckets, in);\n\n            Entry[] aeBucket = m_aeBucket = new Entry[cBuckets];\n\n            // read entries\n            for (int i = 0; i < cEntries; ++i)\n                {\n                K   oKey    = (K) in.readObject();\n                V   oValue  = (V) in.readObject();\n                int nHash   = (oKey == null ? 0 : oKey.hashCode());\n                int nBucket = getBucketIndex(nHash, cBuckets);\n\n                Entry<K, V> entry = instantiateEntry(oKey, oValue, nHash);\n\n                entry.m_eNext     = aeBucket[nBucket];\n                aeBucket[nBucket] = entry;\n                }\n            }\n        else\n            {\n            // if the cBuckets exceeds the threshold, consider the\n            // deserialized map parameters are invalid, and grow\n            // the structures using defaults by calling put.\n            for (int i = 0; i < cEntries; ++i)\n                {\n                put((K) in.readObject(), (V) in.readObject());\n                }\n            }\n        }",
  "diff_func": "--- func_before\n+++ func_after\n private void readObject(ObjectInputStream in)\n             throws IOException, ClassNotFoundException\n         {\n         RESIZING = new Object();\n \n         // read map stats\n-        int     cBuckets = in.readInt();\n+        int  cBuckets    = in.readInt();\n-        Entry[] aeBucket = new Entry[cBuckets];\n+        int  cCapacity   = in.readInt();\n+        float flLoadFactor = in.readFloat();\n+        float flGrowthRate = in.readFloat();\n+        int  cEntries    = in.readInt();\n \n-        m_aeBucket     = aeBucket;\n-        m_cCapacity    = in.readInt();\n-        m_flLoadFactor = in.readFloat();\n-        m_flGrowthRate = in.readFloat();\n+        if (cBuckets <= ExternalizableHelper.CHUNK_THRESHOLD)\n+            {\n+            m_cCapacity   = cCapacity;\n+            m_flLoadFactor = flLoadFactor;\n+            m_flGrowthRate = flGrowthRate;\n+            m_cEntries    = cEntries;\n \n-        int cEntries = in.readInt();\n-        m_cEntries   = cEntries;\n+            // JEP-290 - ensure we can allocate this array\n+            ExternalizableHelper.validateLoadArray(SafeHashMap.Entry[].class, cBuckets, in);\n \n+            Entry[] aeBucket = m_aeBucket = new Entry[cBuckets];\n+\n-        // read entries\n+            // read entries\n-        for (int i = 0; i < cEntries; ++i)\n+            for (int i = 0; i < cEntries; ++i)\n+                {\n+                K   oKey    = (K) in.readObject();\n+                V   oValue  = (V) in.readObject();\n+                int nHash   = (oKey == null ? 0 : oKey.hashCode());\n+                int nBucket = getBucketIndex(nHash, cBuckets);\n+\n+                Entry<K, V> entry = instantiateEntry(oKey, oValue, nHash);\n+\n+                entry.m_eNext     = aeBucket[nBucket];\n+                aeBucket[nBucket] = entry;\n+                }\n+            }\n+        else\n             {\n+            // if the cBuckets exceeds the threshold, consider the\n+            // deserialized map parameters are invalid, and grow",
  "diff_source": "custom"
}