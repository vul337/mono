{
  "id": 4685,
  "language": "C/C++",
  "commit_url": "https://github.com/torvalds/linux/commit/234f3ce485d54017f15cf5e0699cff4100121601",
  "commit_sha": "234f3ce485d54017f15cf5e0699cff4100121601",
  "commit_msg": "KVM: x86: Emulator fixes for eip canonical checks on near branches\n\nBefore changing rip (during jmp, call, ret, etc.) the target should be asserted\nto be canonical one, as real CPUs do.  During sysret, both target rsp and rip\nshould be canonical. If any of these values is noncanonical, a #GP exception\nshould occur.  The exception to this rule are syscall and sysenter instructions\nin which the assigned rip is checked during the assignment to the relevant\nMSRs.\n\nThis patch fixes the emulator to behave as real CPUs do for near branches.\nFar branches are handled by the next patch.\n\nThis fixes CVE-2014-3647.\n\nCc: stable@vger.kernel.org\nSigned-off-by: Nadav Amit <namit@cs.technion.ac.il>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
  "pr_url": null,
  "pr_info": "no more info",
  "file_name": "arch/x86/kvm/emulate.c",
  "func_name": "x86_emulate_insn",
  "func_before": "int x86_emulate_insn(struct x86_emulate_ctxt *ctxt)\n{\n\tconst struct x86_emulate_ops *ops = ctxt->ops;\n\tint rc = X86EMUL_CONTINUE;\n\tint saved_dst_type = ctxt->dst.type;\n\n\tctxt->mem_read.pos = 0;\n\n\t/* LOCK prefix is allowed only with some instructions */\n\tif (ctxt->lock_prefix && (!(ctxt->d & Lock) || ctxt->dst.type != OP_MEM)) {\n\t\trc = emulate_ud(ctxt);\n\t\tgoto done;\n\t}\n\n\tif ((ctxt->d & SrcMask) == SrcMemFAddr && ctxt->src.type != OP_MEM) {\n\t\trc = emulate_ud(ctxt);\n\t\tgoto done;\n\t}\n\n\tif (unlikely(ctxt->d &\n\t\t     (No64|Undefined|Sse|Mmx|Intercept|CheckPerm|Priv|Prot|String))) {\n\t\tif ((ctxt->mode == X86EMUL_MODE_PROT64 && (ctxt->d & No64)) ||\n\t\t\t\t(ctxt->d & Undefined)) {\n\t\t\trc = emulate_ud(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (((ctxt->d & (Sse|Mmx)) && ((ops->get_cr(ctxt, 0) & X86_CR0_EM)))\n\t\t    || ((ctxt->d & Sse) && !(ops->get_cr(ctxt, 4) & X86_CR4_OSFXSR))) {\n\t\t\trc = emulate_ud(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\tif ((ctxt->d & (Sse|Mmx)) && (ops->get_cr(ctxt, 0) & X86_CR0_TS)) {\n\t\t\trc = emulate_nm(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (ctxt->d & Mmx) {\n\t\t\trc = flush_pending_x87_faults(ctxt);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t\t/*\n\t\t\t * Now that we know the fpu is exception safe, we can fetch\n\t\t\t * operands from it.\n\t\t\t */\n\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->src);\n\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->src2);\n\t\t\tif (!(ctxt->d & Mov))\n\t\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->dst);\n\t\t}\n\n\t\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n\t\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n\t\t\t\t\t\t      X86_ICPT_PRE_EXCEPT);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\t/* Privileged instruction can be executed only in CPL=0 */\n\t\tif ((ctxt->d & Priv) && ops->cpl(ctxt)) {\n\t\t\tif (ctxt->d & PrivUD)\n\t\t\t\trc = emulate_ud(ctxt);\n\t\t\telse\n\t\t\t\trc = emulate_gp(ctxt, 0);\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Instruction can only be executed in protected mode */\n\t\tif ((ctxt->d & Prot) && ctxt->mode < X86EMUL_MODE_PROT16) {\n\t\t\trc = emulate_ud(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Do instruction specific permission checks */\n\t\tif (ctxt->d & CheckPerm) {\n\t\t\trc = ctxt->check_perm(ctxt);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n\t\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n\t\t\t\t\t\t      X86_ICPT_POST_EXCEPT);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tif (ctxt->rep_prefix && (ctxt->d & String)) {\n\t\t\t/* All REP prefixes have the same first termination condition */\n\t\t\tif (address_mask(ctxt, reg_read(ctxt, VCPU_REGS_RCX)) == 0) {\n\t\t\t\tctxt->eip = ctxt->_eip;\n\t\t\t\tctxt->eflags &= ~EFLG_RF;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ((ctxt->src.type == OP_MEM) && !(ctxt->d & NoAccess)) {\n\t\trc = segmented_read(ctxt, ctxt->src.addr.mem,\n\t\t\t\t    ctxt->src.valptr, ctxt->src.bytes);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t\tctxt->src.orig_val64 = ctxt->src.val64;\n\t}\n\n\tif (ctxt->src2.type == OP_MEM) {\n\t\trc = segmented_read(ctxt, ctxt->src2.addr.mem,\n\t\t\t\t    &ctxt->src2.val, ctxt->src2.bytes);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\n\tif ((ctxt->d & DstMask) == ImplicitOps)\n\t\tgoto special_insn;\n\n\n\tif ((ctxt->dst.type == OP_MEM) && !(ctxt->d & Mov)) {\n\t\t/* optimisation - avoid slow emulated read if Mov */\n\t\trc = segmented_read(ctxt, ctxt->dst.addr.mem,\n\t\t\t\t   &ctxt->dst.val, ctxt->dst.bytes);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\tctxt->dst.orig_val = ctxt->dst.val;\n\nspecial_insn:\n\n\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n\t\t\t\t\t      X86_ICPT_POST_MEMACCESS);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\n\tif (ctxt->rep_prefix && (ctxt->d & String))\n\t\tctxt->eflags |= EFLG_RF;\n\telse\n\t\tctxt->eflags &= ~EFLG_RF;\n\n\tif (ctxt->execute) {\n\t\tif (ctxt->d & Fastop) {\n\t\t\tvoid (*fop)(struct fastop *) = (void *)ctxt->execute;\n\t\t\trc = fastop(ctxt, fop);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t\tgoto writeback;\n\t\t}\n\t\trc = ctxt->execute(ctxt);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t\tgoto writeback;\n\t}\n\n\tif (ctxt->opcode_len == 2)\n\t\tgoto twobyte_insn;\n\telse if (ctxt->opcode_len == 3)\n\t\tgoto threebyte_insn;\n\n\tswitch (ctxt->b) {\n\tcase 0x63:\t\t/* movsxd */\n\t\tif (ctxt->mode != X86EMUL_MODE_PROT64)\n\t\t\tgoto cannot_emulate;\n\t\tctxt->dst.val = (s32) ctxt->src.val;\n\t\tbreak;\n\tcase 0x70 ... 0x7f: /* jcc (short) */\n\t\tif (test_cc(ctxt->b, ctxt->eflags))\n\t\t\tjmp_rel(ctxt, ctxt->src.val);\n\t\tbreak;\n\tcase 0x8d: /* lea r16/r32, m */\n\t\tctxt->dst.val = ctxt->src.addr.mem.ea;\n\t\tbreak;\n\tcase 0x90 ... 0x97: /* nop / xchg reg, rax */\n\t\tif (ctxt->dst.addr.reg == reg_rmw(ctxt, VCPU_REGS_RAX))\n\t\t\tctxt->dst.type = OP_NONE;\n\t\telse\n\t\t\trc = em_xchg(ctxt);\n\t\tbreak;\n\tcase 0x98: /* cbw/cwde/cdqe */\n\t\tswitch (ctxt->op_bytes) {\n\t\tcase 2: ctxt->dst.val = (s8)ctxt->dst.val; break;\n\t\tcase 4: ctxt->dst.val = (s16)ctxt->dst.val; break;\n\t\tcase 8: ctxt->dst.val = (s32)ctxt->dst.val; break;\n\t\t}\n\t\tbreak;\n\tcase 0xcc:\t\t/* int3 */\n\t\trc = emulate_int(ctxt, 3);\n\t\tbreak;\n\tcase 0xcd:\t\t/* int n */\n\t\trc = emulate_int(ctxt, ctxt->src.val);\n\t\tbreak;\n\tcase 0xce:\t\t/* into */\n\t\tif (ctxt->eflags & EFLG_OF)\n\t\t\trc = emulate_int(ctxt, 4);\n\t\tbreak;\n\tcase 0xe9: /* jmp rel */\n\tcase 0xeb: /* jmp rel short */\n\t\tjmp_rel(ctxt, ctxt->src.val);\n\t\tctxt->dst.type = OP_NONE; /* Disable writeback. */\n\t\tbreak;\n\tcase 0xf4:              /* hlt */\n\t\tctxt->ops->halt(ctxt);\n\t\tbreak;\n\tcase 0xf5:\t/* cmc */\n\t\t/* complement carry flag from eflags reg */\n\t\tctxt->eflags ^= EFLG_CF;\n\t\tbreak;\n\tcase 0xf8: /* clc */\n\t\tctxt->eflags &= ~EFLG_CF;\n\t\tbreak;\n\tcase 0xf9: /* stc */\n\t\tctxt->eflags |= EFLG_CF;\n\t\tbreak;\n\tcase 0xfc: /* cld */\n\t\tctxt->eflags &= ~EFLG_DF;\n\t\tbreak;\n\tcase 0xfd: /* std */\n\t\tctxt->eflags |= EFLG_DF;\n\t\tbreak;\n\tdefault:\n\t\tgoto cannot_emulate;\n\t}\n\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\nwriteback:\n\tif (ctxt->d & SrcWrite) {\n\t\tBUG_ON(ctxt->src.type == OP_MEM || ctxt->src.type == OP_MEM_STR);\n\t\trc = writeback(ctxt, &ctxt->src);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\tif (!(ctxt->d & NoWrite)) {\n\t\trc = writeback(ctxt, &ctxt->dst);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\n\t/*\n\t * restore dst type in case the decoding will be reused\n\t * (happens for string instruction )\n\t */\n\tctxt->dst.type = saved_dst_type;\n\n\tif ((ctxt->d & SrcMask) == SrcSI)\n\t\tstring_addr_inc(ctxt, VCPU_REGS_RSI, &ctxt->src);\n\n\tif ((ctxt->d & DstMask) == DstDI)\n\t\tstring_addr_inc(ctxt, VCPU_REGS_RDI, &ctxt->dst);\n\n\tif (ctxt->rep_prefix && (ctxt->d & String)) {\n\t\tunsigned int count;\n\t\tstruct read_cache *r = &ctxt->io_read;\n\t\tif ((ctxt->d & SrcMask) == SrcSI)\n\t\t\tcount = ctxt->src.count;\n\t\telse\n\t\t\tcount = ctxt->dst.count;\n\t\tregister_address_increment(ctxt, reg_rmw(ctxt, VCPU_REGS_RCX),\n\t\t\t\t-count);\n\n\t\tif (!string_insn_completed(ctxt)) {\n\t\t\t/*\n\t\t\t * Re-enter guest when pio read ahead buffer is empty\n\t\t\t * or, if it is not used, after each 1024 iteration.\n\t\t\t */\n\t\t\tif ((r->end != 0 || reg_read(ctxt, VCPU_REGS_RCX) & 0x3ff) &&\n\t\t\t    (r->end == 0 || r->end != r->pos)) {\n\t\t\t\t/*\n\t\t\t\t * Reset read cache. Usually happens before\n\t\t\t\t * decode, but since instruction is restarted\n\t\t\t\t * we have to do it here.\n\t\t\t\t */\n\t\t\t\tctxt->mem_read.end = 0;\n\t\t\t\twriteback_registers(ctxt);\n\t\t\t\treturn EMULATION_RESTART;\n\t\t\t}\n\t\t\tgoto done; /* skip rip writeback */\n\t\t}\n\t\tctxt->eflags &= ~EFLG_RF;\n\t}\n\n\tctxt->eip = ctxt->_eip;\n\ndone:\n\tif (rc == X86EMUL_PROPAGATE_FAULT) {\n\t\tWARN_ON(ctxt->exception.vector > 0x1f);\n\t\tctxt->have_exception = true;\n\t}\n\tif (rc == X86EMUL_INTERCEPTED)\n\t\treturn EMULATION_INTERCEPTED;\n\n\tif (rc == X86EMUL_CONTINUE)\n\t\twriteback_registers(ctxt);\n\n\treturn (rc == X86EMUL_UNHANDLEABLE) ? EMULATION_FAILED : EMULATION_OK;\n\ntwobyte_insn:\n\tswitch (ctxt->b) {\n\tcase 0x09:\t\t/* wbinvd */\n\t\t(ctxt->ops->wbinvd)(ctxt);\n\t\tbreak;\n\tcase 0x08:\t\t/* invd */\n\tcase 0x0d:\t\t/* GrpP (prefetch) */\n\tcase 0x18:\t\t/* Grp16 (prefetch/nop) */\n\tcase 0x1f:\t\t/* nop */\n\t\tbreak;\n\tcase 0x20: /* mov cr, reg */\n\t\tctxt->dst.val = ops->get_cr(ctxt, ctxt->modrm_reg);\n\t\tbreak;\n\tcase 0x21: /* mov from dr to reg */\n\t\tops->get_dr(ctxt, ctxt->modrm_reg, &ctxt->dst.val);\n\t\tbreak;\n\tcase 0x40 ... 0x4f:\t/* cmov */\n\t\tif (test_cc(ctxt->b, ctxt->eflags))\n\t\t\tctxt->dst.val = ctxt->src.val;\n\t\telse if (ctxt->mode != X86EMUL_MODE_PROT64 ||\n\t\t\t ctxt->op_bytes != 4)\n\t\t\tctxt->dst.type = OP_NONE; /* no writeback */\n\t\tbreak;\n\tcase 0x80 ... 0x8f: /* jnz rel, etc*/\n\t\tif (test_cc(ctxt->b, ctxt->eflags))\n\t\t\tjmp_rel(ctxt, ctxt->src.val);\n\t\tbreak;\n\tcase 0x90 ... 0x9f:     /* setcc r/m8 */\n\t\tctxt->dst.val = test_cc(ctxt->b, ctxt->eflags);\n\t\tbreak;\n\tcase 0xae:              /* clflush */\n\t\tbreak;\n\tcase 0xb6 ... 0xb7:\t/* movzx */\n\t\tctxt->dst.bytes = ctxt->op_bytes;\n\t\tctxt->dst.val = (ctxt->src.bytes == 1) ? (u8) ctxt->src.val\n\t\t\t\t\t\t       : (u16) ctxt->src.val;\n\t\tbreak;\n\tcase 0xbe ... 0xbf:\t/* movsx */\n\t\tctxt->dst.bytes = ctxt->op_bytes;\n\t\tctxt->dst.val = (ctxt->src.bytes == 1) ? (s8) ctxt->src.val :\n\t\t\t\t\t\t\t(s16) ctxt->src.val;\n\t\tbreak;\n\tcase 0xc3:\t\t/* movnti */\n\t\tctxt->dst.bytes = ctxt->op_bytes;\n\t\tctxt->dst.val = (ctxt->op_bytes == 8) ? (u64) ctxt->src.val :\n\t\t\t\t\t\t\t(u32) ctxt->src.val;\n\t\tbreak;\n\tdefault:\n\t\tgoto cannot_emulate;\n\t}\n\nthreebyte_insn:\n\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tgoto writeback;\n\ncannot_emulate:\n\treturn EMULATION_FAILED;\n}",
  "func_after": "int x86_emulate_insn(struct x86_emulate_ctxt *ctxt)\n{\n\tconst struct x86_emulate_ops *ops = ctxt->ops;\n\tint rc = X86EMUL_CONTINUE;\n\tint saved_dst_type = ctxt->dst.type;\n\n\tctxt->mem_read.pos = 0;\n\n\t/* LOCK prefix is allowed only with some instructions */\n\tif (ctxt->lock_prefix && (!(ctxt->d & Lock) || ctxt->dst.type != OP_MEM)) {\n\t\trc = emulate_ud(ctxt);\n\t\tgoto done;\n\t}\n\n\tif ((ctxt->d & SrcMask) == SrcMemFAddr && ctxt->src.type != OP_MEM) {\n\t\trc = emulate_ud(ctxt);\n\t\tgoto done;\n\t}\n\n\tif (unlikely(ctxt->d &\n\t\t     (No64|Undefined|Sse|Mmx|Intercept|CheckPerm|Priv|Prot|String))) {\n\t\tif ((ctxt->mode == X86EMUL_MODE_PROT64 && (ctxt->d & No64)) ||\n\t\t\t\t(ctxt->d & Undefined)) {\n\t\t\trc = emulate_ud(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (((ctxt->d & (Sse|Mmx)) && ((ops->get_cr(ctxt, 0) & X86_CR0_EM)))\n\t\t    || ((ctxt->d & Sse) && !(ops->get_cr(ctxt, 4) & X86_CR4_OSFXSR))) {\n\t\t\trc = emulate_ud(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\tif ((ctxt->d & (Sse|Mmx)) && (ops->get_cr(ctxt, 0) & X86_CR0_TS)) {\n\t\t\trc = emulate_nm(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (ctxt->d & Mmx) {\n\t\t\trc = flush_pending_x87_faults(ctxt);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t\t/*\n\t\t\t * Now that we know the fpu is exception safe, we can fetch\n\t\t\t * operands from it.\n\t\t\t */\n\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->src);\n\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->src2);\n\t\t\tif (!(ctxt->d & Mov))\n\t\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->dst);\n\t\t}\n\n\t\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n\t\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n\t\t\t\t\t\t      X86_ICPT_PRE_EXCEPT);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\t/* Privileged instruction can be executed only in CPL=0 */\n\t\tif ((ctxt->d & Priv) && ops->cpl(ctxt)) {\n\t\t\tif (ctxt->d & PrivUD)\n\t\t\t\trc = emulate_ud(ctxt);\n\t\t\telse\n\t\t\t\trc = emulate_gp(ctxt, 0);\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Instruction can only be executed in protected mode */\n\t\tif ((ctxt->d & Prot) && ctxt->mode < X86EMUL_MODE_PROT16) {\n\t\t\trc = emulate_ud(ctxt);\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Do instruction specific permission checks */\n\t\tif (ctxt->d & CheckPerm) {\n\t\t\trc = ctxt->check_perm(ctxt);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n\t\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n\t\t\t\t\t\t      X86_ICPT_POST_EXCEPT);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tif (ctxt->rep_prefix && (ctxt->d & String)) {\n\t\t\t/* All REP prefixes have the same first termination condition */\n\t\t\tif (address_mask(ctxt, reg_read(ctxt, VCPU_REGS_RCX)) == 0) {\n\t\t\t\tctxt->eip = ctxt->_eip;\n\t\t\t\tctxt->eflags &= ~EFLG_RF;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ((ctxt->src.type == OP_MEM) && !(ctxt->d & NoAccess)) {\n\t\trc = segmented_read(ctxt, ctxt->src.addr.mem,\n\t\t\t\t    ctxt->src.valptr, ctxt->src.bytes);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t\tctxt->src.orig_val64 = ctxt->src.val64;\n\t}\n\n\tif (ctxt->src2.type == OP_MEM) {\n\t\trc = segmented_read(ctxt, ctxt->src2.addr.mem,\n\t\t\t\t    &ctxt->src2.val, ctxt->src2.bytes);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\n\tif ((ctxt->d & DstMask) == ImplicitOps)\n\t\tgoto special_insn;\n\n\n\tif ((ctxt->dst.type == OP_MEM) && !(ctxt->d & Mov)) {\n\t\t/* optimisation - avoid slow emulated read if Mov */\n\t\trc = segmented_read(ctxt, ctxt->dst.addr.mem,\n\t\t\t\t   &ctxt->dst.val, ctxt->dst.bytes);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\tctxt->dst.orig_val = ctxt->dst.val;\n\nspecial_insn:\n\n\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n\t\t\t\t\t      X86_ICPT_POST_MEMACCESS);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\n\tif (ctxt->rep_prefix && (ctxt->d & String))\n\t\tctxt->eflags |= EFLG_RF;\n\telse\n\t\tctxt->eflags &= ~EFLG_RF;\n\n\tif (ctxt->execute) {\n\t\tif (ctxt->d & Fastop) {\n\t\t\tvoid (*fop)(struct fastop *) = (void *)ctxt->execute;\n\t\t\trc = fastop(ctxt, fop);\n\t\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\t\tgoto done;\n\t\t\tgoto writeback;\n\t\t}\n\t\trc = ctxt->execute(ctxt);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t\tgoto writeback;\n\t}\n\n\tif (ctxt->opcode_len == 2)\n\t\tgoto twobyte_insn;\n\telse if (ctxt->opcode_len == 3)\n\t\tgoto threebyte_insn;\n\n\tswitch (ctxt->b) {\n\tcase 0x63:\t\t/* movsxd */\n\t\tif (ctxt->mode != X86EMUL_MODE_PROT64)\n\t\t\tgoto cannot_emulate;\n\t\tctxt->dst.val = (s32) ctxt->src.val;\n\t\tbreak;\n\tcase 0x70 ... 0x7f: /* jcc (short) */\n\t\tif (test_cc(ctxt->b, ctxt->eflags))\n\t\t\trc = jmp_rel(ctxt, ctxt->src.val);\n\t\tbreak;\n\tcase 0x8d: /* lea r16/r32, m */\n\t\tctxt->dst.val = ctxt->src.addr.mem.ea;\n\t\tbreak;\n\tcase 0x90 ... 0x97: /* nop / xchg reg, rax */\n\t\tif (ctxt->dst.addr.reg == reg_rmw(ctxt, VCPU_REGS_RAX))\n\t\t\tctxt->dst.type = OP_NONE;\n\t\telse\n\t\t\trc = em_xchg(ctxt);\n\t\tbreak;\n\tcase 0x98: /* cbw/cwde/cdqe */\n\t\tswitch (ctxt->op_bytes) {\n\t\tcase 2: ctxt->dst.val = (s8)ctxt->dst.val; break;\n\t\tcase 4: ctxt->dst.val = (s16)ctxt->dst.val; break;\n\t\tcase 8: ctxt->dst.val = (s32)ctxt->dst.val; break;\n\t\t}\n\t\tbreak;\n\tcase 0xcc:\t\t/* int3 */\n\t\trc = emulate_int(ctxt, 3);\n\t\tbreak;\n\tcase 0xcd:\t\t/* int n */\n\t\trc = emulate_int(ctxt, ctxt->src.val);\n\t\tbreak;\n\tcase 0xce:\t\t/* into */\n\t\tif (ctxt->eflags & EFLG_OF)\n\t\t\trc = emulate_int(ctxt, 4);\n\t\tbreak;\n\tcase 0xe9: /* jmp rel */\n\tcase 0xeb: /* jmp rel short */\n\t\trc = jmp_rel(ctxt, ctxt->src.val);\n\t\tctxt->dst.type = OP_NONE; /* Disable writeback. */\n\t\tbreak;\n\tcase 0xf4:              /* hlt */\n\t\tctxt->ops->halt(ctxt);\n\t\tbreak;\n\tcase 0xf5:\t/* cmc */\n\t\t/* complement carry flag from eflags reg */\n\t\tctxt->eflags ^= EFLG_CF;\n\t\tbreak;\n\tcase 0xf8: /* clc */\n\t\tctxt->eflags &= ~EFLG_CF;\n\t\tbreak;\n\tcase 0xf9: /* stc */\n\t\tctxt->eflags |= EFLG_CF;\n\t\tbreak;\n\tcase 0xfc: /* cld */\n\t\tctxt->eflags &= ~EFLG_DF;\n\t\tbreak;\n\tcase 0xfd: /* std */\n\t\tctxt->eflags |= EFLG_DF;\n\t\tbreak;\n\tdefault:\n\t\tgoto cannot_emulate;\n\t}\n\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\nwriteback:\n\tif (ctxt->d & SrcWrite) {\n\t\tBUG_ON(ctxt->src.type == OP_MEM || ctxt->src.type == OP_MEM_STR);\n\t\trc = writeback(ctxt, &ctxt->src);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\tif (!(ctxt->d & NoWrite)) {\n\t\trc = writeback(ctxt, &ctxt->dst);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\tgoto done;\n\t}\n\n\t/*\n\t * restore dst type in case the decoding will be reused\n\t * (happens for string instruction )\n\t */\n\tctxt->dst.type = saved_dst_type;\n\n\tif ((ctxt->d & SrcMask) == SrcSI)\n\t\tstring_addr_inc(ctxt, VCPU_REGS_RSI, &ctxt->src);\n\n\tif ((ctxt->d & DstMask) == DstDI)\n\t\tstring_addr_inc(ctxt, VCPU_REGS_RDI, &ctxt->dst);\n\n\tif (ctxt->rep_prefix && (ctxt->d & String)) {\n\t\tunsigned int count;\n\t\tstruct read_cache *r = &ctxt->io_read;\n\t\tif ((ctxt->d & SrcMask) == SrcSI)\n\t\t\tcount = ctxt->src.count;\n\t\telse\n\t\t\tcount = ctxt->dst.count;\n\t\tregister_address_increment(ctxt, reg_rmw(ctxt, VCPU_REGS_RCX),\n\t\t\t\t-count);\n\n\t\tif (!string_insn_completed(ctxt)) {\n\t\t\t/*\n\t\t\t * Re-enter guest when pio read ahead buffer is empty\n\t\t\t * or, if it is not used, after each 1024 iteration.\n\t\t\t */\n\t\t\tif ((r->end != 0 || reg_read(ctxt, VCPU_REGS_RCX) & 0x3ff) &&\n\t\t\t    (r->end == 0 || r->end != r->pos)) {\n\t\t\t\t/*\n\t\t\t\t * Reset read cache. Usually happens before\n\t\t\t\t * decode, but since instruction is restarted\n\t\t\t\t * we have to do it here.\n\t\t\t\t */\n\t\t\t\tctxt->mem_read.end = 0;\n\t\t\t\twriteback_registers(ctxt);\n\t\t\t\treturn EMULATION_RESTART;\n\t\t\t}\n\t\t\tgoto done; /* skip rip writeback */\n\t\t}\n\t\tctxt->eflags &= ~EFLG_RF;\n\t}\n\n\tctxt->eip = ctxt->_eip;\n\ndone:\n\tif (rc == X86EMUL_PROPAGATE_FAULT) {\n\t\tWARN_ON(ctxt->exception.vector > 0x1f);\n\t\tctxt->have_exception = true;\n\t}\n\tif (rc == X86EMUL_INTERCEPTED)\n\t\treturn EMULATION_INTERCEPTED;\n\n\tif (rc == X86EMUL_CONTINUE)\n\t\twriteback_registers(ctxt);\n\n\treturn (rc == X86EMUL_UNHANDLEABLE) ? EMULATION_FAILED : EMULATION_OK;\n\ntwobyte_insn:\n\tswitch (ctxt->b) {\n\tcase 0x09:\t\t/* wbinvd */\n\t\t(ctxt->ops->wbinvd)(ctxt);\n\t\tbreak;\n\tcase 0x08:\t\t/* invd */\n\tcase 0x0d:\t\t/* GrpP (prefetch) */\n\tcase 0x18:\t\t/* Grp16 (prefetch/nop) */\n\tcase 0x1f:\t\t/* nop */\n\t\tbreak;\n\tcase 0x20: /* mov cr, reg */\n\t\tctxt->dst.val = ops->get_cr(ctxt, ctxt->modrm_reg);\n\t\tbreak;\n\tcase 0x21: /* mov from dr to reg */\n\t\tops->get_dr(ctxt, ctxt->modrm_reg, &ctxt->dst.val);\n\t\tbreak;\n\tcase 0x40 ... 0x4f:\t/* cmov */\n\t\tif (test_cc(ctxt->b, ctxt->eflags))\n\t\t\tctxt->dst.val = ctxt->src.val;\n\t\telse if (ctxt->mode != X86EMUL_MODE_PROT64 ||\n\t\t\t ctxt->op_bytes != 4)\n\t\t\tctxt->dst.type = OP_NONE; /* no writeback */\n\t\tbreak;\n\tcase 0x80 ... 0x8f: /* jnz rel, etc*/\n\t\tif (test_cc(ctxt->b, ctxt->eflags))\n\t\t\trc = jmp_rel(ctxt, ctxt->src.val);\n\t\tbreak;\n\tcase 0x90 ... 0x9f:     /* setcc r/m8 */\n\t\tctxt->dst.val = test_cc(ctxt->b, ctxt->eflags);\n\t\tbreak;\n\tcase 0xae:              /* clflush */\n\t\tbreak;\n\tcase 0xb6 ... 0xb7:\t/* movzx */\n\t\tctxt->dst.bytes = ctxt->op_bytes;\n\t\tctxt->dst.val = (ctxt->src.bytes == 1) ? (u8) ctxt->src.val\n\t\t\t\t\t\t       : (u16) ctxt->src.val;\n\t\tbreak;\n\tcase 0xbe ... 0xbf:\t/* movsx */\n\t\tctxt->dst.bytes = ctxt->op_bytes;\n\t\tctxt->dst.val = (ctxt->src.bytes == 1) ? (s8) ctxt->src.val :\n\t\t\t\t\t\t\t(s16) ctxt->src.val;\n\t\tbreak;\n\tcase 0xc3:\t\t/* movnti */\n\t\tctxt->dst.bytes = ctxt->op_bytes;\n\t\tctxt->dst.val = (ctxt->op_bytes == 8) ? (u64) ctxt->src.val :\n\t\t\t\t\t\t\t(u32) ctxt->src.val;\n\t\tbreak;\n\tdefault:\n\t\tgoto cannot_emulate;\n\t}\n\nthreebyte_insn:\n\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tgoto writeback;\n\ncannot_emulate:\n\treturn EMULATION_FAILED;\n}",
  "diff_func": "--- func_before\n+++ func_after\n int x86_emulate_insn(struct x86_emulate_ctxt *ctxt)\n {\n \tconst struct x86_emulate_ops *ops = ctxt->ops;\n \tint rc = X86EMUL_CONTINUE;\n \tint saved_dst_type = ctxt->dst.type;\n \n \tctxt->mem_read.pos = 0;\n \n \t/* LOCK prefix is allowed only with some instructions */\n \tif (ctxt->lock_prefix && (!(ctxt->d & Lock) || ctxt->dst.type != OP_MEM)) {\n \t\trc = emulate_ud(ctxt);\n \t\tgoto done;\n \t}\n \n \tif ((ctxt->d & SrcMask) == SrcMemFAddr && ctxt->src.type != OP_MEM) {\n \t\trc = emulate_ud(ctxt);\n \t\tgoto done;\n \t}\n \n \tif (unlikely(ctxt->d &\n \t\t     (No64|Undefined|Sse|Mmx|Intercept|CheckPerm|Priv|Prot|String))) {\n \t\tif ((ctxt->mode == X86EMUL_MODE_PROT64 && (ctxt->d & No64)) ||\n \t\t\t\t(ctxt->d & Undefined)) {\n \t\t\trc = emulate_ud(ctxt);\n \t\t\tgoto done;\n \t\t}\n \n \t\tif (((ctxt->d & (Sse|Mmx)) && ((ops->get_cr(ctxt, 0) & X86_CR0_EM)))\n \t\t    || ((ctxt->d & Sse) && !(ops->get_cr(ctxt, 4) & X86_CR4_OSFXSR))) {\n \t\t\trc = emulate_ud(ctxt);\n \t\t\tgoto done;\n \t\t}\n \n \t\tif ((ctxt->d & (Sse|Mmx)) && (ops->get_cr(ctxt, 0) & X86_CR0_TS)) {\n \t\t\trc = emulate_nm(ctxt);\n \t\t\tgoto done;\n \t\t}\n \n \t\tif (ctxt->d & Mmx) {\n \t\t\trc = flush_pending_x87_faults(ctxt);\n \t\t\tif (rc != X86EMUL_CONTINUE)\n \t\t\t\tgoto done;\n \t\t\t/*\n \t\t\t * Now that we know the fpu is exception safe, we can fetch\n \t\t\t * operands from it.\n \t\t\t */\n \t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->src);\n \t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->src2);\n \t\t\tif (!(ctxt->d & Mov))\n \t\t\t\tfetch_possible_mmx_operand(ctxt, &ctxt->dst);\n \t\t}\n \n \t\tif (unlikely(ctxt->guest_mode) && (ctxt->d & Intercept)) {\n \t\t\trc = emulator_check_intercept(ctxt, ctxt->intercept,\n \t\t\t\t\t\t      X86_ICPT_PRE_EXCEPT);\n \t\t\tif (rc != X86EMUL_CONTINUE)\n \t\t\t\tgoto done;\n \t\t}\n \n \t\t/* Privileged instruction can be executed only in CPL=0 */\n \t\tif ((ctxt->d & Priv) && ops->cpl(ctxt)) {\n \t\t\tif (ctxt->d & PrivUD)\n \t\t\t\trc = emulate_ud(ctxt);\n \t\t\telse\n \t\t\t\trc = emulate_gp(ctxt, 0);\n \t\t\tgoto done;\n \t\t}\n \n \t\t/* Instruction can only be executed in protected mode */\n \t\tif ((ctx",
  "diff_source": "custom"
}