{
  "id": 2181,
  "language": "Java",
  "commit_url": "https://github.com/apache/iotdb/commit/42448cb80d1f949bc9dd7f642441c5bcabcb8e93",
  "commit_sha": "42448cb80d1f949bc9dd7f642441c5bcabcb8e93",
  "commit_msg": "[IOTDB-1415] Fix OOM caused by ChunkCache (#3308)\n\nCo-authored-by: Haonan <hhaonan@outlook.com>",
  "pr_url": "https://github.com/apache/iotdb/pull/3308",
  "pr_info": "## Description\r\nThe detailed description could be seen in [JIRA](https://issues.apache.org/jira/browse/IOTDB-1415)\r\n\r\n## Analysis\r\nThe details could be found in [Confluence](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=181307964)\r\n\r\n## Solution\r\nUse Caffeine Cache to replace the previous LinkedHashMap.\r\n\r\nCaffeine is a high performance Java caching library providing a near optimal hit rate. Caffeine provides an in-memory cache using a Google Guava inspired API. The improvements draw on their experience designing Guava's cache and ConcurrentLinkedHashMap.\r\n\r\nThe [Tests](https://github.com/ben-manes/caffeine/wiki/Benchmarks) in their website shows that it's much more better than Guava Cache.\r\n\r\nIn our own [weekly test](http://ise.thss.tsinghua.edu.cn/confluence/pages/viewpage.action?pageId=57212546), Caffeine Cache's performance is same as the previous wrong implementation of master.\r\n",
  "file_name": "server/src/main/java/org/apache/iotdb/db/engine/cache/TimeSeriesMetadataCache.java",
  "func_name": "SuppressWarnings",
  "func_before": "@SuppressWarnings({\"squid:S1860\", \"squid:S3776\"})\n  public List<TimeseriesMetadata> get(\n      TimeSeriesMetadataCacheKey key,\n      List<String> subSensorList,\n      Set<String> allSensors,\n      boolean debug)\n      throws IOException {\n    // put all sub sensors into allSensors\n    allSensors.addAll(subSensorList);\n    if (!CACHE_ENABLE) {\n      // bloom filter part\n      TsFileSequenceReader reader = FileReaderManager.getInstance().get(key.filePath, true);\n      BloomFilter bloomFilter = reader.readBloomFilter();\n      if (bloomFilter != null\n          && !bloomFilter.contains(key.device + IoTDBConstant.PATH_SEPARATOR + key.measurement)) {\n        return Collections.emptyList();\n      }\n      return reader.readTimeseriesMetadata(new Path(key.device, key.measurement), subSensorList);\n    }\n\n    cacheRequestNum.incrementAndGet();\n\n    List<TimeseriesMetadata> res = new ArrayList<>();\n\n    getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n\n    if (!res.isEmpty()) {\n      cacheHitNum.incrementAndGet();\n      printCacheLog(true);\n    } else {\n      if (debug) {\n        DEBUG_LOGGER.info(\n            \"Cache miss: {}.{} in file: {}\", key.device, key.measurement, key.filePath);\n        DEBUG_LOGGER.info(\"Device: {}, all sensors: {}\", key.device, allSensors);\n      }\n      // allow for the parallelism of different devices\n      synchronized (\n          devices.computeIfAbsent(key.device + SEPARATOR + key.filePath, WeakReference::new)) {\n        // double check\n        getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n        if (!res.isEmpty()) {\n          cacheHitNum.incrementAndGet();\n          printCacheLog(true);\n        } else {\n          Path path = new Path(key.device, key.measurement);\n          // bloom filter part\n          TsFileSequenceReader reader = FileReaderManager.getInstance().get(key.filePath, true);\n          BloomFilter bloomFilter = reader.readBloomFilter();\n          if (bloomFilter != null && !bloomFilter.contains(path.getFullPath())) {\n            if (debug) {\n              DEBUG_LOGGER.info(\"TimeSeries meta data {} is filter by bloomFilter!\", key);\n            }\n            return Collections.emptyList();\n          }\n          printCacheLog(false);\n          List<TimeseriesMetadata> timeSeriesMetadataList =\n              reader.readTimeseriesMetadata(path, allSensors);\n          // put TimeSeriesMetadata of all sensors used in this query into cache\n          lock.writeLock().lock();\n          try {\n            timeSeriesMetadataList.forEach(\n                metadata -> {\n                  // for root.sg1.d1.vector1.s1, key.device of vector will only return root.sg1.d1\n                  // metadata.getMeasurementId() will return s1, the vector1 is saved in\n                  // key.measurement\n                  // so we should concat them to get the deviceId for root.sg1.d1.vector1.s1\n                  TimeSeriesMetadataCacheKey k =\n                      new TimeSeriesMetadataCacheKey(\n                          key.filePath,\n                          key.device + IoTDBConstant.PATH_SEPARATOR + key.measurement,\n                          metadata.getMeasurementId());\n                  if (!lruCache.containsKey(k)) {\n                    lruCache.put(k, metadata);\n                  }\n                });\n            getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n          } finally {\n            lock.writeLock().unlock();\n          }\n        }\n      }\n    }\n    if (res.isEmpty()) {\n      if (debug) {\n        DEBUG_LOGGER.info(\"The file doesn't have this time series {}.\", key);\n      }\n      return Collections.emptyList();\n    } else {\n      if (debug) {\n        DEBUG_LOGGER.info(\n            \"Get timeseries: {}.{}  metadata in file: {}  from cache: {}.\",\n            key.device,\n            key.measurement,\n            key.filePath,\n            res);\n      }\n      for (int i = 0; i < res.size(); i++) {\n        res.set(i, new TimeseriesMetadata(res.get(i)));\n      }\n      return res;\n    }\n  }",
  "func_after": "@SuppressWarnings({\"squid:S1860\", \"squid:S3776\"})\n  public List<TimeseriesMetadata> get(\n      TimeSeriesMetadataCacheKey key,\n      List<String> subSensorList,\n      Set<String> allSensors,\n      boolean debug)\n      throws IOException {\n    // put all sub sensors into allSensors\n    allSensors.addAll(subSensorList);\n    if (!CACHE_ENABLE) {\n      // bloom filter part\n      TsFileSequenceReader reader = FileReaderManager.getInstance().get(key.filePath, true);\n      BloomFilter bloomFilter = reader.readBloomFilter();\n      if (bloomFilter != null\n          && !bloomFilter.contains(key.device + IoTDBConstant.PATH_SEPARATOR + key.measurement)) {\n        return Collections.emptyList();\n      }\n      return reader.readTimeseriesMetadata(new Path(key.device, key.measurement), subSensorList);\n    }\n\n    List<TimeseriesMetadata> res = new ArrayList<>();\n\n    getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n\n    if (res.isEmpty()) {\n      if (debug) {\n        DEBUG_LOGGER.info(\n            \"Cache miss: {}.{} in file: {}\", key.device, key.measurement, key.filePath);\n        DEBUG_LOGGER.info(\"Device: {}, all sensors: {}\", key.device, allSensors);\n      }\n      // allow for the parallelism of different devices\n      synchronized (\n          devices.computeIfAbsent(key.device + SEPARATOR + key.filePath, WeakReference::new)) {\n        // double check\n        getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n        if (res.isEmpty()) {\n          Path path = new Path(key.device, key.measurement);\n          // bloom filter part\n          TsFileSequenceReader reader = FileReaderManager.getInstance().get(key.filePath, true);\n          BloomFilter bloomFilter = reader.readBloomFilter();\n          if (bloomFilter != null && !bloomFilter.contains(path.getFullPath())) {\n            if (debug) {\n              DEBUG_LOGGER.info(\"TimeSeries meta data {} is filter by bloomFilter!\", key);\n            }\n            return Collections.emptyList();\n          }\n          List<TimeseriesMetadata> timeSeriesMetadataList =\n              reader.readTimeseriesMetadata(path, allSensors);\n          Map<TimeSeriesMetadataCacheKey, TimeseriesMetadata> map = new HashMap<>();\n          // put TimeSeriesMetadata of all sensors used in this query into cache\n          timeSeriesMetadataList.forEach(\n              metadata -> {\n                // for root.sg1.d1.vector1.s1, key.device of vector will only return root.sg1.d1\n                // metadata.getMeasurementId() will return s1, the vector1 is saved in\n                // key.measurement\n                // so we should concat them to get the deviceId for root.sg1.d1.vector1.s1\n                TimeSeriesMetadataCacheKey k =\n                    new TimeSeriesMetadataCacheKey(\n                        key.filePath, key.device, metadata.getMeasurementId());\n                lruCache.put(k, metadata);\n                map.put(k, metadata);\n              });\n          // The reason we don't get from cache is in case that\n          // the cache capacity is too small to contains all the sub sensors of this vector\n          getVectorTimeSeriesMetadataListFromMap(key, subSensorList, res, map);\n        }\n      }\n    }\n    if (res.isEmpty()) {\n      if (debug) {\n        DEBUG_LOGGER.info(\"The file doesn't have this time series {}.\", key);\n      }\n      return Collections.emptyList();\n    } else {\n      if (debug) {\n        DEBUG_LOGGER.info(\n            \"Get timeseries: {}.{}  metadata in file: {}  from cache: {}.\",\n            key.device,\n            key.measurement,\n            key.filePath,\n            res);\n      }\n      for (int i = 0; i < res.size(); i++) {\n        res.set(i, new TimeseriesMetadata(res.get(i)));\n      }\n      return res;\n    }\n  }",
  "diff_func": "--- func_before\n+++ func_after\n @SuppressWarnings({\"squid:S1860\", \"squid:S3776\"})\n   public List<TimeseriesMetadata> get(\n       TimeSeriesMetadataCacheKey key,\n       List<String> subSensorList,\n       Set<String> allSensors,\n       boolean debug)\n       throws IOException {\n     // put all sub sensors into allSensors\n     allSensors.addAll(subSensorList);\n     if (!CACHE_ENABLE) {\n       // bloom filter part\n       TsFileSequenceReader reader = FileReaderManager.getInstance().get(key.filePath, true);\n       BloomFilter bloomFilter = reader.readBloomFilter();\n       if (bloomFilter != null\n           && !bloomFilter.contains(key.device + IoTDBConstant.PATH_SEPARATOR + key.measurement)) {\n         return Collections.emptyList();\n       }\n       return reader.readTimeseriesMetadata(new Path(key.device, key.measurement), subSensorList);\n     }\n \n-    cacheRequestNum.incrementAndGet();\n-\n     List<TimeseriesMetadata> res = new ArrayList<>();\n \n     getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n \n-    if (!res.isEmpty()) {\n+    if (res.isEmpty()) {\n-      cacheHitNum.incrementAndGet();\n-      printCacheLog(true);\n-    } else {\n       if (debug) {\n         DEBUG_LOGGER.info(\n             \"Cache miss: {}.{} in file: {}\", key.device, key.measurement, key.filePath);\n         DEBUG_LOGGER.info(\"Device: {}, all sensors: {}\", key.device, allSensors);\n       }\n       // allow for the parallelism of different devices\n       synchronized (\n           devices.computeIfAbsent(key.device + SEPARATOR + key.filePath, WeakReference::new)) {\n         // double check\n         getVectorTimeSeriesMetadataListFromCache(key, subSensorList, res);\n-        if (!res.isEmpty()) {\n+        if (res.isEmpty()) {\n-          cacheHitNum.incrementAndGet();\n-          printCacheLog(true);\n-        } else {\n           Path path = new Path(key.device, key.measurement);\n           // bloom filter part\n           TsFileSequenceReader reader = FileReaderManager.getInstance().get(key.fil",
  "diff_source": "custom"
}