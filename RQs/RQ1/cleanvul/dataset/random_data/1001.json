{
  "id": 1001,
  "language": "Java",
  "commit_url": "https://github.com/apache/kylin/commit/45341307d573c181fa343a34e95fc76b89a5e0ba",
  "commit_sha": "45341307d573c181fa343a34e95fc76b89a5e0ba",
  "commit_msg": "vuln-fix: Temporary File Information Disclosure\n\n\n\nThis fixes temporary file information disclosure vulnerability due to the use\nof the vulnerable `File.createTempFile()` method. The vulnerability is fixed by\nusing the `Files.createTempFile()` method which sets the correct posix permissions.\n\nWeakness: CWE-377: Insecure Temporary File\nSeverity: Medium\nCVSSS: 5.5\nDetection: CodeQL & OpenRewrite (https://public.moderne.io/recipes/org.openrewrite.java.security.SecureTempFileCreation)\n\nReported-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\nSigned-off-by: Jonathan Leitschuh <Jonathan.Leitschuh@gmail.com>\n\nBug-tracker: https://github.com/JLLeitschuh/security-research/issues/18\n\n\nCo-authored-by: Moderne <team@moderne.io>",
  "pr_url": "https://github.com/apache/kylin/pull/2135",
  "pr_info": "Bumps [h2](https://github.com/h2database/h2database) from 2.1.210 to 2.2.220.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/h2database/h2database/releases\">h2's releases</a>.</em></p>\n<blockquote>\n<h2>Version 2.2.220</h2>\n<p>Changes since 2.1.214 release:</p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/h2database/h2database/commit/66185fbfde24fbe5b2adf06fdaae4f5ffb178813\"><code>66185fb</code></a> changelog adjustment</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/f3c8222f3d77a8e71db2e6a72ea183c1931bfa6d\"><code>f3c8222</code></a> version and release date</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/087522bbc84c1b26417dd1ea348d8fbf839d5a32\"><code>087522b</code></a> javadoc</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/1ae052a1c0c87c687ac1d312e2bd69a4def652aa\"><code>1ae052a</code></a> spell-check</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/4ac534343ff7bde11bda681da39075cfa34ca440\"><code>4ac5343</code></a> Merge pull request <a href=\"https://redirect.github.com/h2database/h2database/issues/3834\">#3834</a> from katzyn/version</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/72f6e983789b0ff413ba110d218c18ded50cb7b8\"><code>72f6e98</code></a> Update TestMVStore</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/81bac50fed2f8418d83455e8d4c7fbf855bede89\"><code>81bac50</code></a> Update changelog</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/f047d77085d62cd1867edcf394944de46550d58a\"><code>f047d77</code></a> Add 2.0.* and 2.1.* versions to Upgrade utility</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/1341fea79e0d82d5967ecd19fba206a740870a69\"><code>1341fea</code></a> Increase database format version</li>\n<li><a href=\"https://github.com/h2database/h2database/commit/581ed18ff9d6b3761d851620ed88a3994a351a0d\"><code>581ed18</code></a> Merge pull request <a href=\"https://redirect.github.com/h2database/h2database/issues/3833\">#3833</a> from katzyn/password</li>\n<li>Additional commits viewable in <a href=\"https://github.com/h2database/h2database/compare/version-2.1.210...version-2.2.220\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.h2database:h2&package-manager=maven&previous-version=2.1.210&new-version=2.2.220)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/kylin/network/alerts).\n\n</details>",
  "file_name": "build-engine/src/main/java/org/apache/kylin/engine/mr/common/AbstractHadoopJob.java",
  "func_name": "dumpKylinPropsAndMetadata",
  "func_before": "protected void dumpKylinPropsAndMetadata(String prj, Set<String> dumpList, KylinConfig kylinConfig,\n            Configuration conf) throws IOException {\n        File tmp = File.createTempFile(\"kylin_job_meta\", \"\");\n        FileUtils.forceDelete(tmp); // we need a directory, so delete the file first\n\n        File metaDir = new File(tmp, \"meta\");\n        metaDir.mkdirs();\n\n        // write kylin.properties\n        File kylinPropsFile = new File(metaDir, \"kylin.properties\");\n        kylinConfig.exportToFile(kylinPropsFile);\n\n        if (prj != null) {\n            dumpList.add(ProjectManager.getInstance(kylinConfig).getProject(prj).getResourcePath());\n        }\n\n        if (prj != null) {\n            dumpList.add(ProjectManager.getInstance(kylinConfig).getProject(prj).getResourcePath());\n        }\n\n        // write resources\n        JobRelatedMetaUtil.dumpResources(kylinConfig, metaDir, dumpList);\n\n        // hadoop distributed cache\n        String hdfsMetaDir = OptionsHelper.convertToFileURL(metaDir.getAbsolutePath());\n        if (hdfsMetaDir.startsWith(\"/\")) // note Path on windows is like \"d:/../...\"\n            hdfsMetaDir = \"file://\" + hdfsMetaDir;\n        else\n            hdfsMetaDir = \"file:///\" + hdfsMetaDir;\n        logger.info(\"HDFS meta dir is: \" + hdfsMetaDir);\n\n        appendTmpFiles(hdfsMetaDir, conf);\n    }",
  "func_after": "protected void dumpKylinPropsAndMetadata(String prj, Set<String> dumpList, KylinConfig kylinConfig,\n            Configuration conf) throws IOException {\n        File tmp = Files.createTempFile(\"kylin_job_meta\", \"\").toFile();\n        FileUtils.forceDelete(tmp); // we need a directory, so delete the file first\n\n        File metaDir = new File(tmp, \"meta\");\n        metaDir.mkdirs();\n\n        // write kylin.properties\n        File kylinPropsFile = new File(metaDir, \"kylin.properties\");\n        kylinConfig.exportToFile(kylinPropsFile);\n\n        if (prj != null) {\n            dumpList.add(ProjectManager.getInstance(kylinConfig).getProject(prj).getResourcePath());\n        }\n\n        if (prj != null) {\n            dumpList.add(ProjectManager.getInstance(kylinConfig).getProject(prj).getResourcePath());\n        }\n\n        // write resources\n        JobRelatedMetaUtil.dumpResources(kylinConfig, metaDir, dumpList);\n\n        // hadoop distributed cache\n        String hdfsMetaDir = OptionsHelper.convertToFileURL(metaDir.getAbsolutePath());\n        if (hdfsMetaDir.startsWith(\"/\")) // note Path on windows is like \"d:/../...\"\n            hdfsMetaDir = \"file://\" + hdfsMetaDir;\n        else\n            hdfsMetaDir = \"file:///\" + hdfsMetaDir;\n        logger.info(\"HDFS meta dir is: \" + hdfsMetaDir);\n\n        appendTmpFiles(hdfsMetaDir, conf);\n    }",
  "diff_func": "--- func_before\n+++ func_after\n protected void dumpKylinPropsAndMetadata(String prj, Set<String> dumpList, KylinConfig kylinConfig,\n             Configuration conf) throws IOException {\n-        File tmp = File.createTempFile(\"kylin_job_meta\", \"\");\n+        File tmp = Files.createTempFile(\"kylin_job_meta\", \"\").toFile();\n         FileUtils.forceDelete(tmp); // we need a directory, so delete the file first\n \n         File metaDir = new File(tmp, \"meta\");\n         metaDir.mkdirs();\n \n         // write kylin.properties\n         File kylinPropsFile = new File(metaDir, \"kylin.properties\");\n         kylinConfig.exportToFile(kylinPropsFile);\n \n         if (prj != null) {\n             dumpList.add(ProjectManager.getInstance(kylinConfig).getProject(prj).getResourcePath());\n         }\n \n         if (prj != null) {\n             dumpList.add(ProjectManager.getInstance(kylinConfig).getProject(prj).getResourcePath());\n         }\n \n         // write resources\n         JobRelatedMetaUtil.dumpResources(kylinConfig, metaDir, dumpList);\n \n         // hadoop distributed cache\n         String hdfsMetaDir = OptionsHelper.convertToFileURL(metaDir.getAbsolutePath());\n         if (hdfsMetaDir.startsWith(\"/\")) // note Path on windows is like \"d:/../...\"\n             hdfsMetaDir = \"file://\" + hdfsMetaDir;\n         else\n             hdfsMetaDir = \"file:///\" + hdfsMetaDir;\n         logger.info(\"HDFS meta dir is: \" + hdfsMetaDir);\n \n         appendTmpFiles(hdfsMetaDir, conf);\n     }",
  "diff_source": "custom"
}