{
  "cve_id": "CVE-2023-25667",
  "cwe_ids": [
    "CWE-190"
  ],
  "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
  "cvss_is_v3": true,
  "repo_name": "tensorflow",
  "commit_msg": "Fix integer overflow for multiframe gifs.",
  "commit_hash": "8dc723fcdd1a6127d6c970bd2ecb18b019a1a58d",
  "git_url": "https://github.com/tensorflow/tensorflow/commit/8dc723fcdd1a6127d6c970bd2ecb18b019a1a58d",
  "file_path": "tensorflow/core/kernels/image/decode_image_op.cc",
  "func_name": "DecodeGifV2",
  "func_before": "void DecodeGifV2(OpKernelContext* context, StringPiece input) {\n    // GIF has 3 channels.\n    OP_REQUIRES(context, channels_ == 0 || channels_ == 3,\n                errors::InvalidArgument(\"channels must be 0 or 3 for GIF, got \",\n                                        channels_));\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode GIF format using DecodeBmp op. Use \"\n                      \"`decode_gif` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected GIF.\"));\n    }\n\n    // Decode GIF, allocating tensor if dtype is uint8, otherwise defer tensor\n    // allocation til after dtype conversion is done. `gif`::Decode` supports\n    // uint8 only.\n    Tensor* output = nullptr;\n    int buffer_size = 0;\n    string error_string;\n    uint8* buffer = gif::Decode(\n        input.data(), input.size(),\n        [&](int num_frames, int width, int height, int channels) -> uint8* {\n          buffer_size = num_frames * height * width * channels;\n\n          Status status;\n          // By the existing API, we support decoding GIF with `decode_jpeg` or\n          // with `decode_png` if the GIF is a single-frame GIF (non-animated).\n          // We need to make sure to return 3-D shapes when using in this case.\n          if (op_type_ == \"DecodePng\" || op_type_ == \"DecodeJpeg\") {\n            if (num_frames == 1) {\n              status = context->allocate_output(\n                  0, TensorShape({height, width, channels}), &output);\n            } else {\n              status = errors::InvalidArgument(\n                  \"Got \", num_frames, \" frames, but animated gifs \",\n                  \"can only be decoded by tf.io.decode_gif or \",\n                  \"tf.io.decode_image\");\n            }\n          } else if (op_type_ == \"DecodeGif\" ||\n                     (op_type_ == \"DecodeImage\" && expand_animations_)) {\n            status = context->allocate_output(\n                0, TensorShape({num_frames, height, width, channels}), &output);\n          } else if (op_type_ == \"DecodeImage\" && !expand_animations_) {\n            status = context->allocate_output(\n                0, TensorShape({height, width, channels}), &output);\n          } else {\n            status = errors::InvalidArgument(\"Bad op type \", op_type_);\n          }\n          if (!status.ok()) {\n            VLOG(1) << status;\n            context->SetStatus(status);\n            return nullptr;\n          }\n\n          if (data_type_ == DataType::DT_UINT8) {\n            return output->flat<uint8>().data();\n          } else {\n            return new uint8[buffer_size];\n          }\n        },\n        &error_string, expand_animations_);\n\n    OP_REQUIRES(context, buffer,\n                errors::InvalidArgument(\"Invalid GIF data (size \", input.size(),\n                                        \"), \", error_string));\n\n    // For when desired data type is uint8, the output buffer is already\n    // allocated during the `gif::Decode` call above; return.\n    if (data_type_ == DataType::DT_UINT8) {\n      return;\n    }\n    // Make sure we don't forget to deallocate `buffer`.\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    // Convert the raw uint8 buffer to desired dtype.\n    // Use eigen threadpooling to speed up the copy operation.\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n    if (data_type_ == DataType::DT_UINT16) {\n      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      // Fill output tensor with desired dtype.\n      output->flat<uint16>().device(device) =\n          buffer_view.cast<uint16>() * scale;\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      float scale = 1. / std::numeric_limits<uint8>::max();\n      // Fill output tensor with desired dtype.\n      output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n    }\n  }",
  "abstract_func_before": "void DecodeGifV2(OpKernelContext* VAR_0, StringPiece VAR_1) {\n    /* COMMENT_0 */\n    OP_REQUIRES(VAR_0, VAR_2 == 0 || VAR_2 == 3,\n                errors::InvalidArgument(\"channels must be 0 or 3 for GIF, got \",\n                                        VAR_2));\n\n    if (VAR_3 == \"DecodeBmp\") {\n      /* COMMENT_1 */\n      /* COMMENT_2 */\n      /* COMMENT_3 */\n      /* COMMENT_4 */\n      /* COMMENT_5 */\n      OP_REQUIRES(VAR_0, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode GIF format using DecodeBmp op. Use \"\n                      \"`decode_gif` or `decode_image` instead.\"));\n    } else if (VAR_3 == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(VAR_0, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected GIF.\"));\n    }\n\n    /* COMMENT_6 */\n    /* COMMENT_7 */\n    /* COMMENT_8 */\n    Tensor* VAR_4 = nullptr;\n    int VAR_5 = 0;\n    string VAR_6;\n    uint8* VAR_7 = gif::Decode(\n        VAR_1.data(), VAR_1.size(),\n        [&](int VAR_8, int VAR_9, int VAR_10, int VAR_11) -> uint8* {\n          VAR_5 = VAR_8 * VAR_10 * VAR_9 * VAR_11;\n\n          Status VAR_12;\n          /* COMMENT_9 */\n          /* COMMENT_10 */\n          /* COMMENT_11 */\n          if (VAR_3 == \"DecodePng\" || VAR_3 == \"DecodeJpeg\") {\n            if (VAR_8 == 1) {\n              VAR_12 = VAR_0->allocate_output(\n                  0, TensorShape({VAR_10, VAR_9, VAR_11}), &VAR_4);\n            } else {\n              VAR_12 = errors::InvalidArgument(\n                  \"Got \", VAR_8, \" frames, but animated gifs \",\n                  \"can only be decoded by tf.io.decode_gif or \",\n                  \"tf.io.decode_image\");\n            }\n          } else if (VAR_3 == \"DecodeGif\" ||\n                     (VAR_3 == \"DecodeImage\" && VAR_13)) {\n            VAR_12 = VAR_0->allocate_output(\n                0, TensorShape({VAR_8, VAR_10, VAR_9, VAR_11}), &VAR_4);\n          } else if (VAR_3 == \"DecodeImage\" && !VAR_13) {\n            VAR_12 = VAR_0->allocate_output(\n                0, TensorShape({VAR_10, VAR_9, VAR_11}), &VAR_4);\n          } else {\n            VAR_12 = errors::InvalidArgument(\"Bad op type \", VAR_3);\n          }\n          if (!VAR_12.ok()) {\n            VLOG(1) << VAR_12;\n            VAR_0->SetStatus(VAR_12);\n            return nullptr;\n          }\n\n          if (VAR_14 == DataType::DT_UINT8) {\n            return VAR_4->flat<uint8>().data();\n          } else {\n            return new uint8[VAR_5];\n          }\n        },\n        &VAR_6, VAR_13);\n\n    OP_REQUIRES(VAR_0, VAR_7,\n                errors::InvalidArgument(\"Invalid GIF data (size \", VAR_1.size(),\n                                        \"), \", VAR_6));\n\n    /* COMMENT_12 */\n    /* COMMENT_13 */\n    if (VAR_14 == DataType::DT_UINT8) {\n      return;\n    }\n    /* COMMENT_14 */\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    /* COMMENT_15 */\n    /* COMMENT_16 */\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    const auto& VAR_15 = VAR_0->eigen_device<Eigen::ThreadPoolDevice>();\n    if (VAR_14 == DataType::DT_UINT16) {\n      uint16 VAR_16 = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      /* COMMENT_17 */\n      VAR_4->flat<uint16>().device(VAR_15) =\n          VAR_17.cast<uint16>() * VAR_16;\n    } else if (VAR_14 == DataType::DT_FLOAT) {\n      float VAR_16 = 1. / std::numeric_limits<uint8>::max();\n      /* COMMENT_17 */\n      VAR_4->flat<float>().device(VAR_15) = VAR_17.cast<float>() * VAR_16;\n    }\n  }",
  "func_graph_path_before": "tensorflow/8dc723fcdd1a6127d6c970bd2ecb18b019a1a58d/decode_image_op.cc/vul/before/0.json",
  "func": "void DecodeGifV2(OpKernelContext* context, StringPiece input) {\n    // GIF has 3 channels.\n    OP_REQUIRES(context, channels_ == 0 || channels_ == 3,\n                errors::InvalidArgument(\"channels must be 0 or 3 for GIF, got \",\n                                        channels_));\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode GIF format using DecodeBmp op. Use \"\n                      \"`decode_gif` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected GIF.\"));\n    }\n\n    // Decode GIF, allocating tensor if dtype is uint8, otherwise defer tensor\n    // allocation til after dtype conversion is done. `gif`::Decode` supports\n    // uint8 only.\n    Tensor* output = nullptr;\n    ptrdiff_t buffer_size = 0;\n    string error_string;\n    uint8* buffer = gif::Decode(\n        input.data(), input.size(),\n        [&](int num_frames, int width, int height, int channels) -> uint8* {\n          buffer_size = ptrdiff_t(num_frames) * height * width * channels;\n\n          Status status;\n          // By the existing API, we support decoding GIF with `decode_jpeg` or\n          // with `decode_png` if the GIF is a single-frame GIF (non-animated).\n          // We need to make sure to return 3-D shapes when using in this case.\n          if (op_type_ == \"DecodePng\" || op_type_ == \"DecodeJpeg\") {\n            if (num_frames == 1) {\n              status = context->allocate_output(\n                  0, TensorShape({height, width, channels}), &output);\n            } else {\n              status = errors::InvalidArgument(\n                  \"Got \", num_frames, \" frames, but animated gifs \",\n                  \"can only be decoded by tf.io.decode_gif or \",\n                  \"tf.io.decode_image\");\n            }\n          } else if (op_type_ == \"DecodeGif\" ||\n                     (op_type_ == \"DecodeImage\" && expand_animations_)) {\n            status = context->allocate_output(\n                0, TensorShape({num_frames, height, width, channels}), &output);\n          } else if (op_type_ == \"DecodeImage\" && !expand_animations_) {\n            status = context->allocate_output(\n                0, TensorShape({height, width, channels}), &output);\n          } else {\n            status = errors::InvalidArgument(\"Bad op type \", op_type_);\n          }\n          if (!status.ok()) {\n            VLOG(1) << status;\n            context->SetStatus(status);\n            return nullptr;\n          }\n\n          if (data_type_ == DataType::DT_UINT8) {\n            return output->flat<uint8>().data();\n          } else {\n            return new uint8[buffer_size];\n          }\n        },\n        &error_string, expand_animations_);\n\n    OP_REQUIRES(context, buffer,\n                errors::InvalidArgument(\"Invalid GIF data (size \", input.size(),\n                                        \"), \", error_string));\n\n    // For when desired data type is uint8, the output buffer is already\n    // allocated during the `gif::Decode` call above; return.\n    if (data_type_ == DataType::DT_UINT8) {\n      return;\n    }\n    // Make sure we don't forget to deallocate `buffer`.\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    // Convert the raw uint8 buffer to desired dtype.\n    // Use eigen threadpooling to speed up the copy operation.\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n    if (data_type_ == DataType::DT_UINT16) {\n      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      // Fill output tensor with desired dtype.\n      output->flat<uint16>().device(device) =\n          buffer_view.cast<uint16>() * scale;\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      float scale = 1. / std::numeric_limits<uint8>::max();\n      // Fill output tensor with desired dtype.\n      output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n    }\n  }",
  "abstract_func": "void DecodeGifV2(OpKernelContext* VAR_0, StringPiece VAR_1) {\n    /* COMMENT_0 */\n    OP_REQUIRES(VAR_0, VAR_2 == 0 || VAR_2 == 3,\n                errors::InvalidArgument(\"channels must be 0 or 3 for GIF, got \",\n                                        VAR_2));\n\n    if (VAR_3 == \"DecodeBmp\") {\n      /* COMMENT_1 */\n      /* COMMENT_2 */\n      /* COMMENT_3 */\n      /* COMMENT_4 */\n      /* COMMENT_5 */\n      OP_REQUIRES(VAR_0, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode GIF format using DecodeBmp op. Use \"\n                      \"`decode_gif` or `decode_image` instead.\"));\n    } else if (VAR_3 == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(VAR_0, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected GIF.\"));\n    }\n\n    /* COMMENT_6 */\n    /* COMMENT_7 */\n    /* COMMENT_8 */\n    Tensor* VAR_4 = nullptr;\n    ptrdiff_t VAR_5 = 0;\n    string VAR_6;\n    uint8* VAR_7 = gif::Decode(\n        VAR_1.data(), VAR_1.size(),\n        [&](int VAR_8, int VAR_9, int VAR_10, int VAR_11) -> uint8* {\n          VAR_5 = ptrdiff_t(VAR_8) * VAR_10 * VAR_9 * VAR_11;\n\n          Status VAR_12;\n          /* COMMENT_9 */\n          /* COMMENT_10 */\n          /* COMMENT_11 */\n          if (VAR_3 == \"DecodePng\" || VAR_3 == \"DecodeJpeg\") {\n            if (VAR_8 == 1) {\n              VAR_12 = VAR_0->allocate_output(\n                  0, TensorShape({VAR_10, VAR_9, VAR_11}), &VAR_4);\n            } else {\n              VAR_12 = errors::InvalidArgument(\n                  \"Got \", VAR_8, \" frames, but animated gifs \",\n                  \"can only be decoded by tf.io.decode_gif or \",\n                  \"tf.io.decode_image\");\n            }\n          } else if (VAR_3 == \"DecodeGif\" ||\n                     (VAR_3 == \"DecodeImage\" && VAR_13)) {\n            VAR_12 = VAR_0->allocate_output(\n                0, TensorShape({VAR_8, VAR_10, VAR_9, VAR_11}), &VAR_4);\n          } else if (VAR_3 == \"DecodeImage\" && !VAR_13) {\n            VAR_12 = VAR_0->allocate_output(\n                0, TensorShape({VAR_10, VAR_9, VAR_11}), &VAR_4);\n          } else {\n            VAR_12 = errors::InvalidArgument(\"Bad op type \", VAR_3);\n          }\n          if (!VAR_12.ok()) {\n            VLOG(1) << VAR_12;\n            VAR_0->SetStatus(VAR_12);\n            return nullptr;\n          }\n\n          if (VAR_14 == DataType::DT_UINT8) {\n            return VAR_4->flat<uint8>().data();\n          } else {\n            return new uint8[VAR_5];\n          }\n        },\n        &VAR_6, VAR_13);\n\n    OP_REQUIRES(VAR_0, VAR_7,\n                errors::InvalidArgument(\"Invalid GIF data (size \", VAR_1.size(),\n                                        \"), \", VAR_6));\n\n    /* COMMENT_12 */\n    /* COMMENT_13 */\n    if (VAR_14 == DataType::DT_UINT8) {\n      return;\n    }\n    /* COMMENT_14 */\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    /* COMMENT_15 */\n    /* COMMENT_16 */\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    const auto& VAR_15 = VAR_0->eigen_device<Eigen::ThreadPoolDevice>();\n    if (VAR_14 == DataType::DT_UINT16) {\n      uint16 VAR_16 = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      /* COMMENT_17 */\n      VAR_4->flat<uint16>().device(VAR_15) =\n          VAR_17.cast<uint16>() * VAR_16;\n    } else if (VAR_14 == DataType::DT_FLOAT) {\n      float VAR_16 = 1. / std::numeric_limits<uint8>::max();\n      /* COMMENT_17 */\n      VAR_4->flat<float>().device(VAR_15) = VAR_17.cast<float>() * VAR_16;\n    }\n  }",
  "func_graph_path": "tensorflow/8dc723fcdd1a6127d6c970bd2ecb18b019a1a58d/decode_image_op.cc/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -25,12 +25,12 @@\n     // allocation til after dtype conversion is done. `gif`::Decode` supports\n     // uint8 only.\n     Tensor* output = nullptr;\n-    int buffer_size = 0;\n+    ptrdiff_t buffer_size = 0;\n     string error_string;\n     uint8* buffer = gif::Decode(\n         input.data(), input.size(),\n         [&](int num_frames, int width, int height, int channels) -> uint8* {\n-          buffer_size = num_frames * height * width * channels;\n+          buffer_size = ptrdiff_t(num_frames) * height * width * channels;\n \n           Status status;\n           // By the existing API, we support decoding GIF with `decode_jpeg` or",
  "diff_line_info": {
    "deleted_lines": [
      "    int buffer_size = 0;",
      "          buffer_size = num_frames * height * width * channels;"
    ],
    "added_lines": [
      "    ptrdiff_t buffer_size = 0;",
      "          buffer_size = ptrdiff_t(num_frames) * height * width * channels;"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/tensorflow/tensorflow/pull/58104",
  "description": {
    "pr_info": {
      "title": "Fix segfault for multiframe gifs.",
      "number": 58104
    },
    "comment": [
      "Integer overflow occurs when 2^31 <= num_frames * height * width * channels < 2^32, for example Full HD screencast of at least 346 frames."
    ]
  },
  "Bug Filter": "Defect Remediation & Feature Upgrades",
  "Bug Filter Confidence": 0.95,
  "Bug Filter Response": "\n\n**Final Output:**\nAnalysis: The patch addresses an integer overflow issue in handling multiframe GIFs, preventing a segmentation fault. The overflow occurs with legitimate input sizes, not attacker-controlled inputs, thus it's a stability bug fix.\nFinal Classification: Defect Remediation & Feature Upgrades\nConfidence Score: 0.95"
}