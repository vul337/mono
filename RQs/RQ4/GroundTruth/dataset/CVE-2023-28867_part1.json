{
  "cve_id": "CVE-2023-28867",
  "cwe_ids": [
    "CWE-770"
  ],
  "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
  "cvss_is_v3": true,
  "repo_name": "graphql-java",
  "commit_msg": "Preventing stack overflow exceptions via limiting the depth of the parser rules",
  "commit_hash": "8a1c884c81c0b656db201cfd95881feb0f430a55",
  "git_url": "https://github.com/graphql-java/graphql-java/commit/8a1c884c81c0b656db201cfd95881feb0f430a55",
  "file_path": "src/main/java/graphql/parser/Parser.java",
  "func_name": "parseImpl",
  "func_before": "private Node<?> parseImpl(ParserEnvironment environment, BiFunction<GraphqlParser, GraphqlAntlrToLanguage, Object[]> nodeFunction) throws InvalidSyntaxException {\n        // default in the parser options if they are not set\n        ParserOptions parserOptions = environment.getParserOptions();\n        parserOptions = Optional.ofNullable(parserOptions).orElse(ParserOptions.getDefaultParserOptions());\n\n        MultiSourceReader multiSourceReader;\n        Reader reader = environment.getDocument();\n        if (reader instanceof MultiSourceReader) {\n            multiSourceReader = (MultiSourceReader) reader;\n        } else {\n            multiSourceReader = MultiSourceReader.newMultiSourceReader()\n                    .reader(reader, null)\n                    .trackData(parserOptions.isReaderTrackData())\n                    .build();\n        }\n        CodePointCharStream charStream;\n        try {\n            charStream = CharStreams.fromReader(multiSourceReader);\n        } catch (IOException e) {\n            throw new UncheckedIOException(e);\n        }\n\n        GraphqlLexer lexer = new GraphqlLexer(charStream);\n        lexer.removeErrorListeners();\n        lexer.addErrorListener(new BaseErrorListener() {\n            @Override\n            public void syntaxError(Recognizer<?, ?> recognizer, Object offendingSymbol, int line, int charPositionInLine, String antlerMsg, RecognitionException e) {\n                SourceLocation sourceLocation = AntlrHelper.createSourceLocation(multiSourceReader, line, charPositionInLine);\n                String preview = AntlrHelper.createPreview(multiSourceReader, line);\n                String msgKey;\n                List<Object> args;\n                if (antlerMsg == null) {\n                    msgKey = \"InvalidSyntax.noMessage\";\n                    args = ImmutableList.of(sourceLocation.getLine(), sourceLocation.getColumn());\n                } else {\n                    msgKey = \"InvalidSyntax.full\";\n                    args = ImmutableList.of(antlerMsg, sourceLocation.getLine(), sourceLocation.getColumn());\n                }\n                String msg = environment.getI18N().msg(msgKey, args);\n                throw new InvalidSyntaxException(msg, sourceLocation, null, preview, null);\n            }\n        });\n\n        // this lexer wrapper allows us to stop lexing when too many tokens are in place.  This prevents DOS attacks.\n        int maxTokens = parserOptions.getMaxTokens();\n        int maxWhitespaceTokens = parserOptions.getMaxWhitespaceTokens();\n        BiConsumer<Integer, Token> onTooManyTokens = (maxTokenCount, token) -> throwCancelParseIfTooManyTokens(environment, token, maxTokenCount, multiSourceReader);\n        SafeTokenSource safeTokenSource = new SafeTokenSource(lexer, maxTokens, maxWhitespaceTokens, onTooManyTokens);\n\n        CommonTokenStream tokens = new CommonTokenStream(safeTokenSource);\n\n        GraphqlParser parser = new GraphqlParser(tokens);\n        parser.removeErrorListeners();\n        parser.getInterpreter().setPredictionMode(PredictionMode.SLL);\n\n        ExtendedBailStrategy bailStrategy = new ExtendedBailStrategy(multiSourceReader, environment);\n        parser.setErrorHandler(bailStrategy);\n\n        // preserve old protected call semantics - remove at some point\n        GraphqlAntlrToLanguage toLanguage = getAntlrToLanguage(tokens, multiSourceReader, environment);\n\n        setupParserListener(environment, multiSourceReader, parser, toLanguage);\n\n\n        //\n        // parsing starts ...... now!\n        //\n        Object[] contextAndNode = nodeFunction.apply(parser, toLanguage);\n        ParserRuleContext parserRuleContext = (ParserRuleContext) contextAndNode[0];\n        Node<?> node = (Node<?>) contextAndNode[1];\n\n        Token stop = parserRuleContext.getStop();\n        List<Token> allTokens = tokens.getTokens();\n        if (stop != null && allTokens != null && !allTokens.isEmpty()) {\n            Token last = allTokens.get(allTokens.size() - 1);\n            //\n            // do we have more tokens in the stream than we consumed in the parse?\n            // if yes then it's invalid.  We make sure it's the same channel\n            boolean notEOF = last.getType() != Token.EOF;\n            boolean lastGreaterThanDocument = last.getTokenIndex() > stop.getTokenIndex();\n            boolean sameChannel = last.getChannel() == stop.getChannel();\n            if (notEOF && lastGreaterThanDocument && sameChannel) {\n                throw bailStrategy.mkMoreTokensException(last);\n            }\n        }\n        return node;\n    }",
  "abstract_func_before": "private Node<?> parseImpl(ParserEnvironment VAR_0, BiFunction<GraphqlParser, GraphqlAntlrToLanguage, Object[]> VAR_1) throws InvalidSyntaxException {\n        /* COMMENT_0 */\n        ParserOptions VAR_2 = VAR_0.getParserOptions();\n        VAR_2 = VAR_3.ofNullable(VAR_2).orElse(VAR_4.getDefaultParserOptions());\n\n        MultiSourceReader VAR_5;\n        Reader VAR_6 = VAR_0.getDocument();\n        if (VAR_6 instanceof MultiSourceReader) {\n            VAR_5 = (MultiSourceReader) VAR_6;\n        } else {\n            VAR_5 = VAR_7.newMultiSourceReader()\n                    .reader(VAR_6, null)\n                    .trackData(VAR_2.isReaderTrackData())\n                    .build();\n        }\n        CodePointCharStream VAR_8;\n        try {\n            VAR_8 = VAR_9.fromReader(VAR_5);\n        } catch (IOException VAR_10) {\n            throw new UncheckedIOException(VAR_10);\n        }\n\n        GraphqlLexer VAR_11 = new GraphqlLexer(VAR_8);\n        VAR_11.removeErrorListeners();\n        VAR_11.addErrorListener(new BaseErrorListener() {\n            @Override\n            public void syntaxError(Recognizer<?, ?> VAR_12, Object VAR_13, int VAR_14, int VAR_15, String VAR_16, RecognitionException VAR_10) {\n                SourceLocation VAR_17 = VAR_18.createSourceLocation(VAR_5, VAR_14, VAR_15);\n                String VAR_19 = VAR_18.createPreview(VAR_5, VAR_14);\n                String VAR_20;\n                List<Object> VAR_21;\n                if (VAR_16 == null) {\n                    VAR_20 = \"InvalidSyntax.noMessage\";\n                    VAR_21 = VAR_22.of(VAR_17.getLine(), VAR_17.getColumn());\n                } else {\n                    VAR_20 = \"InvalidSyntax.full\";\n                    VAR_21 = VAR_22.of(VAR_16, VAR_17.getLine(), VAR_17.getColumn());\n                }\n                String VAR_23 = VAR_0.getI18N().msg(VAR_20, VAR_21);\n                throw new InvalidSyntaxException(VAR_23, VAR_17, null, VAR_19, null);\n            }\n        });\n\n        /* COMMENT_1 */\n        int VAR_24 = VAR_2.getMaxTokens();\n        int VAR_25 = VAR_2.getMaxWhitespaceTokens();\n        BiConsumer<Integer, Token> VAR_26 = (VAR_27, VAR_28) -> throwCancelParseIfTooManyTokens(VAR_0, VAR_28, VAR_27, VAR_5);\n        SafeTokenSource VAR_29 = new SafeTokenSource(VAR_11, VAR_24, VAR_25, VAR_26);\n\n        CommonTokenStream VAR_30 = new CommonTokenStream(VAR_29);\n\n        GraphqlParser VAR_31 = new GraphqlParser(VAR_30);\n        VAR_31.removeErrorListeners();\n        VAR_31.getInterpreter().setPredictionMode(VAR_32.SLL);\n\n        ExtendedBailStrategy VAR_33 = new ExtendedBailStrategy(VAR_5, VAR_0);\n        VAR_31.setErrorHandler(VAR_33);\n\n        /* COMMENT_2 */\n        GraphqlAntlrToLanguage VAR_34 = getAntlrToLanguage(VAR_30, VAR_5, VAR_0);\n\n        setupParserListener(VAR_0, VAR_5, VAR_31, VAR_34);\n\n\n        /* COMMENT_3 */\n        /* COMMENT_4 */\n        /* COMMENT_3 */\n        Object[] VAR_35 = VAR_1.apply(VAR_31, VAR_34);\n        ParserRuleContext VAR_36 = (ParserRuleContext) VAR_35[0];\n        Node<?> VAR_37 = (Node<?>) VAR_35[1];\n\n        Token VAR_38 = VAR_36.getStop();\n        List<Token> VAR_39 = VAR_30.getTokens();\n        if (VAR_38 != null && VAR_39 != null && !VAR_39.isEmpty()) {\n            Token VAR_40 = VAR_39.get(VAR_39.size() - 1);\n            /* COMMENT_3 */\n            /* COMMENT_5 */\n            /* COMMENT_6 */\n            boolean VAR_41 = VAR_40.getType() != VAR_42.EOF;\n            boolean VAR_43 = VAR_40.getTokenIndex() > VAR_38.getTokenIndex();\n            boolean VAR_44 = VAR_40.getChannel() == VAR_38.getChannel();\n            if (VAR_41 && VAR_43 && VAR_44) {\n                throw VAR_33.mkMoreTokensException(VAR_40);\n            }\n        }\n        return VAR_37;\n    }",
  "func_graph_path_before": "graphql-java/8a1c884c81c0b656db201cfd95881feb0f430a55/Parser.java/vul/before/0.json",
  "func": "private Node<?> parseImpl(ParserEnvironment environment, BiFunction<GraphqlParser, GraphqlAntlrToLanguage, Object[]> nodeFunction) throws InvalidSyntaxException {\n        // default in the parser options if they are not set\n        ParserOptions parserOptions = environment.getParserOptions();\n        parserOptions = Optional.ofNullable(parserOptions).orElse(ParserOptions.getDefaultParserOptions());\n\n        MultiSourceReader multiSourceReader;\n        Reader reader = environment.getDocument();\n        if (reader instanceof MultiSourceReader) {\n            multiSourceReader = (MultiSourceReader) reader;\n        } else {\n            multiSourceReader = MultiSourceReader.newMultiSourceReader()\n                    .reader(reader, null)\n                    .trackData(parserOptions.isReaderTrackData())\n                    .build();\n        }\n        CodePointCharStream charStream;\n        try {\n            charStream = CharStreams.fromReader(multiSourceReader);\n        } catch (IOException e) {\n            throw new UncheckedIOException(e);\n        }\n\n        GraphqlLexer lexer = new GraphqlLexer(charStream);\n        lexer.removeErrorListeners();\n        lexer.addErrorListener(new BaseErrorListener() {\n            @Override\n            public void syntaxError(Recognizer<?, ?> recognizer, Object offendingSymbol, int line, int charPositionInLine, String antlerMsg, RecognitionException e) {\n                SourceLocation sourceLocation = AntlrHelper.createSourceLocation(multiSourceReader, line, charPositionInLine);\n                String preview = AntlrHelper.createPreview(multiSourceReader, line);\n                String msgKey;\n                List<Object> args;\n                if (antlerMsg == null) {\n                    msgKey = \"InvalidSyntax.noMessage\";\n                    args = ImmutableList.of(sourceLocation.getLine(), sourceLocation.getColumn());\n                } else {\n                    msgKey = \"InvalidSyntax.full\";\n                    args = ImmutableList.of(antlerMsg, sourceLocation.getLine(), sourceLocation.getColumn());\n                }\n                String msg = environment.getI18N().msg(msgKey, args);\n                throw new InvalidSyntaxException(msg, sourceLocation, null, preview, null);\n            }\n        });\n\n        // this lexer wrapper allows us to stop lexing when too many tokens are in place.  This prevents DOS attacks.\n        int maxTokens = parserOptions.getMaxTokens();\n        int maxWhitespaceTokens = parserOptions.getMaxWhitespaceTokens();\n        BiConsumer<Integer, Token> onTooManyTokens = (maxTokenCount, token) -> throwIfTokenProblems(\n                environment,\n                token,\n                maxTokenCount,\n                multiSourceReader,\n                ParseCancelledException.class);\n        SafeTokenSource safeTokenSource = new SafeTokenSource(lexer, maxTokens, maxWhitespaceTokens, onTooManyTokens);\n\n        CommonTokenStream tokens = new CommonTokenStream(safeTokenSource);\n\n        GraphqlParser parser = new GraphqlParser(tokens);\n        parser.removeErrorListeners();\n        parser.getInterpreter().setPredictionMode(PredictionMode.SLL);\n\n        ExtendedBailStrategy bailStrategy = new ExtendedBailStrategy(multiSourceReader, environment);\n        parser.setErrorHandler(bailStrategy);\n\n        // preserve old protected call semantics - remove at some point\n        GraphqlAntlrToLanguage toLanguage = getAntlrToLanguage(tokens, multiSourceReader, environment);\n\n        setupParserListener(environment, multiSourceReader, parser, toLanguage);\n\n\n        //\n        // parsing starts ...... now!\n        //\n        Object[] contextAndNode = nodeFunction.apply(parser, toLanguage);\n        ParserRuleContext parserRuleContext = (ParserRuleContext) contextAndNode[0];\n        Node<?> node = (Node<?>) contextAndNode[1];\n\n        Token stop = parserRuleContext.getStop();\n        List<Token> allTokens = tokens.getTokens();\n        if (stop != null && allTokens != null && !allTokens.isEmpty()) {\n            Token last = allTokens.get(allTokens.size() - 1);\n            //\n            // do we have more tokens in the stream than we consumed in the parse?\n            // if yes then it's invalid.  We make sure it's the same channel\n            boolean notEOF = last.getType() != Token.EOF;\n            boolean lastGreaterThanDocument = last.getTokenIndex() > stop.getTokenIndex();\n            boolean sameChannel = last.getChannel() == stop.getChannel();\n            if (notEOF && lastGreaterThanDocument && sameChannel) {\n                throw bailStrategy.mkMoreTokensException(last);\n            }\n        }\n        return node;\n    }",
  "abstract_func": "private Node<?> parseImpl(ParserEnvironment VAR_0, BiFunction<GraphqlParser, GraphqlAntlrToLanguage, Object[]> VAR_1) throws InvalidSyntaxException {\n        /* COMMENT_0 */\n        ParserOptions VAR_2 = VAR_0.getParserOptions();\n        VAR_2 = VAR_3.ofNullable(VAR_2).orElse(VAR_4.getDefaultParserOptions());\n\n        MultiSourceReader VAR_5;\n        Reader VAR_6 = VAR_0.getDocument();\n        if (VAR_6 instanceof MultiSourceReader) {\n            VAR_5 = (MultiSourceReader) VAR_6;\n        } else {\n            VAR_5 = VAR_7.newMultiSourceReader()\n                    .reader(VAR_6, null)\n                    .trackData(VAR_2.isReaderTrackData())\n                    .build();\n        }\n        CodePointCharStream VAR_8;\n        try {\n            VAR_8 = VAR_9.fromReader(VAR_5);\n        } catch (IOException VAR_10) {\n            throw new UncheckedIOException(VAR_10);\n        }\n\n        GraphqlLexer VAR_11 = new GraphqlLexer(VAR_8);\n        VAR_11.removeErrorListeners();\n        VAR_11.addErrorListener(new BaseErrorListener() {\n            @Override\n            public void syntaxError(Recognizer<?, ?> VAR_12, Object VAR_13, int VAR_14, int VAR_15, String VAR_16, RecognitionException VAR_10) {\n                SourceLocation VAR_17 = VAR_18.createSourceLocation(VAR_5, VAR_14, VAR_15);\n                String VAR_19 = VAR_18.createPreview(VAR_5, VAR_14);\n                String VAR_20;\n                List<Object> VAR_21;\n                if (VAR_16 == null) {\n                    VAR_20 = \"InvalidSyntax.noMessage\";\n                    VAR_21 = VAR_22.of(VAR_17.getLine(), VAR_17.getColumn());\n                } else {\n                    VAR_20 = \"InvalidSyntax.full\";\n                    VAR_21 = VAR_22.of(VAR_16, VAR_17.getLine(), VAR_17.getColumn());\n                }\n                String VAR_23 = VAR_0.getI18N().msg(VAR_20, VAR_21);\n                throw new InvalidSyntaxException(VAR_23, VAR_17, null, VAR_19, null);\n            }\n        });\n\n        /* COMMENT_1 */\n        int VAR_24 = VAR_2.getMaxTokens();\n        int VAR_25 = VAR_2.getMaxWhitespaceTokens();\n        BiConsumer<Integer, Token> VAR_26 = (VAR_27, VAR_28) -> throwIfTokenProblems(\n                VAR_0,\n                VAR_28,\n                VAR_27,\n                VAR_5,\n                ParseCancelledException.class);\n        SafeTokenSource VAR_29 = new SafeTokenSource(VAR_11, VAR_24, VAR_25, VAR_26);\n\n        CommonTokenStream VAR_30 = new CommonTokenStream(VAR_29);\n\n        GraphqlParser VAR_31 = new GraphqlParser(VAR_30);\n        VAR_31.removeErrorListeners();\n        VAR_31.getInterpreter().setPredictionMode(VAR_32.SLL);\n\n        ExtendedBailStrategy VAR_33 = new ExtendedBailStrategy(VAR_5, VAR_0);\n        VAR_31.setErrorHandler(VAR_33);\n\n        /* COMMENT_2 */\n        GraphqlAntlrToLanguage VAR_34 = getAntlrToLanguage(VAR_30, VAR_5, VAR_0);\n\n        setupParserListener(VAR_0, VAR_5, VAR_31, VAR_34);\n\n\n        /* COMMENT_3 */\n        /* COMMENT_4 */\n        /* COMMENT_3 */\n        Object[] VAR_35 = VAR_1.apply(VAR_31, VAR_34);\n        ParserRuleContext VAR_36 = (ParserRuleContext) VAR_35[0];\n        Node<?> VAR_37 = (Node<?>) VAR_35[1];\n\n        Token VAR_38 = VAR_36.getStop();\n        List<Token> VAR_39 = VAR_30.getTokens();\n        if (VAR_38 != null && VAR_39 != null && !VAR_39.isEmpty()) {\n            Token VAR_40 = VAR_39.get(VAR_39.size() - 1);\n            /* COMMENT_3 */\n            /* COMMENT_5 */\n            /* COMMENT_6 */\n            boolean VAR_41 = VAR_40.getType() != VAR_42.EOF;\n            boolean VAR_43 = VAR_40.getTokenIndex() > VAR_38.getTokenIndex();\n            boolean VAR_44 = VAR_40.getChannel() == VAR_38.getChannel();\n            if (VAR_41 && VAR_43 && VAR_44) {\n                throw VAR_33.mkMoreTokensException(VAR_40);\n            }\n        }\n        return VAR_37;\n    }",
  "func_graph_path": "graphql-java/8a1c884c81c0b656db201cfd95881feb0f430a55/Parser.java/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -44,7 +44,12 @@\n         // this lexer wrapper allows us to stop lexing when too many tokens are in place.  This prevents DOS attacks.\n         int maxTokens = parserOptions.getMaxTokens();\n         int maxWhitespaceTokens = parserOptions.getMaxWhitespaceTokens();\n-        BiConsumer<Integer, Token> onTooManyTokens = (maxTokenCount, token) -> throwCancelParseIfTooManyTokens(environment, token, maxTokenCount, multiSourceReader);\n+        BiConsumer<Integer, Token> onTooManyTokens = (maxTokenCount, token) -> throwIfTokenProblems(\n+                environment,\n+                token,\n+                maxTokenCount,\n+                multiSourceReader,\n+                ParseCancelledException.class);\n         SafeTokenSource safeTokenSource = new SafeTokenSource(lexer, maxTokens, maxWhitespaceTokens, onTooManyTokens);\n \n         CommonTokenStream tokens = new CommonTokenStream(safeTokenSource);",
  "diff_line_info": {
    "deleted_lines": [
      "        BiConsumer<Integer, Token> onTooManyTokens = (maxTokenCount, token) -> throwCancelParseIfTooManyTokens(environment, token, maxTokenCount, multiSourceReader);"
    ],
    "added_lines": [
      "        BiConsumer<Integer, Token> onTooManyTokens = (maxTokenCount, token) -> throwIfTokenProblems(",
      "                environment,",
      "                token,",
      "                maxTokenCount,",
      "                multiSourceReader,",
      "                ParseCancelledException.class);"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/graphql-java/graphql-java/pull/3112",
  "description": {
    "pr_info": {
      "title": "Preventing stack overflow exceptions via limiting the depth of the parser rules",
      "number": 3112
    },
    "comment": [
      "This puts in a limit on how deep grammar rules can get.  \r\n\r\nAs ANLTR is a **recursive-descent parser** it will build up a call stack as it moves along.  This stack is limited and can blow up with just the wrong input.  Even if the max tokens checking is in place, it can still blow the JVM stack before the max tokens are reached.\r\n\r\nRight now it's 500 deep as presented here.  Is this the right value?  More?? Less ??  I changed it from 1000"
    ]
  },
  "Bug Filter": "Security Vulnerability Fix",
  "Bug Filter Confidence": 0.95,
  "Bug Filter Response": "**Final Classification:** Security Vulnerability Fix; **Confidence:** 0.95"
}