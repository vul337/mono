{
  "cve_id": "CVE-2023-33297",
  "cwe_ids": [
    "CWE-400"
  ],
  "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
  "cvss_is_v3": true,
  "repo_name": "bitcoin",
  "commit_msg": "net_processing: Boost inv trickle rate\n\nIf transactions are being added to the mempool at a rate faster than 7tx/s\n(INVENTORY_BROADCAST_PER_SECOND) then peers' inventory_to_send queue can\nbecome relatively large. If this happens, increase the number of txids\nwe include in an INV message (normally capped at 35) by 5 for each 1000\ntxids in the queue.\n\nThis will tend to clear a temporary excess out reasonably quickly; an\nexcess of 4000 invs to send will be cleared down to 1000 in about 30\nminutes, while an excess of 20000 invs would be cleared down to 1000 in\nabout 60 minutes.",
  "commit_hash": "5b3406094f2679dfb3763de4414257268565b943",
  "git_url": "https://github.com/bitcoin/bitcoin/commit/5b3406094f2679dfb3763de4414257268565b943",
  "file_path": "src/net_processing.cpp",
  "func_name": "PeerManagerImpl::SendMessages",
  "func_before": "bool PeerManagerImpl::SendMessages(CNode* pto)\n{\n    AssertLockHeld(g_msgproc_mutex);\n\n    PeerRef peer = GetPeerRef(pto->GetId());\n    if (!peer) return false;\n    const Consensus::Params& consensusParams = m_chainparams.GetConsensus();\n\n    // We must call MaybeDiscourageAndDisconnect first, to ensure that we'll\n    // disconnect misbehaving peers even before the version handshake is complete.\n    if (MaybeDiscourageAndDisconnect(*pto, *peer)) return true;\n\n    // Don't send anything until the version handshake is complete\n    if (!pto->fSuccessfullyConnected || pto->fDisconnect)\n        return true;\n\n    // If we get here, the outgoing message serialization version is set and can't change.\n    const CNetMsgMaker msgMaker(pto->GetCommonVersion());\n\n    const auto current_time{GetTime<std::chrono::microseconds>()};\n\n    if (pto->IsAddrFetchConn() && current_time - pto->m_connected > 10 * AVG_ADDRESS_BROADCAST_INTERVAL) {\n        LogPrint(BCLog::NET, \"addrfetch connection timeout; disconnecting peer=%d\\n\", pto->GetId());\n        pto->fDisconnect = true;\n        return true;\n    }\n\n    MaybeSendPing(*pto, *peer, current_time);\n\n    // MaybeSendPing may have marked peer for disconnection\n    if (pto->fDisconnect) return true;\n\n    MaybeSendAddr(*pto, *peer, current_time);\n\n    MaybeSendSendHeaders(*pto, *peer);\n\n    {\n        LOCK(cs_main);\n\n        CNodeState &state = *State(pto->GetId());\n\n        // Start block sync\n        if (m_chainman.m_best_header == nullptr) {\n            m_chainman.m_best_header = m_chainman.ActiveChain().Tip();\n        }\n\n        // Determine whether we might try initial headers sync or parallel\n        // block download from this peer -- this mostly affects behavior while\n        // in IBD (once out of IBD, we sync from all peers).\n        bool sync_blocks_and_headers_from_peer = false;\n        if (state.fPreferredDownload) {\n            sync_blocks_and_headers_from_peer = true;\n        } else if (CanServeBlocks(*peer) && !pto->IsAddrFetchConn()) {\n            // Typically this is an inbound peer. If we don't have any outbound\n            // peers, or if we aren't downloading any blocks from such peers,\n            // then allow block downloads from this peer, too.\n            // We prefer downloading blocks from outbound peers to avoid\n            // putting undue load on (say) some home user who is just making\n            // outbound connections to the network, but if our only source of\n            // the latest blocks is from an inbound peer, we have to be sure to\n            // eventually download it (and not just wait indefinitely for an\n            // outbound peer to have it).\n            if (m_num_preferred_download_peers == 0 || mapBlocksInFlight.empty()) {\n                sync_blocks_and_headers_from_peer = true;\n            }\n        }\n\n        if (!state.fSyncStarted && CanServeBlocks(*peer) && !m_chainman.m_blockman.LoadingBlocks()) {\n            // Only actively request headers from a single peer, unless we're close to today.\n            if ((nSyncStarted == 0 && sync_blocks_and_headers_from_peer) || m_chainman.m_best_header->Time() > GetAdjustedTime() - 24h) {\n                const CBlockIndex* pindexStart = m_chainman.m_best_header;\n                /* If possible, start at the block preceding the currently\n                   best known header.  This ensures that we always get a\n                   non-empty list of headers back as long as the peer\n                   is up-to-date.  With a non-empty response, we can initialise\n                   the peer's known best block.  This wouldn't be possible\n                   if we requested starting at m_chainman.m_best_header and\n                   got back an empty response.  */\n                if (pindexStart->pprev)\n                    pindexStart = pindexStart->pprev;\n                if (MaybeSendGetHeaders(*pto, GetLocator(pindexStart), *peer)) {\n                    LogPrint(BCLog::NET, \"initial getheaders (%d) to peer=%d (startheight:%d)\\n\", pindexStart->nHeight, pto->GetId(), peer->m_starting_height);\n\n                    state.fSyncStarted = true;\n                    peer->m_headers_sync_timeout = current_time + HEADERS_DOWNLOAD_TIMEOUT_BASE +\n                        (\n                         // Convert HEADERS_DOWNLOAD_TIMEOUT_PER_HEADER to microseconds before scaling\n                         // to maintain precision\n                         std::chrono::microseconds{HEADERS_DOWNLOAD_TIMEOUT_PER_HEADER} *\n                         Ticks<std::chrono::seconds>(GetAdjustedTime() - m_chainman.m_best_header->Time()) / consensusParams.nPowTargetSpacing\n                        );\n                    nSyncStarted++;\n                }\n            }\n        }\n\n        //\n        // Try sending block announcements via headers\n        //\n        {\n            // If we have no more than MAX_BLOCKS_TO_ANNOUNCE in our\n            // list of block hashes we're relaying, and our peer wants\n            // headers announcements, then find the first header\n            // not yet known to our peer but would connect, and send.\n            // If no header would connect, or if we have too many\n            // blocks, or if the peer doesn't want headers, just\n            // add all to the inv queue.\n            LOCK(peer->m_block_inv_mutex);\n            std::vector<CBlock> vHeaders;\n            bool fRevertToInv = ((!peer->m_prefers_headers &&\n                                 (!state.m_requested_hb_cmpctblocks || peer->m_blocks_for_headers_relay.size() > 1)) ||\n                                 peer->m_blocks_for_headers_relay.size() > MAX_BLOCKS_TO_ANNOUNCE);\n            const CBlockIndex *pBestIndex = nullptr; // last header queued for delivery\n            ProcessBlockAvailability(pto->GetId()); // ensure pindexBestKnownBlock is up-to-date\n\n            if (!fRevertToInv) {\n                bool fFoundStartingHeader = false;\n                // Try to find first header that our peer doesn't have, and\n                // then send all headers past that one.  If we come across any\n                // headers that aren't on m_chainman.ActiveChain(), give up.\n                for (const uint256& hash : peer->m_blocks_for_headers_relay) {\n                    const CBlockIndex* pindex = m_chainman.m_blockman.LookupBlockIndex(hash);\n                    assert(pindex);\n                    if (m_chainman.ActiveChain()[pindex->nHeight] != pindex) {\n                        // Bail out if we reorged away from this block\n                        fRevertToInv = true;\n                        break;\n                    }\n                    if (pBestIndex != nullptr && pindex->pprev != pBestIndex) {\n                        // This means that the list of blocks to announce don't\n                        // connect to each other.\n                        // This shouldn't really be possible to hit during\n                        // regular operation (because reorgs should take us to\n                        // a chain that has some block not on the prior chain,\n                        // which should be caught by the prior check), but one\n                        // way this could happen is by using invalidateblock /\n                        // reconsiderblock repeatedly on the tip, causing it to\n                        // be added multiple times to m_blocks_for_headers_relay.\n                        // Robustly deal with this rare situation by reverting\n                        // to an inv.\n                        fRevertToInv = true;\n                        break;\n                    }\n                    pBestIndex = pindex;\n                    if (fFoundStartingHeader) {\n                        // add this to the headers message\n                        vHeaders.push_back(pindex->GetBlockHeader());\n                    } else if (PeerHasHeader(&state, pindex)) {\n                        continue; // keep looking for the first new block\n                    } else if (pindex->pprev == nullptr || PeerHasHeader(&state, pindex->pprev)) {\n                        // Peer doesn't have this header but they do have the prior one.\n                        // Start sending headers.\n                        fFoundStartingHeader = true;\n                        vHeaders.push_back(pindex->GetBlockHeader());\n                    } else {\n                        // Peer doesn't have this header or the prior one -- nothing will\n                        // connect, so bail out.\n                        fRevertToInv = true;\n                        break;\n                    }\n                }\n            }\n            if (!fRevertToInv && !vHeaders.empty()) {\n                if (vHeaders.size() == 1 && state.m_requested_hb_cmpctblocks) {\n                    // We only send up to 1 block as header-and-ids, as otherwise\n                    // probably means we're doing an initial-ish-sync or they're slow\n                    LogPrint(BCLog::NET, \"%s sending header-and-ids %s to peer=%d\\n\", __func__,\n                            vHeaders.front().GetHash().ToString(), pto->GetId());\n\n                    std::optional<CSerializedNetMsg> cached_cmpctblock_msg;\n                    {\n                        LOCK(m_most_recent_block_mutex);\n                        if (m_most_recent_block_hash == pBestIndex->GetBlockHash()) {\n                            cached_cmpctblock_msg = msgMaker.Make(NetMsgType::CMPCTBLOCK, *m_most_recent_compact_block);\n                        }\n                    }\n                    if (cached_cmpctblock_msg.has_value()) {\n                        m_connman.PushMessage(pto, std::move(cached_cmpctblock_msg.value()));\n                    } else {\n                        CBlock block;\n                        bool ret = ReadBlockFromDisk(block, pBestIndex, consensusParams);\n                        assert(ret);\n                        CBlockHeaderAndShortTxIDs cmpctblock{block};\n                        m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::CMPCTBLOCK, cmpctblock));\n                    }\n                    state.pindexBestHeaderSent = pBestIndex;\n                } else if (peer->m_prefers_headers) {\n                    if (vHeaders.size() > 1) {\n                        LogPrint(BCLog::NET, \"%s: %u headers, range (%s, %s), to peer=%d\\n\", __func__,\n                                vHeaders.size(),\n                                vHeaders.front().GetHash().ToString(),\n                                vHeaders.back().GetHash().ToString(), pto->GetId());\n                    } else {\n                        LogPrint(BCLog::NET, \"%s: sending header %s to peer=%d\\n\", __func__,\n                                vHeaders.front().GetHash().ToString(), pto->GetId());\n                    }\n                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::HEADERS, vHeaders));\n                    state.pindexBestHeaderSent = pBestIndex;\n                } else\n                    fRevertToInv = true;\n            }\n            if (fRevertToInv) {\n                // If falling back to using an inv, just try to inv the tip.\n                // The last entry in m_blocks_for_headers_relay was our tip at some point\n                // in the past.\n                if (!peer->m_blocks_for_headers_relay.empty()) {\n                    const uint256& hashToAnnounce = peer->m_blocks_for_headers_relay.back();\n                    const CBlockIndex* pindex = m_chainman.m_blockman.LookupBlockIndex(hashToAnnounce);\n                    assert(pindex);\n\n                    // Warn if we're announcing a block that is not on the main chain.\n                    // This should be very rare and could be optimized out.\n                    // Just log for now.\n                    if (m_chainman.ActiveChain()[pindex->nHeight] != pindex) {\n                        LogPrint(BCLog::NET, \"Announcing block %s not on main chain (tip=%s)\\n\",\n                            hashToAnnounce.ToString(), m_chainman.ActiveChain().Tip()->GetBlockHash().ToString());\n                    }\n\n                    // If the peer's chain has this block, don't inv it back.\n                    if (!PeerHasHeader(&state, pindex)) {\n                        peer->m_blocks_for_inv_relay.push_back(hashToAnnounce);\n                        LogPrint(BCLog::NET, \"%s: sending inv peer=%d hash=%s\\n\", __func__,\n                            pto->GetId(), hashToAnnounce.ToString());\n                    }\n                }\n            }\n            peer->m_blocks_for_headers_relay.clear();\n        }\n\n        //\n        // Message: inventory\n        //\n        std::vector<CInv> vInv;\n        {\n            LOCK(peer->m_block_inv_mutex);\n            vInv.reserve(std::max<size_t>(peer->m_blocks_for_inv_relay.size(), INVENTORY_BROADCAST_MAX));\n\n            // Add blocks\n            for (const uint256& hash : peer->m_blocks_for_inv_relay) {\n                vInv.push_back(CInv(MSG_BLOCK, hash));\n                if (vInv.size() == MAX_INV_SZ) {\n                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n                    vInv.clear();\n                }\n            }\n            peer->m_blocks_for_inv_relay.clear();\n        }\n\n        if (auto tx_relay = peer->GetTxRelay(); tx_relay != nullptr) {\n                LOCK(tx_relay->m_tx_inventory_mutex);\n                // Check whether periodic sends should happen\n                bool fSendTrickle = pto->HasPermission(NetPermissionFlags::NoBan);\n                if (tx_relay->m_next_inv_send_time < current_time) {\n                    fSendTrickle = true;\n                    if (pto->IsInboundConn()) {\n                        tx_relay->m_next_inv_send_time = NextInvToInbounds(current_time, INBOUND_INVENTORY_BROADCAST_INTERVAL);\n                    } else {\n                        tx_relay->m_next_inv_send_time = GetExponentialRand(current_time, OUTBOUND_INVENTORY_BROADCAST_INTERVAL);\n                    }\n                }\n\n                // Time to send but the peer has requested we not relay transactions.\n                if (fSendTrickle) {\n                    LOCK(tx_relay->m_bloom_filter_mutex);\n                    if (!tx_relay->m_relay_txs) tx_relay->m_tx_inventory_to_send.clear();\n                }\n\n                // Respond to BIP35 mempool requests\n                if (fSendTrickle && tx_relay->m_send_mempool) {\n                    auto vtxinfo = m_mempool.infoAll();\n                    tx_relay->m_send_mempool = false;\n                    const CFeeRate filterrate{tx_relay->m_fee_filter_received.load()};\n\n                    LOCK(tx_relay->m_bloom_filter_mutex);\n\n                    for (const auto& txinfo : vtxinfo) {\n                        const uint256& hash = peer->m_wtxid_relay ? txinfo.tx->GetWitnessHash() : txinfo.tx->GetHash();\n                        CInv inv(peer->m_wtxid_relay ? MSG_WTX : MSG_TX, hash);\n                        tx_relay->m_tx_inventory_to_send.erase(hash);\n                        // Don't send transactions that peers will not put into their mempool\n                        if (txinfo.fee < filterrate.GetFee(txinfo.vsize)) {\n                            continue;\n                        }\n                        if (tx_relay->m_bloom_filter) {\n                            if (!tx_relay->m_bloom_filter->IsRelevantAndUpdate(*txinfo.tx)) continue;\n                        }\n                        tx_relay->m_tx_inventory_known_filter.insert(hash);\n                        // Responses to MEMPOOL requests bypass the m_recently_announced_invs filter.\n                        vInv.push_back(inv);\n                        if (vInv.size() == MAX_INV_SZ) {\n                            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n                            vInv.clear();\n                        }\n                    }\n                    tx_relay->m_last_mempool_req = std::chrono::duration_cast<std::chrono::seconds>(current_time);\n                }\n\n                // Determine transactions to relay\n                if (fSendTrickle) {\n                    // Produce a vector with all candidates for sending\n                    std::vector<std::set<uint256>::iterator> vInvTx;\n                    vInvTx.reserve(tx_relay->m_tx_inventory_to_send.size());\n                    for (std::set<uint256>::iterator it = tx_relay->m_tx_inventory_to_send.begin(); it != tx_relay->m_tx_inventory_to_send.end(); it++) {\n                        vInvTx.push_back(it);\n                    }\n                    const CFeeRate filterrate{tx_relay->m_fee_filter_received.load()};\n                    // Topologically and fee-rate sort the inventory we send for privacy and priority reasons.\n                    // A heap is used so that not all items need sorting if only a few are being sent.\n                    CompareInvMempoolOrder compareInvMempoolOrder(&m_mempool, peer->m_wtxid_relay);\n                    std::make_heap(vInvTx.begin(), vInvTx.end(), compareInvMempoolOrder);\n                    // No reason to drain out at many times the network's capacity,\n                    // especially since we have many peers and some will draw much shorter delays.\n                    unsigned int nRelayedTransactions = 0;\n                    LOCK(tx_relay->m_bloom_filter_mutex);\n                    while (!vInvTx.empty() && nRelayedTransactions < INVENTORY_BROADCAST_MAX) {\n                        // Fetch the top element from the heap\n                        std::pop_heap(vInvTx.begin(), vInvTx.end(), compareInvMempoolOrder);\n                        std::set<uint256>::iterator it = vInvTx.back();\n                        vInvTx.pop_back();\n                        uint256 hash = *it;\n                        CInv inv(peer->m_wtxid_relay ? MSG_WTX : MSG_TX, hash);\n                        // Remove it from the to-be-sent set\n                        tx_relay->m_tx_inventory_to_send.erase(it);\n                        // Check if not in the filter already\n                        if (tx_relay->m_tx_inventory_known_filter.contains(hash)) {\n                            continue;\n                        }\n                        // Not in the mempool anymore? don't bother sending it.\n                        auto txinfo = m_mempool.info(ToGenTxid(inv));\n                        if (!txinfo.tx) {\n                            continue;\n                        }\n                        auto txid = txinfo.tx->GetHash();\n                        auto wtxid = txinfo.tx->GetWitnessHash();\n                        // Peer told you to not send transactions at that feerate? Don't bother sending it.\n                        if (txinfo.fee < filterrate.GetFee(txinfo.vsize)) {\n                            continue;\n                        }\n                        if (tx_relay->m_bloom_filter && !tx_relay->m_bloom_filter->IsRelevantAndUpdate(*txinfo.tx)) continue;\n                        // Send\n                        tx_relay->m_recently_announced_invs.insert(hash);\n                        vInv.push_back(inv);\n                        nRelayedTransactions++;\n                        {\n                            // Expire old relay messages\n                            while (!g_relay_expiration.empty() && g_relay_expiration.front().first < current_time)\n                            {\n                                mapRelay.erase(g_relay_expiration.front().second);\n                                g_relay_expiration.pop_front();\n                            }\n\n                            auto ret = mapRelay.emplace(txid, std::move(txinfo.tx));\n                            if (ret.second) {\n                                g_relay_expiration.emplace_back(current_time + RELAY_TX_CACHE_TIME, ret.first);\n                            }\n                            // Add wtxid-based lookup into mapRelay as well, so that peers can request by wtxid\n                            auto ret2 = mapRelay.emplace(wtxid, ret.first->second);\n                            if (ret2.second) {\n                                g_relay_expiration.emplace_back(current_time + RELAY_TX_CACHE_TIME, ret2.first);\n                            }\n                        }\n                        if (vInv.size() == MAX_INV_SZ) {\n                            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n                            vInv.clear();\n                        }\n                        tx_relay->m_tx_inventory_known_filter.insert(hash);\n                        if (hash != txid) {\n                            // Insert txid into m_tx_inventory_known_filter, even for\n                            // wtxidrelay peers. This prevents re-adding of\n                            // unconfirmed parents to the recently_announced\n                            // filter, when a child tx is requested. See\n                            // ProcessGetData().\n                            tx_relay->m_tx_inventory_known_filter.insert(txid);\n                        }\n                    }\n                }\n        }\n        if (!vInv.empty())\n            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n\n        // Detect whether we're stalling\n        auto stalling_timeout = m_block_stalling_timeout.load();\n        if (state.m_stalling_since.count() && state.m_stalling_since < current_time - stalling_timeout) {\n            // Stalling only triggers when the block download window cannot move. During normal steady state,\n            // the download window should be much larger than the to-be-downloaded set of blocks, so disconnection\n            // should only happen during initial block download.\n            LogPrintf(\"Peer=%d is stalling block download, disconnecting\\n\", pto->GetId());\n            pto->fDisconnect = true;\n            // Increase timeout for the next peer so that we don't disconnect multiple peers if our own\n            // bandwidth is insufficient.\n            const auto new_timeout = std::min(2 * stalling_timeout, BLOCK_STALLING_TIMEOUT_MAX);\n            if (stalling_timeout != new_timeout && m_block_stalling_timeout.compare_exchange_strong(stalling_timeout, new_timeout)) {\n                LogPrint(BCLog::NET, \"Increased stalling timeout temporarily to %d seconds\\n\", count_seconds(new_timeout));\n            }\n            return true;\n        }\n        // In case there is a block that has been in flight from this peer for block_interval * (1 + 0.5 * N)\n        // (with N the number of peers from which we're downloading validated blocks), disconnect due to timeout.\n        // We compensate for other peers to prevent killing off peers due to our own downstream link\n        // being saturated. We only count validated in-flight blocks so peers can't advertise non-existing block hashes\n        // to unreasonably increase our timeout.\n        if (state.vBlocksInFlight.size() > 0) {\n            QueuedBlock &queuedBlock = state.vBlocksInFlight.front();\n            int nOtherPeersWithValidatedDownloads = m_peers_downloading_from - 1;\n            if (current_time > state.m_downloading_since + std::chrono::seconds{consensusParams.nPowTargetSpacing} * (BLOCK_DOWNLOAD_TIMEOUT_BASE + BLOCK_DOWNLOAD_TIMEOUT_PER_PEER * nOtherPeersWithValidatedDownloads)) {\n                LogPrintf(\"Timeout downloading block %s from peer=%d, disconnecting\\n\", queuedBlock.pindex->GetBlockHash().ToString(), pto->GetId());\n                pto->fDisconnect = true;\n                return true;\n            }\n        }\n        // Check for headers sync timeouts\n        if (state.fSyncStarted && peer->m_headers_sync_timeout < std::chrono::microseconds::max()) {\n            // Detect whether this is a stalling initial-headers-sync peer\n            if (m_chainman.m_best_header->Time() <= GetAdjustedTime() - 24h) {\n                if (current_time > peer->m_headers_sync_timeout && nSyncStarted == 1 && (m_num_preferred_download_peers - state.fPreferredDownload >= 1)) {\n                    // Disconnect a peer (without NetPermissionFlags::NoBan permission) if it is our only sync peer,\n                    // and we have others we could be using instead.\n                    // Note: If all our peers are inbound, then we won't\n                    // disconnect our sync peer for stalling; we have bigger\n                    // problems if we can't get any outbound peers.\n                    if (!pto->HasPermission(NetPermissionFlags::NoBan)) {\n                        LogPrintf(\"Timeout downloading headers from peer=%d, disconnecting\\n\", pto->GetId());\n                        pto->fDisconnect = true;\n                        return true;\n                    } else {\n                        LogPrintf(\"Timeout downloading headers from noban peer=%d, not disconnecting\\n\", pto->GetId());\n                        // Reset the headers sync state so that we have a\n                        // chance to try downloading from a different peer.\n                        // Note: this will also result in at least one more\n                        // getheaders message to be sent to\n                        // this peer (eventually).\n                        state.fSyncStarted = false;\n                        nSyncStarted--;\n                        peer->m_headers_sync_timeout = 0us;\n                    }\n                }\n            } else {\n                // After we've caught up once, reset the timeout so we can't trigger\n                // disconnect later.\n                peer->m_headers_sync_timeout = std::chrono::microseconds::max();\n            }\n        }\n\n        // Check that outbound peers have reasonable chains\n        // GetTime() is used by this anti-DoS logic so we can test this using mocktime\n        ConsiderEviction(*pto, *peer, GetTime<std::chrono::seconds>());\n\n        //\n        // Message: getdata (blocks)\n        //\n        std::vector<CInv> vGetData;\n        if (CanServeBlocks(*peer) && ((sync_blocks_and_headers_from_peer && !IsLimitedPeer(*peer)) || !m_chainman.ActiveChainstate().IsInitialBlockDownload()) && state.nBlocksInFlight < MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n            std::vector<const CBlockIndex*> vToDownload;\n            NodeId staller = -1;\n            FindNextBlocksToDownload(*peer, MAX_BLOCKS_IN_TRANSIT_PER_PEER - state.nBlocksInFlight, vToDownload, staller);\n            for (const CBlockIndex *pindex : vToDownload) {\n                uint32_t nFetchFlags = GetFetchFlags(*peer);\n                vGetData.push_back(CInv(MSG_BLOCK | nFetchFlags, pindex->GetBlockHash()));\n                BlockRequested(pto->GetId(), *pindex);\n                LogPrint(BCLog::NET, \"Requesting block %s (%d) peer=%d\\n\", pindex->GetBlockHash().ToString(),\n                    pindex->nHeight, pto->GetId());\n            }\n            if (state.nBlocksInFlight == 0 && staller != -1) {\n                if (State(staller)->m_stalling_since == 0us) {\n                    State(staller)->m_stalling_since = current_time;\n                    LogPrint(BCLog::NET, \"Stall started peer=%d\\n\", staller);\n                }\n            }\n        }\n\n        //\n        // Message: getdata (transactions)\n        //\n        std::vector<std::pair<NodeId, GenTxid>> expired;\n        auto requestable = m_txrequest.GetRequestable(pto->GetId(), current_time, &expired);\n        for (const auto& entry : expired) {\n            LogPrint(BCLog::NET, \"timeout of inflight %s %s from peer=%d\\n\", entry.second.IsWtxid() ? \"wtx\" : \"tx\",\n                entry.second.GetHash().ToString(), entry.first);\n        }\n        for (const GenTxid& gtxid : requestable) {\n            if (!AlreadyHaveTx(gtxid)) {\n                LogPrint(BCLog::NET, \"Requesting %s %s peer=%d\\n\", gtxid.IsWtxid() ? \"wtx\" : \"tx\",\n                    gtxid.GetHash().ToString(), pto->GetId());\n                vGetData.emplace_back(gtxid.IsWtxid() ? MSG_WTX : (MSG_TX | GetFetchFlags(*peer)), gtxid.GetHash());\n                if (vGetData.size() >= MAX_GETDATA_SZ) {\n                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n                    vGetData.clear();\n                }\n                m_txrequest.RequestedTx(pto->GetId(), gtxid.GetHash(), current_time + GETDATA_TX_INTERVAL);\n            } else {\n                // We have already seen this transaction, no need to download. This is just a belt-and-suspenders, as\n                // this should already be called whenever a transaction becomes AlreadyHaveTx().\n                m_txrequest.ForgetTxHash(gtxid.GetHash());\n            }\n        }\n\n\n        if (!vGetData.empty())\n            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n    } // release cs_main\n    MaybeSendFeefilter(*pto, *peer, current_time);\n    return true;\n}",
  "abstract_func_before": "bool PeerManagerImpl::SendMessages(CNode* VAR_0)\n{\n    AssertLockHeld(VAR_1);\n\n    PeerRef VAR_2 = GetPeerRef(VAR_0->GetId());\n    if (!VAR_2) return false;\n    const Consensus::Params& VAR_3 = VAR_4.GetConsensus();\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    if (MaybeDiscourageAndDisconnect(*VAR_0, *VAR_2)) return true;\n\n    /* COMMENT_2 */\n    if (!VAR_0->fSuccessfullyConnected || VAR_0->fDisconnect)\n        return true;\n\n    /* COMMENT_3 */\n    const CNetMsgMaker VAR_5(VAR_0->GetCommonVersion());\n\n    const auto VAR_6{VAR_7<std::chrono::microseconds>()};\n\n    if (VAR_0->IsAddrFetchConn() && VAR_6 - VAR_0->m_connected > 10 * VAR_8) {\n        LogPrint(BCLog::NET, \"addrfetch connection timeout; disconnecting peer=%d\\n\", VAR_0->GetId());\n        VAR_0->fDisconnect = true;\n        return true;\n    }\n\n    MaybeSendPing(*VAR_0, *VAR_2, VAR_6);\n\n    /* COMMENT_4 */\n    if (VAR_0->fDisconnect) return true;\n\n    MaybeSendAddr(*VAR_0, *VAR_2, VAR_6);\n\n    MaybeSendSendHeaders(*VAR_0, *VAR_2);\n\n    {\n        LOCK(VAR_9);\n\n        CNodeState &VAR_10 = *State(VAR_0->GetId());\n\n        /* COMMENT_5 */\n        if (VAR_11.m_best_header == nullptr) {\n            VAR_11.m_best_header = VAR_11.ActiveChain().Tip();\n        }\n\n        /* COMMENT_6 */\n        /* COMMENT_7 */\n        /* COMMENT_8 */\n        bool VAR_12 = false;\n        if (VAR_10.fPreferredDownload) {\n            VAR_12 = true;\n        } else if (CanServeBlocks(*VAR_2) && !VAR_0->IsAddrFetchConn()) {\n            /* COMMENT_9 */\n            /* COMMENT_10 */\n            /* COMMENT_11 */\n            /* COMMENT_12 */\n            /* COMMENT_13 */\n            /* COMMENT_14 */\n            /* COMMENT_15 */\n            /* COMMENT_16 */\n            /* COMMENT_17 */\n            if (VAR_13 == 0 || VAR_14.empty()) {\n                VAR_12 = true;\n            }\n        }\n\n        if (!VAR_10.fSyncStarted && CanServeBlocks(*VAR_2) && !VAR_11.m_blockman.LoadingBlocks()) {\n            /* COMMENT_18 */\n            if ((VAR_15 == 0 && VAR_12) || VAR_11.m_best_header->Time() > GetAdjustedTime() - 24h) {\n                const CBlockIndex* VAR_16 = VAR_11.m_best_header;\n                /* COMMENT_19 */\n                                                                        \n                                                                     \n                                                                               \n                                                                          \n                                                                           \n                                                  \n                if (VAR_16->pprev)\n                    VAR_16 = VAR_16->pprev;\n                if (MaybeSendGetHeaders(*VAR_0, GetLocator(VAR_16), *VAR_2)) {\n                    LogPrint(BCLog::NET, \"initial getheaders (%d) to peer=%d (startheight:%d)\\n\", VAR_16->nHeight, VAR_0->GetId(), VAR_2->m_starting_height);\n\n                    VAR_10.fSyncStarted = true;\n                    VAR_2->m_headers_sync_timeout = VAR_6 + VAR_17 +\n                        (\n                         /* COMMENT_26 */\n                         /* COMMENT_27 */\n                         std::chrono::microseconds{VAR_18} *\n                         VAR_19<std::chrono::seconds>(GetAdjustedTime() - VAR_11.m_best_header->Time()) / VAR_3.nPowTargetSpacing\n                        );\n                    VAR_15++;\n                }\n            }\n        }\n\n        /* COMMENT_28 */\n        /* COMMENT_29 */\n        /* COMMENT_28 */\n        {\n            /* COMMENT_30 */\n            /* COMMENT_31 */\n            /* COMMENT_32 */\n            /* COMMENT_33 */\n            /* COMMENT_34 */\n            /* COMMENT_35 */\n            /* COMMENT_36 */\n            LOCK(VAR_2->m_block_inv_mutex);\n            std::vector<CBlock> VAR_20;\n            bool VAR_21 = ((!VAR_2->m_prefers_headers &&\n                                 (!VAR_10.m_requested_hb_cmpctblocks || VAR_2->m_blocks_for_headers_relay.size() > 1)) ||\n                                 VAR_2->m_blocks_for_headers_relay.size() > VAR_22);\n            const CBlockIndex *VAR_23 = nullptr; /* COMMENT_37 */\n            ProcessBlockAvailability(VAR_0->GetId()); /* COMMENT_38 */\n\n            if (!VAR_21) {\n                bool VAR_24 = false;\n                /* COMMENT_39 */\n                /* COMMENT_40 */\n                /* COMMENT_41 */\n                for (const uint256& VAR_25 : VAR_2->m_blocks_for_headers_relay) {\n                    const CBlockIndex* VAR_26 = VAR_11.m_blockman.LookupBlockIndex(VAR_25);\n                    assert(VAR_26);\n                    if (VAR_11.ActiveChain()[VAR_26->nHeight] != VAR_26) {\n                        /* COMMENT_42 */\n                        VAR_21 = true;\n                        break;\n                    }\n                    if (VAR_23 != nullptr && VAR_26->pprev != VAR_23) {\n                        /* COMMENT_43 */\n                        /* COMMENT_44 */\n                        /* COMMENT_45 */\n                        /* COMMENT_46 */\n                        /* COMMENT_47 */\n                        /* COMMENT_48 */\n                        /* COMMENT_49 */\n                        /* COMMENT_50 */\n                        /* COMMENT_51 */\n                        /* COMMENT_52 */\n                        /* COMMENT_53 */\n                        VAR_21 = true;\n                        break;\n                    }\n                    VAR_23 = VAR_26;\n                    if (VAR_24) {\n                        /* COMMENT_54 */\n                        VAR_20.push_back(VAR_26->GetBlockHeader());\n                    } else if (PeerHasHeader(&VAR_10, VAR_26)) {\n                        continue; /* COMMENT_55 */\n                    } else if (VAR_26->pprev == nullptr || PeerHasHeader(&VAR_10, VAR_26->pprev)) {\n                        /* COMMENT_56 */\n                        /* COMMENT_57 */\n                        VAR_24 = true;\n                        VAR_20.push_back(VAR_26->GetBlockHeader());\n                    } else {\n                        /* COMMENT_58 */\n                        /* COMMENT_59 */\n                        VAR_21 = true;\n                        break;\n                    }\n                }\n            }\n            if (!VAR_21 && !VAR_20.empty()) {\n                if (VAR_20.size() == 1 && VAR_10.m_requested_hb_cmpctblocks) {\n                    /* COMMENT_60 */\n                    /* COMMENT_61 */\n                    LogPrint(BCLog::NET, \"%s sending header-and-ids %s to peer=%d\\n\", VAR_27,\n                            VAR_20.front().GetHash().ToString(), VAR_0->GetId());\n\n                    std::optional<CSerializedNetMsg> VAR_28;\n                    {\n                        LOCK(VAR_29);\n                        if (VAR_30 == VAR_23->GetBlockHash()) {\n                            VAR_28 = VAR_5.Make(NetMsgType::CMPCTBLOCK, *VAR_31);\n                        }\n                    }\n                    if (VAR_28.has_value()) {\n                        VAR_32.PushMessage(VAR_0, std::move(VAR_28.value()));\n                    } else {\n                        CBlock VAR_33;\n                        bool VAR_34 = ReadBlockFromDisk(VAR_33, VAR_23, VAR_3);\n                        assert(VAR_34);\n                        CBlockHeaderAndShortTxIDs VAR_35{VAR_33};\n                        VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::CMPCTBLOCK, VAR_35));\n                    }\n                    VAR_10.pindexBestHeaderSent = VAR_23;\n                } else if (VAR_2->m_prefers_headers) {\n                    if (VAR_20.size() > 1) {\n                        LogPrint(BCLog::NET, \"%s: %u headers, range (%s, %s), to peer=%d\\n\", VAR_27,\n                                VAR_20.size(),\n                                VAR_20.front().GetHash().ToString(),\n                                VAR_20.back().GetHash().ToString(), VAR_0->GetId());\n                    } else {\n                        LogPrint(BCLog::NET, \"%s: sending header %s to peer=%d\\n\", VAR_27,\n                                VAR_20.front().GetHash().ToString(), VAR_0->GetId());\n                    }\n                    VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::HEADERS, VAR_20));\n                    VAR_10.pindexBestHeaderSent = VAR_23;\n                } else\n                    VAR_21 = true;\n            }\n            if (VAR_21) {\n                /* COMMENT_62 */\n                /* COMMENT_63 */\n                /* COMMENT_64 */\n                if (!VAR_2->m_blocks_for_headers_relay.empty()) {\n                    const uint256& VAR_36 = VAR_2->m_blocks_for_headers_relay.back();\n                    const CBlockIndex* VAR_26 = VAR_11.m_blockman.LookupBlockIndex(VAR_36);\n                    assert(VAR_26);\n\n                    /* COMMENT_65 */\n                    /* COMMENT_66 */\n                    /* COMMENT_67 */\n                    if (VAR_11.ActiveChain()[VAR_26->nHeight] != VAR_26) {\n                        LogPrint(BCLog::NET, \"Announcing block %s not on main chain (tip=%s)\\n\",\n                            VAR_36.ToString(), VAR_11.ActiveChain().Tip()->GetBlockHash().ToString());\n                    }\n\n                    /* COMMENT_68 */\n                    if (!PeerHasHeader(&VAR_10, VAR_26)) {\n                        VAR_2->m_blocks_for_inv_relay.push_back(VAR_36);\n                        LogPrint(BCLog::NET, \"%s: sending inv peer=%d hash=%s\\n\", VAR_27,\n                            VAR_0->GetId(), VAR_36.ToString());\n                    }\n                }\n            }\n            VAR_2->m_blocks_for_headers_relay.clear();\n        }\n\n        /* COMMENT_28 */\n        /* COMMENT_69 */\n        /* COMMENT_28 */\n        std::vector<CInv> VAR_37;\n        {\n            LOCK(VAR_2->m_block_inv_mutex);\n            VAR_37.reserve(std::VAR_38<size_t>(VAR_2->m_blocks_for_inv_relay.size(), VAR_39));\n\n            /* COMMENT_70 */\n            for (const uint256& VAR_25 : VAR_2->m_blocks_for_inv_relay) {\n                VAR_37.push_back(CInv(VAR_40, VAR_25));\n                if (VAR_37.size() == VAR_41) {\n                    VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n                    VAR_37.clear();\n                }\n            }\n            VAR_2->m_blocks_for_inv_relay.clear();\n        }\n\n        if (auto VAR_42 = VAR_2->GetTxRelay(); VAR_42 != nullptr) {\n                LOCK(VAR_42->m_tx_inventory_mutex);\n                /* COMMENT_71 */\n                bool VAR_43 = VAR_0->HasPermission(NetPermissionFlags::NoBan);\n                if (VAR_42->m_next_inv_send_time < VAR_6) {\n                    VAR_43 = true;\n                    if (VAR_0->IsInboundConn()) {\n                        VAR_42->m_next_inv_send_time = NextInvToInbounds(VAR_6, VAR_44);\n                    } else {\n                        VAR_42->m_next_inv_send_time = GetExponentialRand(VAR_6, VAR_45);\n                    }\n                }\n\n                /* COMMENT_72 */\n                if (VAR_43) {\n                    LOCK(VAR_42->m_bloom_filter_mutex);\n                    if (!VAR_42->m_relay_txs) VAR_42->m_tx_inventory_to_send.clear();\n                }\n\n                /* COMMENT_73 */\n                if (VAR_43 && VAR_42->m_send_mempool) {\n                    auto VAR_46 = VAR_47.infoAll();\n                    VAR_42->m_send_mempool = false;\n                    const CFeeRate VAR_48{VAR_42->m_fee_filter_received.load()};\n\n                    LOCK(VAR_42->m_bloom_filter_mutex);\n\n                    for (const auto& VAR_49 : VAR_46) {\n                        const uint256& VAR_25 = VAR_2->m_wtxid_relay ? VAR_49.tx->GetWitnessHash() : VAR_49.tx->GetHash();\n                        CInv VAR_50(VAR_2->m_wtxid_relay ? VAR_51 : VAR_52, VAR_25);\n                        VAR_42->m_tx_inventory_to_send.erase(VAR_25);\n                        /* COMMENT_74 */\n                        if (VAR_49.fee < VAR_48.GetFee(VAR_49.vsize)) {\n                            continue;\n                        }\n                        if (VAR_42->m_bloom_filter) {\n                            if (!VAR_42->m_bloom_filter->IsRelevantAndUpdate(*VAR_49.tx)) continue;\n                        }\n                        VAR_42->m_tx_inventory_known_filter.insert(VAR_25);\n                        /* COMMENT_75 */\n                        VAR_37.push_back(VAR_50);\n                        if (VAR_37.size() == VAR_41) {\n                            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n                            VAR_37.clear();\n                        }\n                    }\n                    VAR_42->m_last_mempool_req = std::chrono::VAR_53<std::chrono::seconds>(VAR_6);\n                }\n\n                /* COMMENT_76 */\n                if (VAR_43) {\n                    /* COMMENT_77 */\n                    std::vector<std::set<uint256>::iterator> VAR_54;\n                    VAR_54.reserve(VAR_42->m_tx_inventory_to_send.size());\n                    for (std::set<uint256>::iterator VAR_55 = VAR_42->m_tx_inventory_to_send.begin(); VAR_55 != VAR_42->m_tx_inventory_to_send.end(); VAR_55++) {\n                        VAR_54.push_back(VAR_55);\n                    }\n                    const CFeeRate VAR_48{VAR_42->m_fee_filter_received.load()};\n                    /* COMMENT_78 */\n                    /* COMMENT_79 */\n                    CompareInvMempoolOrder VAR_56(&VAR_47, VAR_2->m_wtxid_relay);\n                    std::make_heap(VAR_54.begin(), VAR_54.end(), VAR_56);\n                    /* COMMENT_80 */\n                    /* COMMENT_81 */\n                    unsigned int VAR_57 = 0;\n                    LOCK(VAR_42->m_bloom_filter_mutex);\n                    while (!VAR_54.empty() && VAR_57 < VAR_39) {\n                        /* COMMENT_82 */\n                        std::pop_heap(VAR_54.begin(), VAR_54.end(), VAR_56);\n                        std::set<uint256>::iterator VAR_55 = VAR_54.back();\n                        VAR_54.pop_back();\n                        uint256 VAR_25 = *VAR_55;\n                        CInv VAR_50(VAR_2->m_wtxid_relay ? VAR_51 : VAR_52, VAR_25);\n                        /* COMMENT_83 */\n                        VAR_42->m_tx_inventory_to_send.erase(VAR_55);\n                        /* COMMENT_84 */\n                        if (VAR_42->m_tx_inventory_known_filter.contains(VAR_25)) {\n                            continue;\n                        }\n                        /* COMMENT_85 */\n                        auto VAR_49 = VAR_47.info(ToGenTxid(VAR_50));\n                        if (!VAR_49.tx) {\n                            continue;\n                        }\n                        auto VAR_58 = VAR_49.tx->GetHash();\n                        auto VAR_59 = VAR_49.tx->GetWitnessHash();\n                        /* COMMENT_86 */\n                        if (VAR_49.fee < VAR_48.GetFee(VAR_49.vsize)) {\n                            continue;\n                        }\n                        if (VAR_42->m_bloom_filter && !VAR_42->m_bloom_filter->IsRelevantAndUpdate(*VAR_49.tx)) continue;\n                        /* COMMENT_87 */\n                        VAR_42->m_recently_announced_invs.insert(VAR_25);\n                        VAR_37.push_back(VAR_50);\n                        VAR_57++;\n                        {\n                            /* COMMENT_88 */\n                            while (!VAR_60.empty() && VAR_60.front().first < VAR_6)\n                            {\n                                VAR_61.erase(VAR_60.front().second);\n                                VAR_60.pop_front();\n                            }\n\n                            auto VAR_34 = VAR_61.emplace(VAR_58, std::move(VAR_49.tx));\n                            if (VAR_34.second) {\n                                VAR_60.emplace_back(VAR_6 + VAR_62, VAR_34.first);\n                            }\n                            /* COMMENT_89 */\n                            auto VAR_63 = VAR_61.emplace(VAR_59, VAR_34.first->second);\n                            if (VAR_63.second) {\n                                VAR_60.emplace_back(VAR_6 + VAR_62, VAR_63.first);\n                            }\n                        }\n                        if (VAR_37.size() == VAR_41) {\n                            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n                            VAR_37.clear();\n                        }\n                        VAR_42->m_tx_inventory_known_filter.insert(VAR_25);\n                        if (VAR_25 != VAR_58) {\n                            /* COMMENT_90 */\n                            /* COMMENT_91 */\n                            /* COMMENT_92 */\n                            /* COMMENT_93 */\n                            /* COMMENT_94 */\n                            VAR_42->m_tx_inventory_known_filter.insert(VAR_58);\n                        }\n                    }\n                }\n        }\n        if (!VAR_37.empty())\n            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n\n        /* COMMENT_95 */\n        auto VAR_64 = VAR_65.load();\n        if (VAR_10.m_stalling_since.count() && VAR_10.m_stalling_since < VAR_6 - VAR_64) {\n            /* COMMENT_96 */\n            /* COMMENT_97 */\n            /* COMMENT_98 */\n            LogPrintf(\"Peer=%d is stalling block download, disconnecting\\n\", VAR_0->GetId());\n            VAR_0->fDisconnect = true;\n            /* COMMENT_99 */\n            /* COMMENT_100 */\n            const auto VAR_66 = std::min(2 * VAR_64, VAR_67);\n            if (VAR_64 != VAR_66 && VAR_65.compare_exchange_strong(VAR_64, VAR_66)) {\n                LogPrint(BCLog::NET, \"Increased stalling timeout temporarily to %d seconds\\n\", count_seconds(VAR_66));\n            }\n            return true;\n        }\n        /* COMMENT_101 */\n        /* COMMENT_102 */\n        /* COMMENT_103 */\n        /* COMMENT_104 */\n        /* COMMENT_105 */\n        if (VAR_10.vBlocksInFlight.size() > 0) {\n            QueuedBlock &VAR_68 = VAR_10.vBlocksInFlight.front();\n            int VAR_69 = VAR_70 - 1;\n            if (VAR_6 > VAR_10.m_downloading_since + std::chrono::seconds{VAR_3.nPowTargetSpacing} * (VAR_71 + VAR_72 * VAR_69)) {\n                LogPrintf(\"Timeout downloading block %s from peer=%d, disconnecting\\n\", VAR_68.pindex->GetBlockHash().ToString(), VAR_0->GetId());\n                VAR_0->fDisconnect = true;\n                return true;\n            }\n        }\n        /* COMMENT_106 */\n        if (VAR_10.fSyncStarted && VAR_2->m_headers_sync_timeout < std::chrono::microseconds::max()) {\n            /* COMMENT_107 */\n            if (VAR_11.m_best_header->Time() <= GetAdjustedTime() - 24h) {\n                if (VAR_6 > VAR_2->m_headers_sync_timeout && VAR_15 == 1 && (VAR_13 - VAR_10.fPreferredDownload >= 1)) {\n                    /* COMMENT_108 */\n                    /* COMMENT_109 */\n                    /* COMMENT_110 */\n                    /* COMMENT_111 */\n                    /* COMMENT_112 */\n                    if (!VAR_0->HasPermission(NetPermissionFlags::NoBan)) {\n                        LogPrintf(\"Timeout downloading headers from peer=%d, disconnecting\\n\", VAR_0->GetId());\n                        VAR_0->fDisconnect = true;\n                        return true;\n                    } else {\n                        LogPrintf(\"Timeout downloading headers from noban peer=%d, not disconnecting\\n\", VAR_0->GetId());\n                        /* COMMENT_113 */\n                        /* COMMENT_114 */\n                        /* COMMENT_115 */\n                        /* COMMENT_116 */\n                        /* COMMENT_117 */\n                        VAR_10.fSyncStarted = false;\n                        VAR_15--;\n                        VAR_2->m_headers_sync_timeout = 0us;\n                    }\n                }\n            } else {\n                /* COMMENT_118 */\n                /* COMMENT_119 */\n                VAR_2->m_headers_sync_timeout = std::chrono::microseconds::max();\n            }\n        }\n\n        /* COMMENT_120 */\n        /* COMMENT_121 */\n        ConsiderEviction(*VAR_0, *VAR_2, VAR_7<std::chrono::seconds>());\n\n        /* COMMENT_28 */\n        /* COMMENT_122 */\n        /* COMMENT_28 */\n        std::vector<CInv> VAR_73;\n        if (CanServeBlocks(*VAR_2) && ((VAR_12 && !IsLimitedPeer(*VAR_2)) || !VAR_11.ActiveChainstate().IsInitialBlockDownload()) && VAR_10.nBlocksInFlight < VAR_74) {\n            std::vector<const CBlockIndex*> VAR_75;\n            NodeId VAR_76 = -1;\n            FindNextBlocksToDownload(*VAR_2, VAR_74 - VAR_10.nBlocksInFlight, VAR_75, VAR_76);\n            for (const CBlockIndex *VAR_26 : VAR_75) {\n                uint32_t VAR_77 = GetFetchFlags(*VAR_2);\n                VAR_73.push_back(CInv(VAR_40 | VAR_77, VAR_26->GetBlockHash()));\n                BlockRequested(VAR_0->GetId(), *VAR_26);\n                LogPrint(BCLog::NET, \"Requesting block %s (%d) peer=%d\\n\", VAR_26->GetBlockHash().ToString(),\n                    VAR_26->nHeight, VAR_0->GetId());\n            }\n            if (VAR_10.nBlocksInFlight == 0 && VAR_76 != -1) {\n                if (State(VAR_76)->m_stalling_since == 0us) {\n                    State(VAR_76)->m_stalling_since = VAR_6;\n                    LogPrint(BCLog::NET, \"Stall started peer=%d\\n\", VAR_76);\n                }\n            }\n        }\n\n        /* COMMENT_28 */\n        /* COMMENT_123 */\n        /* COMMENT_28 */\n        std::vector<std::pair<NodeId, GenTxid>> VAR_78;\n        auto VAR_79 = VAR_80.GetRequestable(VAR_0->GetId(), VAR_6, &VAR_78);\n        for (const auto& VAR_81 : VAR_78) {\n            LogPrint(BCLog::NET, \"timeout of inflight %s %s from peer=%d\\n\", VAR_81.second.IsWtxid() ? \"wtx\" : \"tx\",\n                VAR_81.second.GetHash().ToString(), VAR_81.first);\n        }\n        for (const GenTxid& VAR_82 : VAR_79) {\n            if (!AlreadyHaveTx(VAR_82)) {\n                LogPrint(BCLog::NET, \"Requesting %s %s peer=%d\\n\", VAR_82.IsWtxid() ? \"wtx\" : \"tx\",\n                    VAR_82.GetHash().ToString(), VAR_0->GetId());\n                VAR_73.emplace_back(VAR_82.IsWtxid() ? VAR_51 : (VAR_52 | GetFetchFlags(*VAR_2)), VAR_82.GetHash());\n                if (VAR_73.size() >= VAR_83) {\n                    VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::GETDATA, VAR_73));\n                    VAR_73.clear();\n                }\n                VAR_80.RequestedTx(VAR_0->GetId(), VAR_82.GetHash(), VAR_6 + VAR_84);\n            } else {\n                /* COMMENT_124 */\n                /* COMMENT_125 */\n                VAR_80.ForgetTxHash(VAR_82.GetHash());\n            }\n        }\n\n\n        if (!VAR_73.empty())\n            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::GETDATA, VAR_73));\n    } /* COMMENT_126 */\n    MaybeSendFeefilter(*VAR_0, *VAR_2, VAR_6);\n    return true;\n}",
  "func_graph_path_before": "bitcoin/5b3406094f2679dfb3763de4414257268565b943/net_processing.cpp/vul/before/0.json",
  "func": "bool PeerManagerImpl::SendMessages(CNode* pto)\n{\n    AssertLockHeld(g_msgproc_mutex);\n\n    PeerRef peer = GetPeerRef(pto->GetId());\n    if (!peer) return false;\n    const Consensus::Params& consensusParams = m_chainparams.GetConsensus();\n\n    // We must call MaybeDiscourageAndDisconnect first, to ensure that we'll\n    // disconnect misbehaving peers even before the version handshake is complete.\n    if (MaybeDiscourageAndDisconnect(*pto, *peer)) return true;\n\n    // Don't send anything until the version handshake is complete\n    if (!pto->fSuccessfullyConnected || pto->fDisconnect)\n        return true;\n\n    // If we get here, the outgoing message serialization version is set and can't change.\n    const CNetMsgMaker msgMaker(pto->GetCommonVersion());\n\n    const auto current_time{GetTime<std::chrono::microseconds>()};\n\n    if (pto->IsAddrFetchConn() && current_time - pto->m_connected > 10 * AVG_ADDRESS_BROADCAST_INTERVAL) {\n        LogPrint(BCLog::NET, \"addrfetch connection timeout; disconnecting peer=%d\\n\", pto->GetId());\n        pto->fDisconnect = true;\n        return true;\n    }\n\n    MaybeSendPing(*pto, *peer, current_time);\n\n    // MaybeSendPing may have marked peer for disconnection\n    if (pto->fDisconnect) return true;\n\n    MaybeSendAddr(*pto, *peer, current_time);\n\n    MaybeSendSendHeaders(*pto, *peer);\n\n    {\n        LOCK(cs_main);\n\n        CNodeState &state = *State(pto->GetId());\n\n        // Start block sync\n        if (m_chainman.m_best_header == nullptr) {\n            m_chainman.m_best_header = m_chainman.ActiveChain().Tip();\n        }\n\n        // Determine whether we might try initial headers sync or parallel\n        // block download from this peer -- this mostly affects behavior while\n        // in IBD (once out of IBD, we sync from all peers).\n        bool sync_blocks_and_headers_from_peer = false;\n        if (state.fPreferredDownload) {\n            sync_blocks_and_headers_from_peer = true;\n        } else if (CanServeBlocks(*peer) && !pto->IsAddrFetchConn()) {\n            // Typically this is an inbound peer. If we don't have any outbound\n            // peers, or if we aren't downloading any blocks from such peers,\n            // then allow block downloads from this peer, too.\n            // We prefer downloading blocks from outbound peers to avoid\n            // putting undue load on (say) some home user who is just making\n            // outbound connections to the network, but if our only source of\n            // the latest blocks is from an inbound peer, we have to be sure to\n            // eventually download it (and not just wait indefinitely for an\n            // outbound peer to have it).\n            if (m_num_preferred_download_peers == 0 || mapBlocksInFlight.empty()) {\n                sync_blocks_and_headers_from_peer = true;\n            }\n        }\n\n        if (!state.fSyncStarted && CanServeBlocks(*peer) && !m_chainman.m_blockman.LoadingBlocks()) {\n            // Only actively request headers from a single peer, unless we're close to today.\n            if ((nSyncStarted == 0 && sync_blocks_and_headers_from_peer) || m_chainman.m_best_header->Time() > GetAdjustedTime() - 24h) {\n                const CBlockIndex* pindexStart = m_chainman.m_best_header;\n                /* If possible, start at the block preceding the currently\n                   best known header.  This ensures that we always get a\n                   non-empty list of headers back as long as the peer\n                   is up-to-date.  With a non-empty response, we can initialise\n                   the peer's known best block.  This wouldn't be possible\n                   if we requested starting at m_chainman.m_best_header and\n                   got back an empty response.  */\n                if (pindexStart->pprev)\n                    pindexStart = pindexStart->pprev;\n                if (MaybeSendGetHeaders(*pto, GetLocator(pindexStart), *peer)) {\n                    LogPrint(BCLog::NET, \"initial getheaders (%d) to peer=%d (startheight:%d)\\n\", pindexStart->nHeight, pto->GetId(), peer->m_starting_height);\n\n                    state.fSyncStarted = true;\n                    peer->m_headers_sync_timeout = current_time + HEADERS_DOWNLOAD_TIMEOUT_BASE +\n                        (\n                         // Convert HEADERS_DOWNLOAD_TIMEOUT_PER_HEADER to microseconds before scaling\n                         // to maintain precision\n                         std::chrono::microseconds{HEADERS_DOWNLOAD_TIMEOUT_PER_HEADER} *\n                         Ticks<std::chrono::seconds>(GetAdjustedTime() - m_chainman.m_best_header->Time()) / consensusParams.nPowTargetSpacing\n                        );\n                    nSyncStarted++;\n                }\n            }\n        }\n\n        //\n        // Try sending block announcements via headers\n        //\n        {\n            // If we have no more than MAX_BLOCKS_TO_ANNOUNCE in our\n            // list of block hashes we're relaying, and our peer wants\n            // headers announcements, then find the first header\n            // not yet known to our peer but would connect, and send.\n            // If no header would connect, or if we have too many\n            // blocks, or if the peer doesn't want headers, just\n            // add all to the inv queue.\n            LOCK(peer->m_block_inv_mutex);\n            std::vector<CBlock> vHeaders;\n            bool fRevertToInv = ((!peer->m_prefers_headers &&\n                                 (!state.m_requested_hb_cmpctblocks || peer->m_blocks_for_headers_relay.size() > 1)) ||\n                                 peer->m_blocks_for_headers_relay.size() > MAX_BLOCKS_TO_ANNOUNCE);\n            const CBlockIndex *pBestIndex = nullptr; // last header queued for delivery\n            ProcessBlockAvailability(pto->GetId()); // ensure pindexBestKnownBlock is up-to-date\n\n            if (!fRevertToInv) {\n                bool fFoundStartingHeader = false;\n                // Try to find first header that our peer doesn't have, and\n                // then send all headers past that one.  If we come across any\n                // headers that aren't on m_chainman.ActiveChain(), give up.\n                for (const uint256& hash : peer->m_blocks_for_headers_relay) {\n                    const CBlockIndex* pindex = m_chainman.m_blockman.LookupBlockIndex(hash);\n                    assert(pindex);\n                    if (m_chainman.ActiveChain()[pindex->nHeight] != pindex) {\n                        // Bail out if we reorged away from this block\n                        fRevertToInv = true;\n                        break;\n                    }\n                    if (pBestIndex != nullptr && pindex->pprev != pBestIndex) {\n                        // This means that the list of blocks to announce don't\n                        // connect to each other.\n                        // This shouldn't really be possible to hit during\n                        // regular operation (because reorgs should take us to\n                        // a chain that has some block not on the prior chain,\n                        // which should be caught by the prior check), but one\n                        // way this could happen is by using invalidateblock /\n                        // reconsiderblock repeatedly on the tip, causing it to\n                        // be added multiple times to m_blocks_for_headers_relay.\n                        // Robustly deal with this rare situation by reverting\n                        // to an inv.\n                        fRevertToInv = true;\n                        break;\n                    }\n                    pBestIndex = pindex;\n                    if (fFoundStartingHeader) {\n                        // add this to the headers message\n                        vHeaders.push_back(pindex->GetBlockHeader());\n                    } else if (PeerHasHeader(&state, pindex)) {\n                        continue; // keep looking for the first new block\n                    } else if (pindex->pprev == nullptr || PeerHasHeader(&state, pindex->pprev)) {\n                        // Peer doesn't have this header but they do have the prior one.\n                        // Start sending headers.\n                        fFoundStartingHeader = true;\n                        vHeaders.push_back(pindex->GetBlockHeader());\n                    } else {\n                        // Peer doesn't have this header or the prior one -- nothing will\n                        // connect, so bail out.\n                        fRevertToInv = true;\n                        break;\n                    }\n                }\n            }\n            if (!fRevertToInv && !vHeaders.empty()) {\n                if (vHeaders.size() == 1 && state.m_requested_hb_cmpctblocks) {\n                    // We only send up to 1 block as header-and-ids, as otherwise\n                    // probably means we're doing an initial-ish-sync or they're slow\n                    LogPrint(BCLog::NET, \"%s sending header-and-ids %s to peer=%d\\n\", __func__,\n                            vHeaders.front().GetHash().ToString(), pto->GetId());\n\n                    std::optional<CSerializedNetMsg> cached_cmpctblock_msg;\n                    {\n                        LOCK(m_most_recent_block_mutex);\n                        if (m_most_recent_block_hash == pBestIndex->GetBlockHash()) {\n                            cached_cmpctblock_msg = msgMaker.Make(NetMsgType::CMPCTBLOCK, *m_most_recent_compact_block);\n                        }\n                    }\n                    if (cached_cmpctblock_msg.has_value()) {\n                        m_connman.PushMessage(pto, std::move(cached_cmpctblock_msg.value()));\n                    } else {\n                        CBlock block;\n                        bool ret = ReadBlockFromDisk(block, pBestIndex, consensusParams);\n                        assert(ret);\n                        CBlockHeaderAndShortTxIDs cmpctblock{block};\n                        m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::CMPCTBLOCK, cmpctblock));\n                    }\n                    state.pindexBestHeaderSent = pBestIndex;\n                } else if (peer->m_prefers_headers) {\n                    if (vHeaders.size() > 1) {\n                        LogPrint(BCLog::NET, \"%s: %u headers, range (%s, %s), to peer=%d\\n\", __func__,\n                                vHeaders.size(),\n                                vHeaders.front().GetHash().ToString(),\n                                vHeaders.back().GetHash().ToString(), pto->GetId());\n                    } else {\n                        LogPrint(BCLog::NET, \"%s: sending header %s to peer=%d\\n\", __func__,\n                                vHeaders.front().GetHash().ToString(), pto->GetId());\n                    }\n                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::HEADERS, vHeaders));\n                    state.pindexBestHeaderSent = pBestIndex;\n                } else\n                    fRevertToInv = true;\n            }\n            if (fRevertToInv) {\n                // If falling back to using an inv, just try to inv the tip.\n                // The last entry in m_blocks_for_headers_relay was our tip at some point\n                // in the past.\n                if (!peer->m_blocks_for_headers_relay.empty()) {\n                    const uint256& hashToAnnounce = peer->m_blocks_for_headers_relay.back();\n                    const CBlockIndex* pindex = m_chainman.m_blockman.LookupBlockIndex(hashToAnnounce);\n                    assert(pindex);\n\n                    // Warn if we're announcing a block that is not on the main chain.\n                    // This should be very rare and could be optimized out.\n                    // Just log for now.\n                    if (m_chainman.ActiveChain()[pindex->nHeight] != pindex) {\n                        LogPrint(BCLog::NET, \"Announcing block %s not on main chain (tip=%s)\\n\",\n                            hashToAnnounce.ToString(), m_chainman.ActiveChain().Tip()->GetBlockHash().ToString());\n                    }\n\n                    // If the peer's chain has this block, don't inv it back.\n                    if (!PeerHasHeader(&state, pindex)) {\n                        peer->m_blocks_for_inv_relay.push_back(hashToAnnounce);\n                        LogPrint(BCLog::NET, \"%s: sending inv peer=%d hash=%s\\n\", __func__,\n                            pto->GetId(), hashToAnnounce.ToString());\n                    }\n                }\n            }\n            peer->m_blocks_for_headers_relay.clear();\n        }\n\n        //\n        // Message: inventory\n        //\n        std::vector<CInv> vInv;\n        {\n            LOCK(peer->m_block_inv_mutex);\n            vInv.reserve(std::max<size_t>(peer->m_blocks_for_inv_relay.size(), INVENTORY_BROADCAST_MAX));\n\n            // Add blocks\n            for (const uint256& hash : peer->m_blocks_for_inv_relay) {\n                vInv.push_back(CInv(MSG_BLOCK, hash));\n                if (vInv.size() == MAX_INV_SZ) {\n                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n                    vInv.clear();\n                }\n            }\n            peer->m_blocks_for_inv_relay.clear();\n        }\n\n        if (auto tx_relay = peer->GetTxRelay(); tx_relay != nullptr) {\n                LOCK(tx_relay->m_tx_inventory_mutex);\n                // Check whether periodic sends should happen\n                bool fSendTrickle = pto->HasPermission(NetPermissionFlags::NoBan);\n                if (tx_relay->m_next_inv_send_time < current_time) {\n                    fSendTrickle = true;\n                    if (pto->IsInboundConn()) {\n                        tx_relay->m_next_inv_send_time = NextInvToInbounds(current_time, INBOUND_INVENTORY_BROADCAST_INTERVAL);\n                    } else {\n                        tx_relay->m_next_inv_send_time = GetExponentialRand(current_time, OUTBOUND_INVENTORY_BROADCAST_INTERVAL);\n                    }\n                }\n\n                // Time to send but the peer has requested we not relay transactions.\n                if (fSendTrickle) {\n                    LOCK(tx_relay->m_bloom_filter_mutex);\n                    if (!tx_relay->m_relay_txs) tx_relay->m_tx_inventory_to_send.clear();\n                }\n\n                // Respond to BIP35 mempool requests\n                if (fSendTrickle && tx_relay->m_send_mempool) {\n                    auto vtxinfo = m_mempool.infoAll();\n                    tx_relay->m_send_mempool = false;\n                    const CFeeRate filterrate{tx_relay->m_fee_filter_received.load()};\n\n                    LOCK(tx_relay->m_bloom_filter_mutex);\n\n                    for (const auto& txinfo : vtxinfo) {\n                        const uint256& hash = peer->m_wtxid_relay ? txinfo.tx->GetWitnessHash() : txinfo.tx->GetHash();\n                        CInv inv(peer->m_wtxid_relay ? MSG_WTX : MSG_TX, hash);\n                        tx_relay->m_tx_inventory_to_send.erase(hash);\n                        // Don't send transactions that peers will not put into their mempool\n                        if (txinfo.fee < filterrate.GetFee(txinfo.vsize)) {\n                            continue;\n                        }\n                        if (tx_relay->m_bloom_filter) {\n                            if (!tx_relay->m_bloom_filter->IsRelevantAndUpdate(*txinfo.tx)) continue;\n                        }\n                        tx_relay->m_tx_inventory_known_filter.insert(hash);\n                        // Responses to MEMPOOL requests bypass the m_recently_announced_invs filter.\n                        vInv.push_back(inv);\n                        if (vInv.size() == MAX_INV_SZ) {\n                            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n                            vInv.clear();\n                        }\n                    }\n                    tx_relay->m_last_mempool_req = std::chrono::duration_cast<std::chrono::seconds>(current_time);\n                }\n\n                // Determine transactions to relay\n                if (fSendTrickle) {\n                    // Produce a vector with all candidates for sending\n                    std::vector<std::set<uint256>::iterator> vInvTx;\n                    vInvTx.reserve(tx_relay->m_tx_inventory_to_send.size());\n                    for (std::set<uint256>::iterator it = tx_relay->m_tx_inventory_to_send.begin(); it != tx_relay->m_tx_inventory_to_send.end(); it++) {\n                        vInvTx.push_back(it);\n                    }\n                    const CFeeRate filterrate{tx_relay->m_fee_filter_received.load()};\n                    // Topologically and fee-rate sort the inventory we send for privacy and priority reasons.\n                    // A heap is used so that not all items need sorting if only a few are being sent.\n                    CompareInvMempoolOrder compareInvMempoolOrder(&m_mempool, peer->m_wtxid_relay);\n                    std::make_heap(vInvTx.begin(), vInvTx.end(), compareInvMempoolOrder);\n                    // No reason to drain out at many times the network's capacity,\n                    // especially since we have many peers and some will draw much shorter delays.\n                    unsigned int nRelayedTransactions = 0;\n                    LOCK(tx_relay->m_bloom_filter_mutex);\n                    size_t broadcast_max{INVENTORY_BROADCAST_MAX + (tx_relay->m_tx_inventory_to_send.size()/1000)*5};\n                    broadcast_max = std::min<size_t>(1000, broadcast_max);\n                    while (!vInvTx.empty() && nRelayedTransactions < broadcast_max) {\n                        // Fetch the top element from the heap\n                        std::pop_heap(vInvTx.begin(), vInvTx.end(), compareInvMempoolOrder);\n                        std::set<uint256>::iterator it = vInvTx.back();\n                        vInvTx.pop_back();\n                        uint256 hash = *it;\n                        CInv inv(peer->m_wtxid_relay ? MSG_WTX : MSG_TX, hash);\n                        // Remove it from the to-be-sent set\n                        tx_relay->m_tx_inventory_to_send.erase(it);\n                        // Check if not in the filter already\n                        if (tx_relay->m_tx_inventory_known_filter.contains(hash)) {\n                            continue;\n                        }\n                        // Not in the mempool anymore? don't bother sending it.\n                        auto txinfo = m_mempool.info(ToGenTxid(inv));\n                        if (!txinfo.tx) {\n                            continue;\n                        }\n                        auto txid = txinfo.tx->GetHash();\n                        auto wtxid = txinfo.tx->GetWitnessHash();\n                        // Peer told you to not send transactions at that feerate? Don't bother sending it.\n                        if (txinfo.fee < filterrate.GetFee(txinfo.vsize)) {\n                            continue;\n                        }\n                        if (tx_relay->m_bloom_filter && !tx_relay->m_bloom_filter->IsRelevantAndUpdate(*txinfo.tx)) continue;\n                        // Send\n                        tx_relay->m_recently_announced_invs.insert(hash);\n                        vInv.push_back(inv);\n                        nRelayedTransactions++;\n                        {\n                            // Expire old relay messages\n                            while (!g_relay_expiration.empty() && g_relay_expiration.front().first < current_time)\n                            {\n                                mapRelay.erase(g_relay_expiration.front().second);\n                                g_relay_expiration.pop_front();\n                            }\n\n                            auto ret = mapRelay.emplace(txid, std::move(txinfo.tx));\n                            if (ret.second) {\n                                g_relay_expiration.emplace_back(current_time + RELAY_TX_CACHE_TIME, ret.first);\n                            }\n                            // Add wtxid-based lookup into mapRelay as well, so that peers can request by wtxid\n                            auto ret2 = mapRelay.emplace(wtxid, ret.first->second);\n                            if (ret2.second) {\n                                g_relay_expiration.emplace_back(current_time + RELAY_TX_CACHE_TIME, ret2.first);\n                            }\n                        }\n                        if (vInv.size() == MAX_INV_SZ) {\n                            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n                            vInv.clear();\n                        }\n                        tx_relay->m_tx_inventory_known_filter.insert(hash);\n                        if (hash != txid) {\n                            // Insert txid into m_tx_inventory_known_filter, even for\n                            // wtxidrelay peers. This prevents re-adding of\n                            // unconfirmed parents to the recently_announced\n                            // filter, when a child tx is requested. See\n                            // ProcessGetData().\n                            tx_relay->m_tx_inventory_known_filter.insert(txid);\n                        }\n                    }\n                }\n        }\n        if (!vInv.empty())\n            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n\n        // Detect whether we're stalling\n        auto stalling_timeout = m_block_stalling_timeout.load();\n        if (state.m_stalling_since.count() && state.m_stalling_since < current_time - stalling_timeout) {\n            // Stalling only triggers when the block download window cannot move. During normal steady state,\n            // the download window should be much larger than the to-be-downloaded set of blocks, so disconnection\n            // should only happen during initial block download.\n            LogPrintf(\"Peer=%d is stalling block download, disconnecting\\n\", pto->GetId());\n            pto->fDisconnect = true;\n            // Increase timeout for the next peer so that we don't disconnect multiple peers if our own\n            // bandwidth is insufficient.\n            const auto new_timeout = std::min(2 * stalling_timeout, BLOCK_STALLING_TIMEOUT_MAX);\n            if (stalling_timeout != new_timeout && m_block_stalling_timeout.compare_exchange_strong(stalling_timeout, new_timeout)) {\n                LogPrint(BCLog::NET, \"Increased stalling timeout temporarily to %d seconds\\n\", count_seconds(new_timeout));\n            }\n            return true;\n        }\n        // In case there is a block that has been in flight from this peer for block_interval * (1 + 0.5 * N)\n        // (with N the number of peers from which we're downloading validated blocks), disconnect due to timeout.\n        // We compensate for other peers to prevent killing off peers due to our own downstream link\n        // being saturated. We only count validated in-flight blocks so peers can't advertise non-existing block hashes\n        // to unreasonably increase our timeout.\n        if (state.vBlocksInFlight.size() > 0) {\n            QueuedBlock &queuedBlock = state.vBlocksInFlight.front();\n            int nOtherPeersWithValidatedDownloads = m_peers_downloading_from - 1;\n            if (current_time > state.m_downloading_since + std::chrono::seconds{consensusParams.nPowTargetSpacing} * (BLOCK_DOWNLOAD_TIMEOUT_BASE + BLOCK_DOWNLOAD_TIMEOUT_PER_PEER * nOtherPeersWithValidatedDownloads)) {\n                LogPrintf(\"Timeout downloading block %s from peer=%d, disconnecting\\n\", queuedBlock.pindex->GetBlockHash().ToString(), pto->GetId());\n                pto->fDisconnect = true;\n                return true;\n            }\n        }\n        // Check for headers sync timeouts\n        if (state.fSyncStarted && peer->m_headers_sync_timeout < std::chrono::microseconds::max()) {\n            // Detect whether this is a stalling initial-headers-sync peer\n            if (m_chainman.m_best_header->Time() <= GetAdjustedTime() - 24h) {\n                if (current_time > peer->m_headers_sync_timeout && nSyncStarted == 1 && (m_num_preferred_download_peers - state.fPreferredDownload >= 1)) {\n                    // Disconnect a peer (without NetPermissionFlags::NoBan permission) if it is our only sync peer,\n                    // and we have others we could be using instead.\n                    // Note: If all our peers are inbound, then we won't\n                    // disconnect our sync peer for stalling; we have bigger\n                    // problems if we can't get any outbound peers.\n                    if (!pto->HasPermission(NetPermissionFlags::NoBan)) {\n                        LogPrintf(\"Timeout downloading headers from peer=%d, disconnecting\\n\", pto->GetId());\n                        pto->fDisconnect = true;\n                        return true;\n                    } else {\n                        LogPrintf(\"Timeout downloading headers from noban peer=%d, not disconnecting\\n\", pto->GetId());\n                        // Reset the headers sync state so that we have a\n                        // chance to try downloading from a different peer.\n                        // Note: this will also result in at least one more\n                        // getheaders message to be sent to\n                        // this peer (eventually).\n                        state.fSyncStarted = false;\n                        nSyncStarted--;\n                        peer->m_headers_sync_timeout = 0us;\n                    }\n                }\n            } else {\n                // After we've caught up once, reset the timeout so we can't trigger\n                // disconnect later.\n                peer->m_headers_sync_timeout = std::chrono::microseconds::max();\n            }\n        }\n\n        // Check that outbound peers have reasonable chains\n        // GetTime() is used by this anti-DoS logic so we can test this using mocktime\n        ConsiderEviction(*pto, *peer, GetTime<std::chrono::seconds>());\n\n        //\n        // Message: getdata (blocks)\n        //\n        std::vector<CInv> vGetData;\n        if (CanServeBlocks(*peer) && ((sync_blocks_and_headers_from_peer && !IsLimitedPeer(*peer)) || !m_chainman.ActiveChainstate().IsInitialBlockDownload()) && state.nBlocksInFlight < MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n            std::vector<const CBlockIndex*> vToDownload;\n            NodeId staller = -1;\n            FindNextBlocksToDownload(*peer, MAX_BLOCKS_IN_TRANSIT_PER_PEER - state.nBlocksInFlight, vToDownload, staller);\n            for (const CBlockIndex *pindex : vToDownload) {\n                uint32_t nFetchFlags = GetFetchFlags(*peer);\n                vGetData.push_back(CInv(MSG_BLOCK | nFetchFlags, pindex->GetBlockHash()));\n                BlockRequested(pto->GetId(), *pindex);\n                LogPrint(BCLog::NET, \"Requesting block %s (%d) peer=%d\\n\", pindex->GetBlockHash().ToString(),\n                    pindex->nHeight, pto->GetId());\n            }\n            if (state.nBlocksInFlight == 0 && staller != -1) {\n                if (State(staller)->m_stalling_since == 0us) {\n                    State(staller)->m_stalling_since = current_time;\n                    LogPrint(BCLog::NET, \"Stall started peer=%d\\n\", staller);\n                }\n            }\n        }\n\n        //\n        // Message: getdata (transactions)\n        //\n        std::vector<std::pair<NodeId, GenTxid>> expired;\n        auto requestable = m_txrequest.GetRequestable(pto->GetId(), current_time, &expired);\n        for (const auto& entry : expired) {\n            LogPrint(BCLog::NET, \"timeout of inflight %s %s from peer=%d\\n\", entry.second.IsWtxid() ? \"wtx\" : \"tx\",\n                entry.second.GetHash().ToString(), entry.first);\n        }\n        for (const GenTxid& gtxid : requestable) {\n            if (!AlreadyHaveTx(gtxid)) {\n                LogPrint(BCLog::NET, \"Requesting %s %s peer=%d\\n\", gtxid.IsWtxid() ? \"wtx\" : \"tx\",\n                    gtxid.GetHash().ToString(), pto->GetId());\n                vGetData.emplace_back(gtxid.IsWtxid() ? MSG_WTX : (MSG_TX | GetFetchFlags(*peer)), gtxid.GetHash());\n                if (vGetData.size() >= MAX_GETDATA_SZ) {\n                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n                    vGetData.clear();\n                }\n                m_txrequest.RequestedTx(pto->GetId(), gtxid.GetHash(), current_time + GETDATA_TX_INTERVAL);\n            } else {\n                // We have already seen this transaction, no need to download. This is just a belt-and-suspenders, as\n                // this should already be called whenever a transaction becomes AlreadyHaveTx().\n                m_txrequest.ForgetTxHash(gtxid.GetHash());\n            }\n        }\n\n\n        if (!vGetData.empty())\n            m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n    } // release cs_main\n    MaybeSendFeefilter(*pto, *peer, current_time);\n    return true;\n}",
  "abstract_func": "bool PeerManagerImpl::SendMessages(CNode* VAR_0)\n{\n    AssertLockHeld(VAR_1);\n\n    PeerRef VAR_2 = GetPeerRef(VAR_0->GetId());\n    if (!VAR_2) return false;\n    const Consensus::Params& VAR_3 = VAR_4.GetConsensus();\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    if (MaybeDiscourageAndDisconnect(*VAR_0, *VAR_2)) return true;\n\n    /* COMMENT_2 */\n    if (!VAR_0->fSuccessfullyConnected || VAR_0->fDisconnect)\n        return true;\n\n    /* COMMENT_3 */\n    const CNetMsgMaker VAR_5(VAR_0->GetCommonVersion());\n\n    const auto VAR_6{VAR_7<std::chrono::microseconds>()};\n\n    if (VAR_0->IsAddrFetchConn() && VAR_6 - VAR_0->m_connected > 10 * VAR_8) {\n        LogPrint(BCLog::NET, \"addrfetch connection timeout; disconnecting peer=%d\\n\", VAR_0->GetId());\n        VAR_0->fDisconnect = true;\n        return true;\n    }\n\n    MaybeSendPing(*VAR_0, *VAR_2, VAR_6);\n\n    /* COMMENT_4 */\n    if (VAR_0->fDisconnect) return true;\n\n    MaybeSendAddr(*VAR_0, *VAR_2, VAR_6);\n\n    MaybeSendSendHeaders(*VAR_0, *VAR_2);\n\n    {\n        LOCK(VAR_9);\n\n        CNodeState &VAR_10 = *State(VAR_0->GetId());\n\n        /* COMMENT_5 */\n        if (VAR_11.m_best_header == nullptr) {\n            VAR_11.m_best_header = VAR_11.ActiveChain().Tip();\n        }\n\n        /* COMMENT_6 */\n        /* COMMENT_7 */\n        /* COMMENT_8 */\n        bool VAR_12 = false;\n        if (VAR_10.fPreferredDownload) {\n            VAR_12 = true;\n        } else if (CanServeBlocks(*VAR_2) && !VAR_0->IsAddrFetchConn()) {\n            /* COMMENT_9 */\n            /* COMMENT_10 */\n            /* COMMENT_11 */\n            /* COMMENT_12 */\n            /* COMMENT_13 */\n            /* COMMENT_14 */\n            /* COMMENT_15 */\n            /* COMMENT_16 */\n            /* COMMENT_17 */\n            if (VAR_13 == 0 || VAR_14.empty()) {\n                VAR_12 = true;\n            }\n        }\n\n        if (!VAR_10.fSyncStarted && CanServeBlocks(*VAR_2) && !VAR_11.m_blockman.LoadingBlocks()) {\n            /* COMMENT_18 */\n            if ((VAR_15 == 0 && VAR_12) || VAR_11.m_best_header->Time() > GetAdjustedTime() - 24h) {\n                const CBlockIndex* VAR_16 = VAR_11.m_best_header;\n                /* COMMENT_19 */\n                                                                        \n                                                                     \n                                                                               \n                                                                          \n                                                                           \n                                                  \n                if (VAR_16->pprev)\n                    VAR_16 = VAR_16->pprev;\n                if (MaybeSendGetHeaders(*VAR_0, GetLocator(VAR_16), *VAR_2)) {\n                    LogPrint(BCLog::NET, \"initial getheaders (%d) to peer=%d (startheight:%d)\\n\", VAR_16->nHeight, VAR_0->GetId(), VAR_2->m_starting_height);\n\n                    VAR_10.fSyncStarted = true;\n                    VAR_2->m_headers_sync_timeout = VAR_6 + VAR_17 +\n                        (\n                         /* COMMENT_26 */\n                         /* COMMENT_27 */\n                         std::chrono::microseconds{VAR_18} *\n                         VAR_19<std::chrono::seconds>(GetAdjustedTime() - VAR_11.m_best_header->Time()) / VAR_3.nPowTargetSpacing\n                        );\n                    VAR_15++;\n                }\n            }\n        }\n\n        /* COMMENT_28 */\n        /* COMMENT_29 */\n        /* COMMENT_28 */\n        {\n            /* COMMENT_30 */\n            /* COMMENT_31 */\n            /* COMMENT_32 */\n            /* COMMENT_33 */\n            /* COMMENT_34 */\n            /* COMMENT_35 */\n            /* COMMENT_36 */\n            LOCK(VAR_2->m_block_inv_mutex);\n            std::vector<CBlock> VAR_20;\n            bool VAR_21 = ((!VAR_2->m_prefers_headers &&\n                                 (!VAR_10.m_requested_hb_cmpctblocks || VAR_2->m_blocks_for_headers_relay.size() > 1)) ||\n                                 VAR_2->m_blocks_for_headers_relay.size() > VAR_22);\n            const CBlockIndex *VAR_23 = nullptr; /* COMMENT_37 */\n            ProcessBlockAvailability(VAR_0->GetId()); /* COMMENT_38 */\n\n            if (!VAR_21) {\n                bool VAR_24 = false;\n                /* COMMENT_39 */\n                /* COMMENT_40 */\n                /* COMMENT_41 */\n                for (const uint256& VAR_25 : VAR_2->m_blocks_for_headers_relay) {\n                    const CBlockIndex* VAR_26 = VAR_11.m_blockman.LookupBlockIndex(VAR_25);\n                    assert(VAR_26);\n                    if (VAR_11.ActiveChain()[VAR_26->nHeight] != VAR_26) {\n                        /* COMMENT_42 */\n                        VAR_21 = true;\n                        break;\n                    }\n                    if (VAR_23 != nullptr && VAR_26->pprev != VAR_23) {\n                        /* COMMENT_43 */\n                        /* COMMENT_44 */\n                        /* COMMENT_45 */\n                        /* COMMENT_46 */\n                        /* COMMENT_47 */\n                        /* COMMENT_48 */\n                        /* COMMENT_49 */\n                        /* COMMENT_50 */\n                        /* COMMENT_51 */\n                        /* COMMENT_52 */\n                        /* COMMENT_53 */\n                        VAR_21 = true;\n                        break;\n                    }\n                    VAR_23 = VAR_26;\n                    if (VAR_24) {\n                        /* COMMENT_54 */\n                        VAR_20.push_back(VAR_26->GetBlockHeader());\n                    } else if (PeerHasHeader(&VAR_10, VAR_26)) {\n                        continue; /* COMMENT_55 */\n                    } else if (VAR_26->pprev == nullptr || PeerHasHeader(&VAR_10, VAR_26->pprev)) {\n                        /* COMMENT_56 */\n                        /* COMMENT_57 */\n                        VAR_24 = true;\n                        VAR_20.push_back(VAR_26->GetBlockHeader());\n                    } else {\n                        /* COMMENT_58 */\n                        /* COMMENT_59 */\n                        VAR_21 = true;\n                        break;\n                    }\n                }\n            }\n            if (!VAR_21 && !VAR_20.empty()) {\n                if (VAR_20.size() == 1 && VAR_10.m_requested_hb_cmpctblocks) {\n                    /* COMMENT_60 */\n                    /* COMMENT_61 */\n                    LogPrint(BCLog::NET, \"%s sending header-and-ids %s to peer=%d\\n\", VAR_27,\n                            VAR_20.front().GetHash().ToString(), VAR_0->GetId());\n\n                    std::optional<CSerializedNetMsg> VAR_28;\n                    {\n                        LOCK(VAR_29);\n                        if (VAR_30 == VAR_23->GetBlockHash()) {\n                            VAR_28 = VAR_5.Make(NetMsgType::CMPCTBLOCK, *VAR_31);\n                        }\n                    }\n                    if (VAR_28.has_value()) {\n                        VAR_32.PushMessage(VAR_0, std::move(VAR_28.value()));\n                    } else {\n                        CBlock VAR_33;\n                        bool VAR_34 = ReadBlockFromDisk(VAR_33, VAR_23, VAR_3);\n                        assert(VAR_34);\n                        CBlockHeaderAndShortTxIDs VAR_35{VAR_33};\n                        VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::CMPCTBLOCK, VAR_35));\n                    }\n                    VAR_10.pindexBestHeaderSent = VAR_23;\n                } else if (VAR_2->m_prefers_headers) {\n                    if (VAR_20.size() > 1) {\n                        LogPrint(BCLog::NET, \"%s: %u headers, range (%s, %s), to peer=%d\\n\", VAR_27,\n                                VAR_20.size(),\n                                VAR_20.front().GetHash().ToString(),\n                                VAR_20.back().GetHash().ToString(), VAR_0->GetId());\n                    } else {\n                        LogPrint(BCLog::NET, \"%s: sending header %s to peer=%d\\n\", VAR_27,\n                                VAR_20.front().GetHash().ToString(), VAR_0->GetId());\n                    }\n                    VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::HEADERS, VAR_20));\n                    VAR_10.pindexBestHeaderSent = VAR_23;\n                } else\n                    VAR_21 = true;\n            }\n            if (VAR_21) {\n                /* COMMENT_62 */\n                /* COMMENT_63 */\n                /* COMMENT_64 */\n                if (!VAR_2->m_blocks_for_headers_relay.empty()) {\n                    const uint256& VAR_36 = VAR_2->m_blocks_for_headers_relay.back();\n                    const CBlockIndex* VAR_26 = VAR_11.m_blockman.LookupBlockIndex(VAR_36);\n                    assert(VAR_26);\n\n                    /* COMMENT_65 */\n                    /* COMMENT_66 */\n                    /* COMMENT_67 */\n                    if (VAR_11.ActiveChain()[VAR_26->nHeight] != VAR_26) {\n                        LogPrint(BCLog::NET, \"Announcing block %s not on main chain (tip=%s)\\n\",\n                            VAR_36.ToString(), VAR_11.ActiveChain().Tip()->GetBlockHash().ToString());\n                    }\n\n                    /* COMMENT_68 */\n                    if (!PeerHasHeader(&VAR_10, VAR_26)) {\n                        VAR_2->m_blocks_for_inv_relay.push_back(VAR_36);\n                        LogPrint(BCLog::NET, \"%s: sending inv peer=%d hash=%s\\n\", VAR_27,\n                            VAR_0->GetId(), VAR_36.ToString());\n                    }\n                }\n            }\n            VAR_2->m_blocks_for_headers_relay.clear();\n        }\n\n        /* COMMENT_28 */\n        /* COMMENT_69 */\n        /* COMMENT_28 */\n        std::vector<CInv> VAR_37;\n        {\n            LOCK(VAR_2->m_block_inv_mutex);\n            VAR_37.reserve(std::VAR_38<size_t>(VAR_2->m_blocks_for_inv_relay.size(), VAR_39));\n\n            /* COMMENT_70 */\n            for (const uint256& VAR_25 : VAR_2->m_blocks_for_inv_relay) {\n                VAR_37.push_back(CInv(VAR_40, VAR_25));\n                if (VAR_37.size() == VAR_41) {\n                    VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n                    VAR_37.clear();\n                }\n            }\n            VAR_2->m_blocks_for_inv_relay.clear();\n        }\n\n        if (auto VAR_42 = VAR_2->GetTxRelay(); VAR_42 != nullptr) {\n                LOCK(VAR_42->m_tx_inventory_mutex);\n                /* COMMENT_71 */\n                bool VAR_43 = VAR_0->HasPermission(NetPermissionFlags::NoBan);\n                if (VAR_42->m_next_inv_send_time < VAR_6) {\n                    VAR_43 = true;\n                    if (VAR_0->IsInboundConn()) {\n                        VAR_42->m_next_inv_send_time = NextInvToInbounds(VAR_6, VAR_44);\n                    } else {\n                        VAR_42->m_next_inv_send_time = GetExponentialRand(VAR_6, VAR_45);\n                    }\n                }\n\n                /* COMMENT_72 */\n                if (VAR_43) {\n                    LOCK(VAR_42->m_bloom_filter_mutex);\n                    if (!VAR_42->m_relay_txs) VAR_42->m_tx_inventory_to_send.clear();\n                }\n\n                /* COMMENT_73 */\n                if (VAR_43 && VAR_42->m_send_mempool) {\n                    auto VAR_46 = VAR_47.infoAll();\n                    VAR_42->m_send_mempool = false;\n                    const CFeeRate VAR_48{VAR_42->m_fee_filter_received.load()};\n\n                    LOCK(VAR_42->m_bloom_filter_mutex);\n\n                    for (const auto& VAR_49 : VAR_46) {\n                        const uint256& VAR_25 = VAR_2->m_wtxid_relay ? VAR_49.tx->GetWitnessHash() : VAR_49.tx->GetHash();\n                        CInv VAR_50(VAR_2->m_wtxid_relay ? VAR_51 : VAR_52, VAR_25);\n                        VAR_42->m_tx_inventory_to_send.erase(VAR_25);\n                        /* COMMENT_74 */\n                        if (VAR_49.fee < VAR_48.GetFee(VAR_49.vsize)) {\n                            continue;\n                        }\n                        if (VAR_42->m_bloom_filter) {\n                            if (!VAR_42->m_bloom_filter->IsRelevantAndUpdate(*VAR_49.tx)) continue;\n                        }\n                        VAR_42->m_tx_inventory_known_filter.insert(VAR_25);\n                        /* COMMENT_75 */\n                        VAR_37.push_back(VAR_50);\n                        if (VAR_37.size() == VAR_41) {\n                            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n                            VAR_37.clear();\n                        }\n                    }\n                    VAR_42->m_last_mempool_req = std::chrono::VAR_53<std::chrono::seconds>(VAR_6);\n                }\n\n                /* COMMENT_76 */\n                if (VAR_43) {\n                    /* COMMENT_77 */\n                    std::vector<std::set<uint256>::iterator> VAR_54;\n                    VAR_54.reserve(VAR_42->m_tx_inventory_to_send.size());\n                    for (std::set<uint256>::iterator VAR_55 = VAR_42->m_tx_inventory_to_send.begin(); VAR_55 != VAR_42->m_tx_inventory_to_send.end(); VAR_55++) {\n                        VAR_54.push_back(VAR_55);\n                    }\n                    const CFeeRate VAR_48{VAR_42->m_fee_filter_received.load()};\n                    /* COMMENT_78 */\n                    /* COMMENT_79 */\n                    CompareInvMempoolOrder VAR_56(&VAR_47, VAR_2->m_wtxid_relay);\n                    std::make_heap(VAR_54.begin(), VAR_54.end(), VAR_56);\n                    /* COMMENT_80 */\n                    /* COMMENT_81 */\n                    unsigned int VAR_57 = 0;\n                    LOCK(VAR_42->m_bloom_filter_mutex);\n                    size_t VAR_58{VAR_39 + (VAR_42->m_tx_inventory_to_send.size()/1000)*5};\n                    VAR_58 = std::VAR_59<size_t>(1000, VAR_58);\n                    while (!VAR_54.empty() && VAR_57 < VAR_58) {\n                        /* COMMENT_82 */\n                        std::pop_heap(VAR_54.begin(), VAR_54.end(), VAR_56);\n                        std::set<uint256>::iterator VAR_55 = VAR_54.back();\n                        VAR_54.pop_back();\n                        uint256 VAR_25 = *VAR_55;\n                        CInv VAR_50(VAR_2->m_wtxid_relay ? VAR_51 : VAR_52, VAR_25);\n                        /* COMMENT_83 */\n                        VAR_42->m_tx_inventory_to_send.erase(VAR_55);\n                        /* COMMENT_84 */\n                        if (VAR_42->m_tx_inventory_known_filter.contains(VAR_25)) {\n                            continue;\n                        }\n                        /* COMMENT_85 */\n                        auto VAR_49 = VAR_47.info(ToGenTxid(VAR_50));\n                        if (!VAR_49.tx) {\n                            continue;\n                        }\n                        auto VAR_60 = VAR_49.tx->GetHash();\n                        auto VAR_61 = VAR_49.tx->GetWitnessHash();\n                        /* COMMENT_86 */\n                        if (VAR_49.fee < VAR_48.GetFee(VAR_49.vsize)) {\n                            continue;\n                        }\n                        if (VAR_42->m_bloom_filter && !VAR_42->m_bloom_filter->IsRelevantAndUpdate(*VAR_49.tx)) continue;\n                        /* COMMENT_87 */\n                        VAR_42->m_recently_announced_invs.insert(VAR_25);\n                        VAR_37.push_back(VAR_50);\n                        VAR_57++;\n                        {\n                            /* COMMENT_88 */\n                            while (!VAR_62.empty() && VAR_62.front().first < VAR_6)\n                            {\n                                VAR_63.erase(VAR_62.front().second);\n                                VAR_62.pop_front();\n                            }\n\n                            auto VAR_34 = VAR_63.emplace(VAR_60, std::move(VAR_49.tx));\n                            if (VAR_34.second) {\n                                VAR_62.emplace_back(VAR_6 + VAR_64, VAR_34.first);\n                            }\n                            /* COMMENT_89 */\n                            auto VAR_65 = VAR_63.emplace(VAR_61, VAR_34.first->second);\n                            if (VAR_65.second) {\n                                VAR_62.emplace_back(VAR_6 + VAR_64, VAR_65.first);\n                            }\n                        }\n                        if (VAR_37.size() == VAR_41) {\n                            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n                            VAR_37.clear();\n                        }\n                        VAR_42->m_tx_inventory_known_filter.insert(VAR_25);\n                        if (VAR_25 != VAR_60) {\n                            /* COMMENT_90 */\n                            /* COMMENT_91 */\n                            /* COMMENT_92 */\n                            /* COMMENT_93 */\n                            /* COMMENT_94 */\n                            VAR_42->m_tx_inventory_known_filter.insert(VAR_60);\n                        }\n                    }\n                }\n        }\n        if (!VAR_37.empty())\n            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::INV, VAR_37));\n\n        /* COMMENT_95 */\n        auto VAR_66 = VAR_67.load();\n        if (VAR_10.m_stalling_since.count() && VAR_10.m_stalling_since < VAR_6 - VAR_66) {\n            /* COMMENT_96 */\n            /* COMMENT_97 */\n            /* COMMENT_98 */\n            LogPrintf(\"Peer=%d is stalling block download, disconnecting\\n\", VAR_0->GetId());\n            VAR_0->fDisconnect = true;\n            /* COMMENT_99 */\n            /* COMMENT_100 */\n            const auto VAR_68 = std::min(2 * VAR_66, VAR_69);\n            if (VAR_66 != VAR_68 && VAR_67.compare_exchange_strong(VAR_66, VAR_68)) {\n                LogPrint(BCLog::NET, \"Increased stalling timeout temporarily to %d seconds\\n\", count_seconds(VAR_68));\n            }\n            return true;\n        }\n        /* COMMENT_101 */\n        /* COMMENT_102 */\n        /* COMMENT_103 */\n        /* COMMENT_104 */\n        /* COMMENT_105 */\n        if (VAR_10.vBlocksInFlight.size() > 0) {\n            QueuedBlock &VAR_70 = VAR_10.vBlocksInFlight.front();\n            int VAR_71 = VAR_72 - 1;\n            if (VAR_6 > VAR_10.m_downloading_since + std::chrono::seconds{VAR_3.nPowTargetSpacing} * (VAR_73 + VAR_74 * VAR_71)) {\n                LogPrintf(\"Timeout downloading block %s from peer=%d, disconnecting\\n\", VAR_70.pindex->GetBlockHash().ToString(), VAR_0->GetId());\n                VAR_0->fDisconnect = true;\n                return true;\n            }\n        }\n        /* COMMENT_106 */\n        if (VAR_10.fSyncStarted && VAR_2->m_headers_sync_timeout < std::chrono::microseconds::max()) {\n            /* COMMENT_107 */\n            if (VAR_11.m_best_header->Time() <= GetAdjustedTime() - 24h) {\n                if (VAR_6 > VAR_2->m_headers_sync_timeout && VAR_15 == 1 && (VAR_13 - VAR_10.fPreferredDownload >= 1)) {\n                    /* COMMENT_108 */\n                    /* COMMENT_109 */\n                    /* COMMENT_110 */\n                    /* COMMENT_111 */\n                    /* COMMENT_112 */\n                    if (!VAR_0->HasPermission(NetPermissionFlags::NoBan)) {\n                        LogPrintf(\"Timeout downloading headers from peer=%d, disconnecting\\n\", VAR_0->GetId());\n                        VAR_0->fDisconnect = true;\n                        return true;\n                    } else {\n                        LogPrintf(\"Timeout downloading headers from noban peer=%d, not disconnecting\\n\", VAR_0->GetId());\n                        /* COMMENT_113 */\n                        /* COMMENT_114 */\n                        /* COMMENT_115 */\n                        /* COMMENT_116 */\n                        /* COMMENT_117 */\n                        VAR_10.fSyncStarted = false;\n                        VAR_15--;\n                        VAR_2->m_headers_sync_timeout = 0us;\n                    }\n                }\n            } else {\n                /* COMMENT_118 */\n                /* COMMENT_119 */\n                VAR_2->m_headers_sync_timeout = std::chrono::microseconds::max();\n            }\n        }\n\n        /* COMMENT_120 */\n        /* COMMENT_121 */\n        ConsiderEviction(*VAR_0, *VAR_2, VAR_7<std::chrono::seconds>());\n\n        /* COMMENT_28 */\n        /* COMMENT_122 */\n        /* COMMENT_28 */\n        std::vector<CInv> VAR_75;\n        if (CanServeBlocks(*VAR_2) && ((VAR_12 && !IsLimitedPeer(*VAR_2)) || !VAR_11.ActiveChainstate().IsInitialBlockDownload()) && VAR_10.nBlocksInFlight < VAR_76) {\n            std::vector<const CBlockIndex*> VAR_77;\n            NodeId VAR_78 = -1;\n            FindNextBlocksToDownload(*VAR_2, VAR_76 - VAR_10.nBlocksInFlight, VAR_77, VAR_78);\n            for (const CBlockIndex *VAR_26 : VAR_77) {\n                uint32_t VAR_79 = GetFetchFlags(*VAR_2);\n                VAR_75.push_back(CInv(VAR_40 | VAR_79, VAR_26->GetBlockHash()));\n                BlockRequested(VAR_0->GetId(), *VAR_26);\n                LogPrint(BCLog::NET, \"Requesting block %s (%d) peer=%d\\n\", VAR_26->GetBlockHash().ToString(),\n                    VAR_26->nHeight, VAR_0->GetId());\n            }\n            if (VAR_10.nBlocksInFlight == 0 && VAR_78 != -1) {\n                if (State(VAR_78)->m_stalling_since == 0us) {\n                    State(VAR_78)->m_stalling_since = VAR_6;\n                    LogPrint(BCLog::NET, \"Stall started peer=%d\\n\", VAR_78);\n                }\n            }\n        }\n\n        /* COMMENT_28 */\n        /* COMMENT_123 */\n        /* COMMENT_28 */\n        std::vector<std::pair<NodeId, GenTxid>> VAR_80;\n        auto VAR_81 = VAR_82.GetRequestable(VAR_0->GetId(), VAR_6, &VAR_80);\n        for (const auto& VAR_83 : VAR_80) {\n            LogPrint(BCLog::NET, \"timeout of inflight %s %s from peer=%d\\n\", VAR_83.second.IsWtxid() ? \"wtx\" : \"tx\",\n                VAR_83.second.GetHash().ToString(), VAR_83.first);\n        }\n        for (const GenTxid& VAR_84 : VAR_81) {\n            if (!AlreadyHaveTx(VAR_84)) {\n                LogPrint(BCLog::NET, \"Requesting %s %s peer=%d\\n\", VAR_84.IsWtxid() ? \"wtx\" : \"tx\",\n                    VAR_84.GetHash().ToString(), VAR_0->GetId());\n                VAR_75.emplace_back(VAR_84.IsWtxid() ? VAR_51 : (VAR_52 | GetFetchFlags(*VAR_2)), VAR_84.GetHash());\n                if (VAR_75.size() >= VAR_85) {\n                    VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::GETDATA, VAR_75));\n                    VAR_75.clear();\n                }\n                VAR_82.RequestedTx(VAR_0->GetId(), VAR_84.GetHash(), VAR_6 + VAR_86);\n            } else {\n                /* COMMENT_124 */\n                /* COMMENT_125 */\n                VAR_82.ForgetTxHash(VAR_84.GetHash());\n            }\n        }\n\n\n        if (!VAR_75.empty())\n            VAR_32.PushMessage(VAR_0, VAR_5.Make(NetMsgType::GETDATA, VAR_75));\n    } /* COMMENT_126 */\n    MaybeSendFeefilter(*VAR_0, *VAR_2, VAR_6);\n    return true;\n}",
  "func_graph_path": "bitcoin/5b3406094f2679dfb3763de4414257268565b943/net_processing.cpp/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -312,7 +312,9 @@\n                     // especially since we have many peers and some will draw much shorter delays.\n                     unsigned int nRelayedTransactions = 0;\n                     LOCK(tx_relay->m_bloom_filter_mutex);\n-                    while (!vInvTx.empty() && nRelayedTransactions < INVENTORY_BROADCAST_MAX) {\n+                    size_t broadcast_max{INVENTORY_BROADCAST_MAX + (tx_relay->m_tx_inventory_to_send.size()/1000)*5};\n+                    broadcast_max = std::min<size_t>(1000, broadcast_max);\n+                    while (!vInvTx.empty() && nRelayedTransactions < broadcast_max) {\n                         // Fetch the top element from the heap\n                         std::pop_heap(vInvTx.begin(), vInvTx.end(), compareInvMempoolOrder);\n                         std::set<uint256>::iterator it = vInvTx.back();",
  "diff_line_info": {
    "deleted_lines": [
      "                    while (!vInvTx.empty() && nRelayedTransactions < INVENTORY_BROADCAST_MAX) {"
    ],
    "added_lines": [
      "                    size_t broadcast_max{INVENTORY_BROADCAST_MAX + (tx_relay->m_tx_inventory_to_send.size()/1000)*5};",
      "                    broadcast_max = std::min<size_t>(1000, broadcast_max);",
      "                    while (!vInvTx.empty() && nRelayedTransactions < broadcast_max) {"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/bitcoin/bitcoin/pull/27610",
  "description": {
    "pr_info": {
      "title": "Improve performance of p2p inv to send queues",
      "number": 27610
    },
    "comment": [
      "Couple of performance improvements when draining the inventory-to-send queue:\r\n\r\n * drop txs that have already been evicted from the mempool (or included in a block) immediately, rather than at the end of processing\r\n * marginally increase outgoing trickle rate during spikes in tx volume",
      "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--021abf342d371248e50ceaed478a90ca-->\n### Reviews\nSee [the guideline](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#code-review) for information on the review process.\n| Type | Reviewers |\n| ---- | --------- |\n| ACK | [darosior](https://github.com/bitcoin/bitcoin/pull/27610#pullrequestreview-1419935557), [willcl-ark](https://github.com/bitcoin/bitcoin/pull/27610#issuecomment-1542181711), [instagibbs](https://github.com/bitcoin/bitcoin/pull/27610#issuecomment-1542201540), [glozow](https://github.com/bitcoin/bitcoin/pull/27610#pullrequestreview-1422536495), [dergoegge](https://github.com/bitcoin/bitcoin/pull/27610#pullrequestreview-1422347722) |\n| Concept ACK | [0xB10C](https://github.com/bitcoin/bitcoin/pull/27610#issuecomment-1542178451), [pinheadmz](https://github.com/bitcoin/bitcoin/pull/27610#pullrequestreview-1420860416) |\n\nIf your review is incorrectly listed, please react with  to this comment and the bot will ignore it on the next update.\n",
      "Concept ACK",
      "ACK 5b34060\r\n\r\nCurrently running this cherry-picked on top of v24.0.1 on mainnet and seeing reduced resource usage.",
      "ACK https://github.com/bitcoin/bitcoin/pull/27610/commits/5b3406094f2679dfb3763de4414257268565b943\r\n\r\nSignificant reduction in CPU usage when influx of transactions is high and sustained. Allows an additional INV to trickle per additional 200 INV backlog, capped at 1k.",
      "Compared where the time is spent in the `b-msghand` thread on a mainnet `master` and a mainnet 5b3406094f2679dfb3763de4414257268565b943 node that were both running for a while. Followed [eklitzke's flamegraph.md](https://github.com/eklitzke/bitcoin/blob/flamegraphs/doc/flamegraphs.md#generating-a-profile) to create the flamegraphs below. This seems to be indeed a nice performance improvement. The second flamegraph looks _healthier_. \r\n\r\n`master`:\r\n\r\n![flamegraph-master](https://github.com/bitcoin/bitcoin/assets/19157360/7e31c262-648f-4168-9a9a-5cc93b4a9da0)\r\n\r\n\r\n5b3406094f2679dfb3763de4414257268565b943:\r\n\r\n![flamegraph-202305-invtosend](https://github.com/bitcoin/bitcoin/assets/19157360/36f2ee57-b017-4ffe-8099-970b20998d0a)\r\n",
      "Partial utACK, for 228e9201efb5574b1b96bb924de1d2e8dd1317f3 (i.e. the changes in `CompareDepthAndScore`). Took me a while to wrap my head around it.",
      "<img width=\"1552\" alt=\"Screen Shot 2023-05-17 at 10 06 51 AM\" src=\"https://github.com/bitcoin/bitcoin/assets/2084648/43139c94-d32d-4469-952b-25980242e1f6\">\r\n\r\n\r\n\r\nI've been running this branch for 7 days on a VPS and noticed this morning the CPU on b-msghand is back up to 100%. It was about that high running v24 release but dropped to 30% or so when I first switched to this branch and restarted.",
      "@pinheadmz I am also still running this patch, but I still see pretty stable utilisation in the range of ~2-12%, currently with 88 inbound peers.\r\n\r\n![image](https://github.com/bitcoin/bitcoin/assets/6606587/a7e61cef-4a31-4404-b9e2-80348d59bc0c)\r\n",
      "> I've been running this branch for 7 days on a VPS and noticed this morning the CPU on b-msghand is back up to 100%. It was about that high running v24 release but dropped to 30% or so when I first switched to this branch and restarted.\r\n\r\n@pinheadmz I've been running the patch on multiple nodes for a week now and haven't seen 100% CPU usage in the b-msghand thread again. If you haven't restarted or if it happens again, it would be helpful to see which functions are slow. `perf top -p $(pidof bitcoind)` should do the trick.\r\n",
      "Could also make sense to double check the debug.log to ensure you restarted `bitcoind` after compiling? :sweat_smile: ",
      "> Could also make sense to double check the debug.log to ensure you restarted `bitcoind` after compiling? \r\n\r\nPhew! That would've been embarassing\r\n\r\n```\r\n2023-05-10T15:39:40Z Bitcoin Core version v25.99.0-5b3406094f26 (debug build)\r\n```\r\n\r\n\r\n\r\n>  `perf top -p $(pidof bitcoind)` should do the trick.\r\n\r\nNot familiar with this tool but it looks cool! This is at the top. Every other line in the output is < 0.10%\r\n\r\n```\r\n  99.56%  bitcoind             [.] boost::multi_index::detail::safe_iterator_base::detach\r\n```\r\n\r\n\r\n",
      ">(debug build)\r\n\r\nSee https://github.com/bitcoin/bitcoin/issues/27700#issuecomment-1553401313 ?",
      "ah thanks I forgot I configured that way, will follow the other threads"
    ]
  },
  "Bug Filter": "Defect Remediation & Feature Upgrades",
  "Bug Filter Confidence": 0.9,
  "Bug Filter Response": "**Final Classification:** Defect Remediation & Feature Upgrades  \n**Confidence:** 0.9  \n\nThe patch addresses performance issues related to transaction processing and inventory queue management, aligning with defect remediation rather than security fixes."
}