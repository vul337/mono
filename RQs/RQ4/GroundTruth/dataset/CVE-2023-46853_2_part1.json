{
  "cve_id": "CVE-2023-46853",
  "cwe_ids": [
    "CWE-193"
  ],
  "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
  "cvss_is_v3": true,
  "repo_name": "memcached",
  "commit_msg": "proxy: fix off-by-one if \\r is missing\n\nA bunch of the parser assumed we only had \\r\\n, but I didn't actually\nhave that strictness set. Some commands worked and some broke in subtle\nways when just \"\\n\" was being submitted.\n\nI'm not 100% confident in this change yet so I'm opening a PR to stage\nit while I run some more thorough tests.",
  "commit_hash": "6987918e9a3094ec4fc8976f01f769f624d790fa",
  "git_url": "https://github.com/memcached/memcached/commit/6987918e9a3094ec4fc8976f01f769f624d790fa",
  "file_path": "proxy_request.c",
  "func_name": "_process_tokenize",
  "func_before": "static int _process_tokenize(mcp_parser_t *pr, const size_t max) {\n    const char *s = pr->request;\n    int len = pr->reqlen - 2;\n\n    // since multigets can be huge, we can't purely judge reqlen against this\n    // limit, but we also can't index past it since the tokens are shorts.\n    if (len > PARSER_MAXLEN) {\n        len = PARSER_MAXLEN;\n    }\n    const char *end = s + len;\n    int curtoken = 0;\n\n    int state = 0;\n    while (s != end) {\n        switch (state) {\n            case 0:\n                // scanning for first non-space to find a token.\n                if (*s != ' ') {\n                    pr->tokens[curtoken] = s - pr->request;\n                    if (++curtoken == max) {\n                        s++;\n                        state = 2;\n                        break;\n                    }\n                    state = 1;\n                }\n                s++;\n                break;\n            case 1:\n                // advance over a token\n                if (*s != ' ') {\n                    s++;\n                } else {\n                    state = 0;\n                }\n                break;\n            case 2:\n                // hit max tokens before end of the line.\n                // keep advancing so we can place endcap token.\n                if (*s == ' ') {\n                    goto endloop;\n                }\n                s++;\n                break;\n        }\n    }\nendloop:\n\n    // endcap token so we can quickly find the length of any token by looking\n    // at the next one.\n    pr->tokens[curtoken] = s - pr->request;\n    pr->ntokens = curtoken;\n    P_DEBUG(\"%s: cur_tokens: %d\\n\", __func__, curtoken);\n\n    return 0;\n}",
  "abstract_func_before": "static int _process_tokenize(mcp_parser_t *VAR_0, const size_t VAR_1) {\n    const char *VAR_2 = VAR_0->request;\n    int VAR_3 = VAR_0->reqlen - 2;\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    if (VAR_3 > VAR_4) {\n        VAR_3 = VAR_4;\n    }\n    const char *VAR_5 = VAR_2 + VAR_3;\n    int VAR_6 = 0;\n\n    int VAR_7 = 0;\n    while (VAR_2 != VAR_5) {\n        switch (VAR_7) {\n            case 0:\n                /* COMMENT_2 */\n                if (*VAR_2 != ' ') {\n                    VAR_0->tokens[VAR_6] = VAR_2 - VAR_0->request;\n                    if (++VAR_6 == VAR_1) {\n                        VAR_2++;\n                        VAR_7 = 2;\n                        break;\n                    }\n                    VAR_7 = 1;\n                }\n                VAR_2++;\n                break;\n            case 1:\n                /* COMMENT_3 */\n                if (*VAR_2 != ' ') {\n                    VAR_2++;\n                } else {\n                    VAR_7 = 0;\n                }\n                break;\n            case 2:\n                /* COMMENT_4 */\n                /* COMMENT_5 */\n                if (*VAR_2 == ' ') {\n                    goto endloop;\n                }\n                VAR_2++;\n                break;\n        }\n    }\nendloop:\n\n    /* COMMENT_6 */\n    /* COMMENT_7 */\n    VAR_0->tokens[VAR_6] = VAR_2 - VAR_0->request;\n    VAR_0->ntokens = VAR_6;\n    P_DEBUG(\"%s: cur_tokens: %d\\n\", VAR_8, VAR_6);\n\n    return 0;\n}",
  "func_graph_path_before": "memcached/6987918e9a3094ec4fc8976f01f769f624d790fa/proxy_request.c/vul/before/3.json",
  "func": "static int _process_tokenize(mcp_parser_t *pr, const size_t max) {\n    const char *s = pr->request;\n    int len = pr->endlen;\n\n    // since multigets can be huge, we can't purely judge reqlen against this\n    // limit, but we also can't index past it since the tokens are shorts.\n    if (len > PARSER_MAXLEN) {\n        len = PARSER_MAXLEN;\n    }\n    const char *end = s + len;\n    int curtoken = 0;\n\n    int state = 0;\n    while (s != end) {\n        switch (state) {\n            case 0:\n                // scanning for first non-space to find a token.\n                if (*s != ' ') {\n                    pr->tokens[curtoken] = s - pr->request;\n                    if (++curtoken == max) {\n                        s++;\n                        state = 2;\n                        break;\n                    }\n                    state = 1;\n                }\n                s++;\n                break;\n            case 1:\n                // advance over a token\n                if (*s != ' ') {\n                    s++;\n                } else {\n                    state = 0;\n                }\n                break;\n            case 2:\n                // hit max tokens before end of the line.\n                // keep advancing so we can place endcap token.\n                if (*s == ' ') {\n                    goto endloop;\n                }\n                s++;\n                break;\n        }\n    }\nendloop:\n\n    // endcap token so we can quickly find the length of any token by looking\n    // at the next one.\n    pr->tokens[curtoken] = s - pr->request;\n    pr->ntokens = curtoken;\n    P_DEBUG(\"%s: cur_tokens: %d\\n\", __func__, curtoken);\n\n    return 0;\n}",
  "abstract_func": "static int _process_tokenize(mcp_parser_t *VAR_0, const size_t VAR_1) {\n    const char *VAR_2 = VAR_0->request;\n    int VAR_3 = VAR_0->endlen;\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    if (VAR_3 > VAR_4) {\n        VAR_3 = VAR_4;\n    }\n    const char *VAR_5 = VAR_2 + VAR_3;\n    int VAR_6 = 0;\n\n    int VAR_7 = 0;\n    while (VAR_2 != VAR_5) {\n        switch (VAR_7) {\n            case 0:\n                /* COMMENT_2 */\n                if (*VAR_2 != ' ') {\n                    VAR_0->tokens[VAR_6] = VAR_2 - VAR_0->request;\n                    if (++VAR_6 == VAR_1) {\n                        VAR_2++;\n                        VAR_7 = 2;\n                        break;\n                    }\n                    VAR_7 = 1;\n                }\n                VAR_2++;\n                break;\n            case 1:\n                /* COMMENT_3 */\n                if (*VAR_2 != ' ') {\n                    VAR_2++;\n                } else {\n                    VAR_7 = 0;\n                }\n                break;\n            case 2:\n                /* COMMENT_4 */\n                /* COMMENT_5 */\n                if (*VAR_2 == ' ') {\n                    goto endloop;\n                }\n                VAR_2++;\n                break;\n        }\n    }\nendloop:\n\n    /* COMMENT_6 */\n    /* COMMENT_7 */\n    VAR_0->tokens[VAR_6] = VAR_2 - VAR_0->request;\n    VAR_0->ntokens = VAR_6;\n    P_DEBUG(\"%s: cur_tokens: %d\\n\", VAR_8, VAR_6);\n\n    return 0;\n}",
  "func_graph_path": "memcached/6987918e9a3094ec4fc8976f01f769f624d790fa/proxy_request.c/vul/after/3.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static int _process_tokenize(mcp_parser_t *pr, const size_t max) {\n     const char *s = pr->request;\n-    int len = pr->reqlen - 2;\n+    int len = pr->endlen;\n \n     // since multigets can be huge, we can't purely judge reqlen against this\n     // limit, but we also can't index past it since the tokens are shorts.",
  "diff_line_info": {
    "deleted_lines": [
      "    int len = pr->reqlen - 2;"
    ],
    "added_lines": [
      "    int len = pr->endlen;"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/memcached/memcached/pull/1063",
  "description": "Failed to get PR details: HTTP Request Error for PR https://github.com/memcached/memcached/pull/1063: 403 Client Error: Forbidden for url: https://api.github.com/repos/memcached/memcached/pulls/1063",
  "Bug Filter": "Defect Remediation & Feature Upgrades",
  "Bug Filter Confidence": 0.9,
  "Bug Filter Response": "**Final Classification:** Defect Remediation & Feature Upgrades; **Confidence:** 0.9"
}