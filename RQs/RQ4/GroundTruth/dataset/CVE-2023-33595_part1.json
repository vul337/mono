{
  "cve_id": "CVE-2023-33595",
  "cwe_ids": [
    "CWE-416"
  ],
  "cvss_vector": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H",
  "cvss_is_v3": true,
  "repo_name": "python/cpython",
  "commit_msg": "Fix use-after-free in tokenizer.c\n\n`tok_get_fstring_mode`: ensure that token in the f-string middle is properly decoded, i.e. `tok_nextc` doesn't return EOF with `tok->decoding_erred` set to 1",
  "commit_hash": "c120bc2d354ca3d27d0c7a53bf65574ddaabaf3a",
  "git_url": "https://github.com/python/cpython/commit/c120bc2d354ca3d27d0c7a53bf65574ddaabaf3a",
  "file_path": "Parser/tokenizer.c",
  "func_name": "tok_get_fstring_mode",
  "func_before": "static int\ntok_get_fstring_mode(struct tok_state *tok, tokenizer_mode* current_tok, struct token *token)\n{\n    const char *p_start = NULL;\n    const char *p_end = NULL;\n    int end_quote_size = 0;\n    int unicode_escape = 0;\n\n    tok->start = tok->cur;\n    tok->first_lineno = tok->lineno;\n    tok->starting_col_offset = tok->col_offset;\n\n    // If we start with a bracket, we defer to the normal mode as there is nothing for us to tokenize\n    // before it.\n    int start_char = tok_nextc(tok);\n    if (start_char == '{') {\n        int peek1 = tok_nextc(tok);\n        tok_backup(tok, peek1);\n        tok_backup(tok, start_char);\n        if (peek1 != '{') {\n            current_tok->curly_bracket_expr_start_depth++;\n            if (current_tok->curly_bracket_expr_start_depth >= MAX_EXPR_NESTING) {\n                return MAKE_TOKEN(syntaxerror(tok, \"f-string: expressions nested too deeply\"));\n            }\n            TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;\n            return tok_get_normal_mode(tok, current_tok, token);\n        }\n    }\n    else {\n        tok_backup(tok, start_char);\n    }\n\n    // Check if we are at the end of the string\n    for (int i = 0; i < current_tok->f_string_quote_size; i++) {\n        int quote = tok_nextc(tok);\n        if (quote != current_tok->f_string_quote) {\n            tok_backup(tok, quote);\n            goto f_string_middle;\n        }\n    }\n\n    if (current_tok->last_expr_buffer != NULL) {\n        PyMem_Free(current_tok->last_expr_buffer);\n        current_tok->last_expr_buffer = NULL;\n        current_tok->last_expr_size = 0;\n        current_tok->last_expr_end = -1;\n    }\n\n    p_start = tok->start;\n    p_end = tok->cur;\n    tok->tok_mode_stack_index--;\n    return MAKE_TOKEN(FSTRING_END);\n\nf_string_middle:\n\n    while (end_quote_size != current_tok->f_string_quote_size) {\n        int c = tok_nextc(tok);\n        if (c == EOF || (current_tok->f_string_quote_size == 1 && c == '\\n')) {\n            assert(tok->multi_line_start != NULL);\n            // shift the tok_state's location into\n            // the start of string, and report the error\n            // from the initial quote character\n            tok->cur = (char *)current_tok->f_string_start;\n            tok->cur++;\n            tok->line_start = current_tok->f_string_multi_line_start;\n            int start = tok->lineno;\n            tok->lineno = tok->first_lineno;\n\n            if (current_tok->f_string_quote_size == 3) {\n                return MAKE_TOKEN(syntaxerror(tok,\n                                    \"unterminated triple-quoted f-string literal\"\n                                    \" (detected at line %d)\", start));\n            }\n            else {\n                return MAKE_TOKEN(syntaxerror(tok,\n                                    \"unterminated f-string literal (detected at\"\n                                    \" line %d)\", start));\n            }\n        }\n\n        if (c == current_tok->f_string_quote) {\n            end_quote_size += 1;\n            continue;\n        } else {\n            end_quote_size = 0;\n        }\n\n        int in_format_spec = (\n                current_tok->last_expr_end != -1\n                &&\n                INSIDE_FSTRING_EXPR(current_tok)\n        );\n        if (c == '{') {\n            int peek = tok_nextc(tok);\n            if (peek != '{' || in_format_spec) {\n                tok_backup(tok, peek);\n                tok_backup(tok, c);\n                current_tok->curly_bracket_expr_start_depth++;\n                if (current_tok->curly_bracket_expr_start_depth >= MAX_EXPR_NESTING) {\n                    return MAKE_TOKEN(syntaxerror(tok, \"f-string: expressions nested too deeply\"));\n                }\n                TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;\n                p_start = tok->start;\n                p_end = tok->cur;\n            } else {\n                p_start = tok->start;\n                p_end = tok->cur - 1;\n            }\n            return MAKE_TOKEN(FSTRING_MIDDLE);\n        } else if (c == '}') {\n            if (unicode_escape) {\n                p_start = tok->start;\n                p_end = tok->cur;\n                return MAKE_TOKEN(FSTRING_MIDDLE);\n            }\n            int peek = tok_nextc(tok);\n\n            // The tokenizer can only be in the format spec if we have already completed the expression\n            // scanning (indicated by the end of the expression being set) and we are not at the top level\n            // of the bracket stack (-1 is the top level). Since format specifiers can't legally use double\n            // brackets, we can bypass it here.\n            if (peek == '}' && !in_format_spec) {\n                p_start = tok->start;\n                p_end = tok->cur - 1;\n            } else {\n                tok_backup(tok, peek);\n                tok_backup(tok, c);\n                TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;\n                p_start = tok->start;\n                p_end = tok->cur;\n            }\n            return MAKE_TOKEN(FSTRING_MIDDLE);\n        } else if (c == '\\\\') {\n            int peek = tok_nextc(tok);\n            // Special case when the backslash is right before a curly\n            // brace. We have to restore and return the control back\n            // to the loop for the next iteration.\n            if (peek == '{' || peek == '}') {\n                if (!current_tok->f_string_raw) {\n                    if (warn_invalid_escape_sequence(tok, peek)) {\n                        return MAKE_TOKEN(ERRORTOKEN);\n                    }\n                }\n                tok_backup(tok, peek);\n                continue;\n            }\n\n            if (!current_tok->f_string_raw) {\n                if (peek == 'N') {\n                    /* Handle named unicode escapes (\\N{BULLET}) */\n                    peek = tok_nextc(tok);\n                    if (peek == '{') {\n                        unicode_escape = 1;\n                    } else {\n                        tok_backup(tok, peek);\n                    }\n                }\n            } /* else {\n                skip the escaped character\n            }*/\n        }\n    }\n\n    // Backup the f-string quotes to emit a final FSTRING_MIDDLE and\n    // add the quotes to the FSTRING_END in the next tokenizer iteration.\n    for (int i = 0; i < current_tok->f_string_quote_size; i++) {\n        tok_backup(tok, current_tok->f_string_quote);\n    }\n    p_start = tok->start;\n    p_end = tok->cur;\n    return MAKE_TOKEN(FSTRING_MIDDLE);\n}",
  "abstract_func_before": "static int\ntok_get_fstring_mode(struct tok_state *VAR_0, tokenizer_mode* VAR_1, struct token *token)\n{\n    const char *VAR_2 = NULL;\n    const char *VAR_3 = NULL;\n    int VAR_4 = 0;\n    int VAR_5 = 0;\n\n    VAR_0->start = VAR_0->cur;\n    VAR_0->first_lineno = VAR_0->lineno;\n    VAR_0->starting_col_offset = VAR_0->col_offset;\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    int VAR_6 = tok_nextc(VAR_0);\n    if (VAR_6 == '{') {\n        int VAR_7 = tok_nextc(VAR_0);\n        tok_backup(VAR_0, VAR_7);\n        tok_backup(VAR_0, VAR_6);\n        if (VAR_7 != '{') {\n            VAR_1->curly_bracket_expr_start_depth++;\n            if (VAR_1->curly_bracket_expr_start_depth >= VAR_8) {\n                return MAKE_TOKEN(syntaxerror(VAR_0, \"f-string: expressions nested too deeply\"));\n            }\n            TOK_GET_MODE(VAR_0)->kind = VAR_9;\n            return tok_get_normal_mode(VAR_0, VAR_1, token);\n        }\n    }\n    else {\n        tok_backup(VAR_0, VAR_6);\n    }\n\n    /* COMMENT_2 */\n    for (int VAR_10 = 0; VAR_10 < VAR_1->f_string_quote_size; VAR_10++) {\n        int VAR_11 = tok_nextc(VAR_0);\n        if (VAR_11 != VAR_1->f_string_quote) {\n            tok_backup(VAR_0, VAR_11);\n            goto f_string_middle;\n        }\n    }\n\n    if (VAR_1->last_expr_buffer != NULL) {\n        PyMem_Free(VAR_1->last_expr_buffer);\n        VAR_1->last_expr_buffer = NULL;\n        VAR_1->last_expr_size = 0;\n        VAR_1->last_expr_end = -1;\n    }\n\n    VAR_2 = VAR_0->start;\n    VAR_3 = VAR_0->cur;\n    VAR_0->tok_mode_stack_index--;\n    return MAKE_TOKEN(VAR_12);\n\nf_string_middle:\n\n    while (VAR_4 != VAR_1->f_string_quote_size) {\n        int VAR_13 = tok_nextc(VAR_0);\n        if (VAR_13 == VAR_14 || (VAR_1->f_string_quote_size == 1 && VAR_13 == '\\n')) {\n            assert(VAR_0->multi_line_start != NULL);\n            /* COMMENT_3 */\n            /* COMMENT_4 */\n            /* COMMENT_5 */\n            VAR_0->cur = (char *)VAR_1->f_string_start;\n            VAR_0->cur++;\n            VAR_0->line_start = VAR_1->f_string_multi_line_start;\n            int VAR_15 = VAR_0->lineno;\n            VAR_0->lineno = VAR_0->first_lineno;\n\n            if (VAR_1->f_string_quote_size == 3) {\n                return MAKE_TOKEN(syntaxerror(VAR_0,\n                                    \"unterminated triple-quoted f-string literal\"\n                                    \" (detected at line %d)\", VAR_15));\n            }\n            else {\n                return MAKE_TOKEN(syntaxerror(VAR_0,\n                                    \"unterminated f-string literal (detected at\"\n                                    \" line %d)\", VAR_15));\n            }\n        }\n\n        if (VAR_13 == VAR_1->f_string_quote) {\n            VAR_4 += 1;\n            continue;\n        } else {\n            VAR_4 = 0;\n        }\n\n        int VAR_16 = (\n                VAR_1->last_expr_end != -1\n                &&\n                INSIDE_FSTRING_EXPR(VAR_1)\n        );\n        if (VAR_13 == '{') {\n            int VAR_17 = tok_nextc(VAR_0);\n            if (VAR_17 != '{' || VAR_16) {\n                tok_backup(VAR_0, VAR_17);\n                tok_backup(VAR_0, VAR_13);\n                VAR_1->curly_bracket_expr_start_depth++;\n                if (VAR_1->curly_bracket_expr_start_depth >= VAR_8) {\n                    return MAKE_TOKEN(syntaxerror(VAR_0, \"f-string: expressions nested too deeply\"));\n                }\n                TOK_GET_MODE(VAR_0)->kind = VAR_9;\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur;\n            } else {\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur - 1;\n            }\n            return MAKE_TOKEN(VAR_18);\n        } else if (VAR_13 == '}') {\n            if (VAR_5) {\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur;\n                return MAKE_TOKEN(VAR_18);\n            }\n            int VAR_17 = tok_nextc(VAR_0);\n\n            /* COMMENT_6 */\n            /* COMMENT_7 */\n            /* COMMENT_8 */\n            /* COMMENT_9 */\n            if (VAR_17 == '}' && !VAR_16) {\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur - 1;\n            } else {\n                tok_backup(VAR_0, VAR_17);\n                tok_backup(VAR_0, VAR_13);\n                TOK_GET_MODE(VAR_0)->kind = VAR_9;\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur;\n            }\n            return MAKE_TOKEN(VAR_18);\n        } else if (VAR_13 == '\\\\') {\n            int VAR_17 = tok_nextc(VAR_0);\n            /* COMMENT_10 */\n            /* COMMENT_11 */\n            /* COMMENT_12 */\n            if (VAR_17 == '{' || VAR_17 == '}') {\n                if (!VAR_1->f_string_raw) {\n                    if (warn_invalid_escape_sequence(VAR_0, VAR_17)) {\n                        return MAKE_TOKEN(VAR_19);\n                    }\n                }\n                tok_backup(VAR_0, VAR_17);\n                continue;\n            }\n\n            if (!VAR_1->f_string_raw) {\n                if (VAR_17 == 'N') {\n                    /* COMMENT_13 */\n                    VAR_17 = tok_nextc(VAR_0);\n                    if (VAR_17 == '{') {\n                        VAR_5 = 1;\n                    } else {\n                        tok_backup(VAR_0, VAR_17);\n                    }\n                }\n            } /* COMMENT_14 */\n                                          \n               \n        }\n    }\n\n    /* COMMENT_17 */\n    /* COMMENT_18 */\n    for (int VAR_10 = 0; VAR_10 < VAR_1->f_string_quote_size; VAR_10++) {\n        tok_backup(VAR_0, VAR_1->f_string_quote);\n    }\n    VAR_2 = VAR_0->start;\n    VAR_3 = VAR_0->cur;\n    return MAKE_TOKEN(VAR_18);\n}",
  "func_graph_path_before": "python/cpython/c120bc2d354ca3d27d0c7a53bf65574ddaabaf3a/tokenizer.c/vul/before/0.json",
  "func": "static int\ntok_get_fstring_mode(struct tok_state *tok, tokenizer_mode* current_tok, struct token *token)\n{\n    const char *p_start = NULL;\n    const char *p_end = NULL;\n    int end_quote_size = 0;\n    int unicode_escape = 0;\n\n    tok->start = tok->cur;\n    tok->first_lineno = tok->lineno;\n    tok->starting_col_offset = tok->col_offset;\n\n    // If we start with a bracket, we defer to the normal mode as there is nothing for us to tokenize\n    // before it.\n    int start_char = tok_nextc(tok);\n    if (start_char == '{') {\n        int peek1 = tok_nextc(tok);\n        tok_backup(tok, peek1);\n        tok_backup(tok, start_char);\n        if (peek1 != '{') {\n            current_tok->curly_bracket_expr_start_depth++;\n            if (current_tok->curly_bracket_expr_start_depth >= MAX_EXPR_NESTING) {\n                return MAKE_TOKEN(syntaxerror(tok, \"f-string: expressions nested too deeply\"));\n            }\n            TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;\n            return tok_get_normal_mode(tok, current_tok, token);\n        }\n    }\n    else {\n        tok_backup(tok, start_char);\n    }\n\n    // Check if we are at the end of the string\n    for (int i = 0; i < current_tok->f_string_quote_size; i++) {\n        int quote = tok_nextc(tok);\n        if (quote != current_tok->f_string_quote) {\n            tok_backup(tok, quote);\n            goto f_string_middle;\n        }\n    }\n\n    if (current_tok->last_expr_buffer != NULL) {\n        PyMem_Free(current_tok->last_expr_buffer);\n        current_tok->last_expr_buffer = NULL;\n        current_tok->last_expr_size = 0;\n        current_tok->last_expr_end = -1;\n    }\n\n    p_start = tok->start;\n    p_end = tok->cur;\n    tok->tok_mode_stack_index--;\n    return MAKE_TOKEN(FSTRING_END);\n\nf_string_middle:\n\n    while (end_quote_size != current_tok->f_string_quote_size) {\n        int c = tok_nextc(tok);\n        if (c == EOF || (current_tok->f_string_quote_size == 1 && c == '\\n')) {\n            if (tok->decoding_erred)\n                return MAKE_TOKEN(ERRORTOKEN);\n\n            assert(tok->multi_line_start != NULL);\n            // shift the tok_state's location into\n            // the start of string, and report the error\n            // from the initial quote character\n            tok->cur = (char *)current_tok->f_string_start;\n            tok->cur++;\n            tok->line_start = current_tok->f_string_multi_line_start;\n            int start = tok->lineno;\n            tok->lineno = tok->first_lineno;\n\n            if (current_tok->f_string_quote_size == 3) {\n                return MAKE_TOKEN(syntaxerror(tok,\n                                    \"unterminated triple-quoted f-string literal\"\n                                    \" (detected at line %d)\", start));\n            }\n            else {\n                return MAKE_TOKEN(syntaxerror(tok,\n                                    \"unterminated f-string literal (detected at\"\n                                    \" line %d)\", start));\n            }\n        }\n\n        if (c == current_tok->f_string_quote) {\n            end_quote_size += 1;\n            continue;\n        } else {\n            end_quote_size = 0;\n        }\n\n        int in_format_spec = (\n                current_tok->last_expr_end != -1\n                &&\n                INSIDE_FSTRING_EXPR(current_tok)\n        );\n        if (c == '{') {\n            int peek = tok_nextc(tok);\n            if (peek != '{' || in_format_spec) {\n                tok_backup(tok, peek);\n                tok_backup(tok, c);\n                current_tok->curly_bracket_expr_start_depth++;\n                if (current_tok->curly_bracket_expr_start_depth >= MAX_EXPR_NESTING) {\n                    return MAKE_TOKEN(syntaxerror(tok, \"f-string: expressions nested too deeply\"));\n                }\n                TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;\n                p_start = tok->start;\n                p_end = tok->cur;\n            } else {\n                p_start = tok->start;\n                p_end = tok->cur - 1;\n            }\n            return MAKE_TOKEN(FSTRING_MIDDLE);\n        } else if (c == '}') {\n            if (unicode_escape) {\n                p_start = tok->start;\n                p_end = tok->cur;\n                return MAKE_TOKEN(FSTRING_MIDDLE);\n            }\n            int peek = tok_nextc(tok);\n\n            // The tokenizer can only be in the format spec if we have already completed the expression\n            // scanning (indicated by the end of the expression being set) and we are not at the top level\n            // of the bracket stack (-1 is the top level). Since format specifiers can't legally use double\n            // brackets, we can bypass it here.\n            if (peek == '}' && !in_format_spec) {\n                p_start = tok->start;\n                p_end = tok->cur - 1;\n            } else {\n                tok_backup(tok, peek);\n                tok_backup(tok, c);\n                TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;\n                p_start = tok->start;\n                p_end = tok->cur;\n            }\n            return MAKE_TOKEN(FSTRING_MIDDLE);\n        } else if (c == '\\\\') {\n            int peek = tok_nextc(tok);\n            // Special case when the backslash is right before a curly\n            // brace. We have to restore and return the control back\n            // to the loop for the next iteration.\n            if (peek == '{' || peek == '}') {\n                if (!current_tok->f_string_raw) {\n                    if (warn_invalid_escape_sequence(tok, peek)) {\n                        return MAKE_TOKEN(ERRORTOKEN);\n                    }\n                }\n                tok_backup(tok, peek);\n                continue;\n            }\n\n            if (!current_tok->f_string_raw) {\n                if (peek == 'N') {\n                    /* Handle named unicode escapes (\\N{BULLET}) */\n                    peek = tok_nextc(tok);\n                    if (peek == '{') {\n                        unicode_escape = 1;\n                    } else {\n                        tok_backup(tok, peek);\n                    }\n                }\n            } /* else {\n                skip the escaped character\n            }*/\n        }\n    }\n\n    // Backup the f-string quotes to emit a final FSTRING_MIDDLE and\n    // add the quotes to the FSTRING_END in the next tokenizer iteration.\n    for (int i = 0; i < current_tok->f_string_quote_size; i++) {\n        tok_backup(tok, current_tok->f_string_quote);\n    }\n    p_start = tok->start;\n    p_end = tok->cur;\n    return MAKE_TOKEN(FSTRING_MIDDLE);\n}",
  "abstract_func": "static int\ntok_get_fstring_mode(struct tok_state *VAR_0, tokenizer_mode* VAR_1, struct token *token)\n{\n    const char *VAR_2 = NULL;\n    const char *VAR_3 = NULL;\n    int VAR_4 = 0;\n    int VAR_5 = 0;\n\n    VAR_0->start = VAR_0->cur;\n    VAR_0->first_lineno = VAR_0->lineno;\n    VAR_0->starting_col_offset = VAR_0->col_offset;\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    int VAR_6 = tok_nextc(VAR_0);\n    if (VAR_6 == '{') {\n        int VAR_7 = tok_nextc(VAR_0);\n        tok_backup(VAR_0, VAR_7);\n        tok_backup(VAR_0, VAR_6);\n        if (VAR_7 != '{') {\n            VAR_1->curly_bracket_expr_start_depth++;\n            if (VAR_1->curly_bracket_expr_start_depth >= VAR_8) {\n                return MAKE_TOKEN(syntaxerror(VAR_0, \"f-string: expressions nested too deeply\"));\n            }\n            TOK_GET_MODE(VAR_0)->kind = VAR_9;\n            return tok_get_normal_mode(VAR_0, VAR_1, token);\n        }\n    }\n    else {\n        tok_backup(VAR_0, VAR_6);\n    }\n\n    /* COMMENT_2 */\n    for (int VAR_10 = 0; VAR_10 < VAR_1->f_string_quote_size; VAR_10++) {\n        int VAR_11 = tok_nextc(VAR_0);\n        if (VAR_11 != VAR_1->f_string_quote) {\n            tok_backup(VAR_0, VAR_11);\n            goto f_string_middle;\n        }\n    }\n\n    if (VAR_1->last_expr_buffer != NULL) {\n        PyMem_Free(VAR_1->last_expr_buffer);\n        VAR_1->last_expr_buffer = NULL;\n        VAR_1->last_expr_size = 0;\n        VAR_1->last_expr_end = -1;\n    }\n\n    VAR_2 = VAR_0->start;\n    VAR_3 = VAR_0->cur;\n    VAR_0->tok_mode_stack_index--;\n    return MAKE_TOKEN(VAR_12);\n\nf_string_middle:\n\n    while (VAR_4 != VAR_1->f_string_quote_size) {\n        int VAR_13 = tok_nextc(VAR_0);\n        if (VAR_13 == VAR_14 || (VAR_1->f_string_quote_size == 1 && VAR_13 == '\\n')) {\n            if (VAR_0->decoding_erred)\n                return MAKE_TOKEN(VAR_15);\n\n            assert(VAR_0->multi_line_start != NULL);\n            /* COMMENT_3 */\n            /* COMMENT_4 */\n            /* COMMENT_5 */\n            VAR_0->cur = (char *)VAR_1->f_string_start;\n            VAR_0->cur++;\n            VAR_0->line_start = VAR_1->f_string_multi_line_start;\n            int VAR_16 = VAR_0->lineno;\n            VAR_0->lineno = VAR_0->first_lineno;\n\n            if (VAR_1->f_string_quote_size == 3) {\n                return MAKE_TOKEN(syntaxerror(VAR_0,\n                                    \"unterminated triple-quoted f-string literal\"\n                                    \" (detected at line %d)\", VAR_16));\n            }\n            else {\n                return MAKE_TOKEN(syntaxerror(VAR_0,\n                                    \"unterminated f-string literal (detected at\"\n                                    \" line %d)\", VAR_16));\n            }\n        }\n\n        if (VAR_13 == VAR_1->f_string_quote) {\n            VAR_4 += 1;\n            continue;\n        } else {\n            VAR_4 = 0;\n        }\n\n        int VAR_17 = (\n                VAR_1->last_expr_end != -1\n                &&\n                INSIDE_FSTRING_EXPR(VAR_1)\n        );\n        if (VAR_13 == '{') {\n            int VAR_18 = tok_nextc(VAR_0);\n            if (VAR_18 != '{' || VAR_17) {\n                tok_backup(VAR_0, VAR_18);\n                tok_backup(VAR_0, VAR_13);\n                VAR_1->curly_bracket_expr_start_depth++;\n                if (VAR_1->curly_bracket_expr_start_depth >= VAR_8) {\n                    return MAKE_TOKEN(syntaxerror(VAR_0, \"f-string: expressions nested too deeply\"));\n                }\n                TOK_GET_MODE(VAR_0)->kind = VAR_9;\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur;\n            } else {\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur - 1;\n            }\n            return MAKE_TOKEN(VAR_19);\n        } else if (VAR_13 == '}') {\n            if (VAR_5) {\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur;\n                return MAKE_TOKEN(VAR_19);\n            }\n            int VAR_18 = tok_nextc(VAR_0);\n\n            /* COMMENT_6 */\n            /* COMMENT_7 */\n            /* COMMENT_8 */\n            /* COMMENT_9 */\n            if (VAR_18 == '}' && !VAR_17) {\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur - 1;\n            } else {\n                tok_backup(VAR_0, VAR_18);\n                tok_backup(VAR_0, VAR_13);\n                TOK_GET_MODE(VAR_0)->kind = VAR_9;\n                VAR_2 = VAR_0->start;\n                VAR_3 = VAR_0->cur;\n            }\n            return MAKE_TOKEN(VAR_19);\n        } else if (VAR_13 == '\\\\') {\n            int VAR_18 = tok_nextc(VAR_0);\n            /* COMMENT_10 */\n            /* COMMENT_11 */\n            /* COMMENT_12 */\n            if (VAR_18 == '{' || VAR_18 == '}') {\n                if (!VAR_1->f_string_raw) {\n                    if (warn_invalid_escape_sequence(VAR_0, VAR_18)) {\n                        return MAKE_TOKEN(VAR_15);\n                    }\n                }\n                tok_backup(VAR_0, VAR_18);\n                continue;\n            }\n\n            if (!VAR_1->f_string_raw) {\n                if (VAR_18 == 'N') {\n                    /* COMMENT_13 */\n                    VAR_18 = tok_nextc(VAR_0);\n                    if (VAR_18 == '{') {\n                        VAR_5 = 1;\n                    } else {\n                        tok_backup(VAR_0, VAR_18);\n                    }\n                }\n            } /* COMMENT_14 */\n                                          \n               \n        }\n    }\n\n    /* COMMENT_17 */\n    /* COMMENT_18 */\n    for (int VAR_10 = 0; VAR_10 < VAR_1->f_string_quote_size; VAR_10++) {\n        tok_backup(VAR_0, VAR_1->f_string_quote);\n    }\n    VAR_2 = VAR_0->start;\n    VAR_3 = VAR_0->cur;\n    return MAKE_TOKEN(VAR_19);\n}",
  "func_graph_path": "python/cpython/c120bc2d354ca3d27d0c7a53bf65574ddaabaf3a/tokenizer.c/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -56,6 +56,9 @@\n     while (end_quote_size != current_tok->f_string_quote_size) {\n         int c = tok_nextc(tok);\n         if (c == EOF || (current_tok->f_string_quote_size == 1 && c == '\\n')) {\n+            if (tok->decoding_erred)\n+                return MAKE_TOKEN(ERRORTOKEN);\n+\n             assert(tok->multi_line_start != NULL);\n             // shift the tok_state's location into\n             // the start of string, and report the error",
  "diff_line_info": {
    "deleted_lines": [],
    "added_lines": [
      "            if (tok->decoding_erred)",
      "                return MAKE_TOKEN(ERRORTOKEN);",
      ""
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/python/cpython/pull/103993",
  "description": {
    "pr_info": {
      "title": "gh-103824: fix use-after-free error in Parser/tokenizer.c",
      "number": 103993
    },
    "comment": [
      "Fixes use-after-free errors in `tokenizer.c` that are mentioned in #103824.\n\n<!-- gh-issue-number: gh-103824 -->\n* Issue: gh-103824\n<!-- /gh-issue-number -->\n"
    ]
  },
  "Bug Filter": "Security Vulnerability Fix",
  "Bug Filter Confidence": 1.0,
  "Bug Filter Response": "**Final Classification:** Security Vulnerability Fix; **Confidence:** 1.0"
}