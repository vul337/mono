{
  "cve_id": "CVE-2021-45942",
  "cwe_ids": [
    "CWE-787"
  ],
  "cvss_vector": "AV:N/AC:M/Au:N/C:N/I:N/A:P",
  "cvss_is_v3": false,
  "repo_name": "AcademySoftwareFoundation/openexr",
  "commit_msg": "DeepScanlineInputFile now uses chunk size test from DeepTiledInputFile (#1205)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
  "commit_hash": "db217f29dfb24f6b4b5100c24ac5e7490e1c57d0",
  "git_url": "https://github.com/AcademySoftwareFoundation/openexr/commit/db217f29dfb24f6b4b5100c24ac5e7490e1c57d0",
  "file_path": "src/lib/OpenEXR/ImfDeepScanLineInputFile.cpp",
  "func_name": "readSampleCountForLineBlock",
  "func_before": "void\nreadSampleCountForLineBlock(InputStreamMutex* streamData,\n                            DeepScanLineInputFile::Data* data,\n                            int lineBlockId)\n{\n    streamData->is->seekg(data->lineOffsets[lineBlockId]);\n\n    if (isMultiPart(data->version))\n    {\n        int partNumber;\n        OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, partNumber);\n\n        if (partNumber != data->partNumber)\n            throw IEX_NAMESPACE::ArgExc(\"Unexpected part number.\");\n    }\n\n    int minY;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, minY);\n\n    //\n    // Check the correctness of minY.\n    //\n\n    if (minY != data->minY + lineBlockId * data->linesInBuffer)\n        throw IEX_NAMESPACE::ArgExc(\"Unexpected data block y coordinate.\");\n\n    int maxY;\n    maxY = min(minY + data->linesInBuffer - 1, data->maxY);\n\n    uint64_t sampleCountTableDataSize;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, sampleCountTableDataSize);\n\n    \n    \n    if(sampleCountTableDataSize>static_cast<uint64_t>(data->maxSampleCountTableSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"Bad sampleCountTableDataSize read from chunk \"<< lineBlockId << \": expected \" << data->maxSampleCountTableSize << \" or less, got \"<< sampleCountTableDataSize);\n    }\n    \n    uint64_t packedDataSize;\n    uint64_t unpackedDataSize;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, packedDataSize);\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, unpackedDataSize);\n\n    \n    \n    //\n    // We make a check on the data size requirements here.\n    // Whilst we wish to store 64bit sizes on disk, not all the compressors\n    // have been made to work with such data sizes and are still limited to\n    // using signed 32 bit (int) for the data size. As such, this version\n    // insists that we validate that the data size does not exceed the data\n    // type max limit.\n    // @TODO refactor the compressor code to ensure full 64-bit support.\n    //\n\n    int compressorMaxDataSize = std::numeric_limits<int>::max();\n    if (sampleCountTableDataSize > uint64_t(compressorMaxDataSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not \"\n              << \"support the allocation of data with size  > \"\n              << compressorMaxDataSize\n              << \" file table size    :\" << sampleCountTableDataSize << \".\\n\");\n    }\n    streamData->is->read(data->sampleCountTableBuffer, static_cast<int>(sampleCountTableDataSize));\n    \n    const char* readPtr;\n\n    //\n    // If the sample count table is compressed, we'll uncompress it.\n    //\n\n\n    if (sampleCountTableDataSize < static_cast<uint64_t>(data->maxSampleCountTableSize))\n    {\n        if(!data->sampleCountTableComp)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline data corrupt at chunk \" << lineBlockId << \" (sampleCountTableDataSize error)\");\n        }\n        data->sampleCountTableComp->uncompress(data->sampleCountTableBuffer,\n                                               static_cast<int>(sampleCountTableDataSize),\n                                               minY,\n                                               readPtr);\n    }\n    else readPtr = data->sampleCountTableBuffer;\n\n    char* base = data->sampleCountSliceBase;\n    int xStride = data->sampleCountXStride;\n    int yStride = data->sampleCountYStride;\n\n    // total number of samples in block: used to check samplecount table doesn't\n    // reference more data than exists\n    \n    size_t cumulative_total_samples=0;\n    \n    for (int y = minY; y <= maxY; y++)\n    {\n        int yInDataWindow = y - data->minY;\n        data->lineSampleCount[yInDataWindow] = 0;\n\n        int lastAccumulatedCount = 0;\n        for (int x = data->minX; x <= data->maxX; x++)\n        {\n            int accumulatedCount, count;\n\n            //\n            // Read the sample count for pixel (x, y).\n            //\n\n            Xdr::read <CharPtrIO> (readPtr, accumulatedCount);\n            \n            // sample count table should always contain monotonically\n            // increasing values.\n            if (accumulatedCount < lastAccumulatedCount)\n            {\n                THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << lineBlockId << \" (negative sample count detected)\");\n            }\n\n            count = accumulatedCount - lastAccumulatedCount;\n            lastAccumulatedCount = accumulatedCount;\n\n            //\n            // Store the data in both internal and external data structure.\n            //\n\n            data->sampleCount[yInDataWindow][x - data->minX] = count;\n            data->lineSampleCount[yInDataWindow] += count;\n            sampleCount(base, xStride, yStride, x, y) = count;\n        }\n        cumulative_total_samples+=data->lineSampleCount[yInDataWindow];\n        if(cumulative_total_samples*data->combinedSampleSize > unpackedDataSize)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << lineBlockId << \": pixel data only contains \" << unpackedDataSize \n            << \" bytes of data but table references at least \" << cumulative_total_samples*data->combinedSampleSize << \" bytes of sample data\" );            \n        }\n        data->gotSampleCount[y - data->minY] = true;\n    }\n}",
  "abstract_func_before": "void\nreadSampleCountForLineBlock(InputStreamMutex* VAR_0,\n                            DeepScanLineInputFile::Data* VAR_1,\n                            int VAR_2)\n{\n    VAR_0->is->seekg(VAR_1->lineOffsets[VAR_2]);\n\n    if (isMultiPart(VAR_1->version))\n    {\n        int VAR_3;\n        OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_3);\n\n        if (VAR_3 != VAR_1->partNumber)\n            throw IEX_NAMESPACE::ArgExc(\"Unexpected part number.\");\n    }\n\n    int VAR_5;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_5);\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    /* COMMENT_0 */\n\n    if (VAR_5 != VAR_1->minY + VAR_2 * VAR_1->linesInBuffer)\n        throw IEX_NAMESPACE::ArgExc(\"Unexpected data block y coordinate.\");\n\n    int VAR_6;\n    VAR_6 = min(VAR_5 + VAR_1->linesInBuffer - 1, VAR_1->maxY);\n\n    uint64_t VAR_7;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_7);\n\n    \n    \n    if(VAR_7>VAR_8<uint64_t>(VAR_1->maxSampleCountTableSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"Bad sampleCountTableDataSize read from chunk \"<< VAR_2 << \": expected \" << VAR_1->maxSampleCountTableSize << \" or less, got \"<< VAR_7);\n    }\n    \n    uint64_t VAR_9;\n    uint64_t VAR_10;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_9);\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_10);\n\n    \n    \n    /* COMMENT_0 */\n    /* COMMENT_2 */\n    /* COMMENT_3 */\n    /* COMMENT_4 */\n    /* COMMENT_5 */\n    /* COMMENT_6 */\n    /* COMMENT_7 */\n    /* COMMENT_8 */\n    /* COMMENT_0 */\n\n    int VAR_11 = std::numeric_limits<int>::max();\n    if (VAR_7 > uint64_t(VAR_11))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not \"\n              << \"support the allocation of data with size  > \"\n              << VAR_11\n              << \" file table size    :\" << VAR_7 << \".\\n\");\n    }\n    VAR_0->is->read(VAR_1->sampleCountTableBuffer, VAR_8<int>(VAR_7));\n    \n    const char* VAR_12;\n\n    /* COMMENT_0 */\n    /* COMMENT_9 */\n    /* COMMENT_0 */\n\n\n    if (VAR_7 < VAR_8<uint64_t>(VAR_1->maxSampleCountTableSize))\n    {\n        if(!VAR_1->sampleCountTableComp)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline data corrupt at chunk \" << VAR_2 << \" (sampleCountTableDataSize error)\");\n        }\n        VAR_1->sampleCountTableComp->uncompress(VAR_1->sampleCountTableBuffer,\n                                               VAR_8<int>(VAR_7),\n                                               VAR_5,\n                                               VAR_12);\n    }\n    else VAR_12 = VAR_1->sampleCountTableBuffer;\n\n    char* VAR_13 = VAR_1->sampleCountSliceBase;\n    int VAR_14 = VAR_1->sampleCountXStride;\n    int VAR_15 = VAR_1->sampleCountYStride;\n\n    /* COMMENT_10 */\n    /* COMMENT_11 */\n    \n    size_t VAR_16=0;\n    \n    for (int VAR_17 = VAR_5; VAR_17 <= VAR_6; VAR_17++)\n    {\n        int VAR_18 = VAR_17 - VAR_1->minY;\n        VAR_1->lineSampleCount[VAR_18] = 0;\n\n        int VAR_19 = 0;\n        for (int VAR_20 = VAR_1->minX; VAR_20 <= VAR_1->maxX; VAR_20++)\n        {\n            int VAR_21, VAR_22;\n\n            /* COMMENT_0 */\n            /* COMMENT_12 */\n            /* COMMENT_0 */\n\n            Xdr::VAR_4 <CharPtrIO> (VAR_12, VAR_21);\n            \n            /* COMMENT_13 */\n            /* COMMENT_14 */\n            if (VAR_21 < VAR_19)\n            {\n                THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << VAR_2 << \" (negative sample count detected)\");\n            }\n\n            VAR_22 = VAR_21 - VAR_19;\n            VAR_19 = VAR_21;\n\n            /* COMMENT_0 */\n            /* COMMENT_15 */\n            /* COMMENT_0 */\n\n            VAR_1->sampleCount[VAR_18][VAR_20 - VAR_1->minX] = VAR_22;\n            VAR_1->lineSampleCount[VAR_18] += VAR_22;\n            sampleCount(VAR_13, VAR_14, VAR_15, VAR_20, VAR_17) = VAR_22;\n        }\n        VAR_16+=VAR_1->lineSampleCount[VAR_18];\n        if(VAR_16*VAR_1->combinedSampleSize > VAR_10)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << VAR_2 << \": pixel data only contains \" << VAR_10 \n            << \" bytes of data but table references at least \" << VAR_16*VAR_1->combinedSampleSize << \" bytes of sample data\" );            \n        }\n        VAR_1->gotSampleCount[VAR_17 - VAR_1->minY] = true;\n    }\n}",
  "func_graph_path_before": "AcademySoftwareFoundation/openexr/db217f29dfb24f6b4b5100c24ac5e7490e1c57d0/ImfDeepScanLineInputFile.cpp/vul/before/0.json",
  "func": "void\nreadSampleCountForLineBlock(InputStreamMutex* streamData,\n                            DeepScanLineInputFile::Data* data,\n                            int lineBlockId)\n{\n    streamData->is->seekg(data->lineOffsets[lineBlockId]);\n\n    if (isMultiPart(data->version))\n    {\n        int partNumber;\n        OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, partNumber);\n\n        if (partNumber != data->partNumber)\n            throw IEX_NAMESPACE::ArgExc(\"Unexpected part number.\");\n    }\n\n    int minY;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, minY);\n\n    //\n    // Check the correctness of minY.\n    //\n\n    if (minY != data->minY + lineBlockId * data->linesInBuffer)\n        throw IEX_NAMESPACE::ArgExc(\"Unexpected data block y coordinate.\");\n\n    int maxY;\n    maxY = min(minY + data->linesInBuffer - 1, data->maxY);\n\n    uint64_t sampleCountTableDataSize;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, sampleCountTableDataSize);\n\n    \n    \n    if(sampleCountTableDataSize>static_cast<uint64_t>(data->maxSampleCountTableSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"Bad sampleCountTableDataSize read from chunk \"<< lineBlockId << \": expected \" << data->maxSampleCountTableSize << \" or less, got \"<< sampleCountTableDataSize);\n    }\n    \n    uint64_t packedDataSize;\n    uint64_t unpackedDataSize;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, packedDataSize);\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, unpackedDataSize);\n\n    \n    \n    //\n    // We make a check on the data size requirements here.\n    // Whilst we wish to store 64bit sizes on disk, not all the compressors\n    // have been made to work with such data sizes and are still limited to\n    // using signed 32 bit (int) for the data size. As such, this version\n    // insists that we validate that the data size does not exceed the data\n    // type max limit.\n    // @TODO refactor the compressor code to ensure full 64-bit support.\n    //\n\n    uint64_t compressorMaxDataSize = static_cast<uint64_t>(std::numeric_limits<int>::max());\n    if (packedDataSize         > compressorMaxDataSize ||\n        unpackedDataSize > compressorMaxDataSize ||\n        sampleCountTableDataSize        > compressorMaxDataSize)\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not\"\n            << \"support the allocation of data with size  > \"\n            << compressorMaxDataSize\n            << \" file table size    :\" << sampleCountTableDataSize\n            << \" file unpacked size :\" << unpackedDataSize\n            << \" file packed size   :\" << packedDataSize << \".\\n\");\n    }\n\n\n    streamData->is->read(data->sampleCountTableBuffer, static_cast<int>(sampleCountTableDataSize));\n    \n    const char* readPtr;\n\n    //\n    // If the sample count table is compressed, we'll uncompress it.\n    //\n\n\n    if (sampleCountTableDataSize < static_cast<uint64_t>(data->maxSampleCountTableSize))\n    {\n        if(!data->sampleCountTableComp)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline data corrupt at chunk \" << lineBlockId << \" (sampleCountTableDataSize error)\");\n        }\n        data->sampleCountTableComp->uncompress(data->sampleCountTableBuffer,\n                                               static_cast<int>(sampleCountTableDataSize),\n                                               minY,\n                                               readPtr);\n    }\n    else readPtr = data->sampleCountTableBuffer;\n\n    char* base = data->sampleCountSliceBase;\n    int xStride = data->sampleCountXStride;\n    int yStride = data->sampleCountYStride;\n\n    // total number of samples in block: used to check samplecount table doesn't\n    // reference more data than exists\n    \n    size_t cumulative_total_samples=0;\n    \n    for (int y = minY; y <= maxY; y++)\n    {\n        int yInDataWindow = y - data->minY;\n        data->lineSampleCount[yInDataWindow] = 0;\n\n        int lastAccumulatedCount = 0;\n        for (int x = data->minX; x <= data->maxX; x++)\n        {\n            int accumulatedCount, count;\n\n            //\n            // Read the sample count for pixel (x, y).\n            //\n\n            Xdr::read <CharPtrIO> (readPtr, accumulatedCount);\n            \n            // sample count table should always contain monotonically\n            // increasing values.\n            if (accumulatedCount < lastAccumulatedCount)\n            {\n                THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << lineBlockId << \" (negative sample count detected)\");\n            }\n\n            count = accumulatedCount - lastAccumulatedCount;\n            lastAccumulatedCount = accumulatedCount;\n\n            //\n            // Store the data in both internal and external data structure.\n            //\n\n            data->sampleCount[yInDataWindow][x - data->minX] = count;\n            data->lineSampleCount[yInDataWindow] += count;\n            sampleCount(base, xStride, yStride, x, y) = count;\n        }\n        cumulative_total_samples+=data->lineSampleCount[yInDataWindow];\n        if(cumulative_total_samples*data->combinedSampleSize > unpackedDataSize)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << lineBlockId << \": pixel data only contains \" << unpackedDataSize \n            << \" bytes of data but table references at least \" << cumulative_total_samples*data->combinedSampleSize << \" bytes of sample data\" );            \n        }\n        data->gotSampleCount[y - data->minY] = true;\n    }\n}",
  "abstract_func": "void\nreadSampleCountForLineBlock(InputStreamMutex* VAR_0,\n                            DeepScanLineInputFile::Data* VAR_1,\n                            int VAR_2)\n{\n    VAR_0->is->seekg(VAR_1->lineOffsets[VAR_2]);\n\n    if (isMultiPart(VAR_1->version))\n    {\n        int VAR_3;\n        OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_3);\n\n        if (VAR_3 != VAR_1->partNumber)\n            throw IEX_NAMESPACE::ArgExc(\"Unexpected part number.\");\n    }\n\n    int VAR_5;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_5);\n\n    /* COMMENT_0 */\n    /* COMMENT_1 */\n    /* COMMENT_0 */\n\n    if (VAR_5 != VAR_1->minY + VAR_2 * VAR_1->linesInBuffer)\n        throw IEX_NAMESPACE::ArgExc(\"Unexpected data block y coordinate.\");\n\n    int VAR_6;\n    VAR_6 = min(VAR_5 + VAR_1->linesInBuffer - 1, VAR_1->maxY);\n\n    uint64_t VAR_7;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_7);\n\n    \n    \n    if(VAR_7>VAR_8<uint64_t>(VAR_1->maxSampleCountTableSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"Bad sampleCountTableDataSize read from chunk \"<< VAR_2 << \": expected \" << VAR_1->maxSampleCountTableSize << \" or less, got \"<< VAR_7);\n    }\n    \n    uint64_t VAR_9;\n    uint64_t VAR_10;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_9);\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::VAR_4 <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*VAR_0->is, VAR_10);\n\n    \n    \n    /* COMMENT_0 */\n    /* COMMENT_2 */\n    /* COMMENT_3 */\n    /* COMMENT_4 */\n    /* COMMENT_5 */\n    /* COMMENT_6 */\n    /* COMMENT_7 */\n    /* COMMENT_8 */\n    /* COMMENT_0 */\n\n    uint64_t VAR_11 = VAR_8<uint64_t>(std::numeric_limits<int>::max());\n    if (VAR_9         > VAR_11 ||\n        VAR_10 > VAR_11 ||\n        VAR_7        > VAR_11)\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not\"\n            << \"support the allocation of data with size  > \"\n            << VAR_11\n            << \" file table size    :\" << VAR_7\n            << \" file unpacked size :\" << VAR_10\n            << \" file packed size   :\" << VAR_9 << \".\\n\");\n    }\n\n\n    VAR_0->is->read(VAR_1->sampleCountTableBuffer, VAR_8<int>(VAR_7));\n    \n    const char* VAR_12;\n\n    /* COMMENT_0 */\n    /* COMMENT_9 */\n    /* COMMENT_0 */\n\n\n    if (VAR_7 < VAR_8<uint64_t>(VAR_1->maxSampleCountTableSize))\n    {\n        if(!VAR_1->sampleCountTableComp)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline data corrupt at chunk \" << VAR_2 << \" (sampleCountTableDataSize error)\");\n        }\n        VAR_1->sampleCountTableComp->uncompress(VAR_1->sampleCountTableBuffer,\n                                               VAR_8<int>(VAR_7),\n                                               VAR_5,\n                                               VAR_12);\n    }\n    else VAR_12 = VAR_1->sampleCountTableBuffer;\n\n    char* VAR_13 = VAR_1->sampleCountSliceBase;\n    int VAR_14 = VAR_1->sampleCountXStride;\n    int VAR_15 = VAR_1->sampleCountYStride;\n\n    /* COMMENT_10 */\n    /* COMMENT_11 */\n    \n    size_t VAR_16=0;\n    \n    for (int VAR_17 = VAR_5; VAR_17 <= VAR_6; VAR_17++)\n    {\n        int VAR_18 = VAR_17 - VAR_1->minY;\n        VAR_1->lineSampleCount[VAR_18] = 0;\n\n        int VAR_19 = 0;\n        for (int VAR_20 = VAR_1->minX; VAR_20 <= VAR_1->maxX; VAR_20++)\n        {\n            int VAR_21, VAR_22;\n\n            /* COMMENT_0 */\n            /* COMMENT_12 */\n            /* COMMENT_0 */\n\n            Xdr::VAR_4 <CharPtrIO> (VAR_12, VAR_21);\n            \n            /* COMMENT_13 */\n            /* COMMENT_14 */\n            if (VAR_21 < VAR_19)\n            {\n                THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << VAR_2 << \" (negative sample count detected)\");\n            }\n\n            VAR_22 = VAR_21 - VAR_19;\n            VAR_19 = VAR_21;\n\n            /* COMMENT_0 */\n            /* COMMENT_15 */\n            /* COMMENT_0 */\n\n            VAR_1->sampleCount[VAR_18][VAR_20 - VAR_1->minX] = VAR_22;\n            VAR_1->lineSampleCount[VAR_18] += VAR_22;\n            sampleCount(VAR_13, VAR_14, VAR_15, VAR_20, VAR_17) = VAR_22;\n        }\n        VAR_16+=VAR_1->lineSampleCount[VAR_18];\n        if(VAR_16*VAR_1->combinedSampleSize > VAR_10)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << VAR_2 << \": pixel data only contains \" << VAR_10 \n            << \" bytes of data but table references at least \" << VAR_16*VAR_1->combinedSampleSize << \" bytes of sample data\" );            \n        }\n        VAR_1->gotSampleCount[VAR_17 - VAR_1->minY] = true;\n    }\n}",
  "func_graph_path": "AcademySoftwareFoundation/openexr/db217f29dfb24f6b4b5100c24ac5e7490e1c57d0/ImfDeepScanLineInputFile.cpp/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -54,14 +54,20 @@\n     // @TODO refactor the compressor code to ensure full 64-bit support.\n     //\n \n-    int compressorMaxDataSize = std::numeric_limits<int>::max();\n-    if (sampleCountTableDataSize > uint64_t(compressorMaxDataSize))\n+    uint64_t compressorMaxDataSize = static_cast<uint64_t>(std::numeric_limits<int>::max());\n+    if (packedDataSize         > compressorMaxDataSize ||\n+        unpackedDataSize > compressorMaxDataSize ||\n+        sampleCountTableDataSize        > compressorMaxDataSize)\n     {\n-        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not \"\n-              << \"support the allocation of data with size  > \"\n-              << compressorMaxDataSize\n-              << \" file table size    :\" << sampleCountTableDataSize << \".\\n\");\n+        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not\"\n+            << \"support the allocation of data with size  > \"\n+            << compressorMaxDataSize\n+            << \" file table size    :\" << sampleCountTableDataSize\n+            << \" file unpacked size :\" << unpackedDataSize\n+            << \" file packed size   :\" << packedDataSize << \".\\n\");\n     }\n+\n+\n     streamData->is->read(data->sampleCountTableBuffer, static_cast<int>(sampleCountTableDataSize));\n     \n     const char* readPtr;",
  "diff_line_info": {
    "deleted_lines": [
      "    int compressorMaxDataSize = std::numeric_limits<int>::max();",
      "    if (sampleCountTableDataSize > uint64_t(compressorMaxDataSize))",
      "        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not \"",
      "              << \"support the allocation of data with size  > \"",
      "              << compressorMaxDataSize",
      "              << \" file table size    :\" << sampleCountTableDataSize << \".\\n\");"
    ],
    "added_lines": [
      "    uint64_t compressorMaxDataSize = static_cast<uint64_t>(std::numeric_limits<int>::max());",
      "    if (packedDataSize         > compressorMaxDataSize ||",
      "        unpackedDataSize > compressorMaxDataSize ||",
      "        sampleCountTableDataSize        > compressorMaxDataSize)",
      "        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not\"",
      "            << \"support the allocation of data with size  > \"",
      "            << compressorMaxDataSize",
      "            << \" file table size    :\" << sampleCountTableDataSize",
      "            << \" file unpacked size :\" << unpackedDataSize",
      "            << \" file packed size   :\" << packedDataSize << \".\\n\");",
      "",
      ""
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/AcademySoftwareFoundation/openexr/pull/1205",
  "description": {
    "pr_info": {
      "title": "DeepScanlineInputFile now uses chunk size test from DeepTiledInputFile",
      "number": 1205
    },
    "comment": [
      "Address https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=41075\r\nThe file format allows for deep scanline/tile chunks with more than 2GB of data, but this is not currently supported by the library, causing an integer overflow. DeepTiledInputFile was properly testing for large chunks, but DeepScanlineInputFile was only partially checking.\r\nCopy/pasting the test from Scanline to Tile catches the issue before the overflow occurs.\r\n\r\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>"
    ]
  },
  "Bug Filter": "Defect Remediation & Feature Upgrades",
  "Bug Filter Confidence": 0.7,
  "Bug Filter Response": "\n\n**Final Output:**\nAnalysis: The patch modifies data size checks to prevent overflow by comparing multiple sizes against a max limit, enhancing error handling. It addresses potential issues with large data sizes but lacks explicit security context.\n\nFinal Classification: Defect Remediation & Feature Upgrades\nConfidence Score: 0.7\n\n**Step-by-Step Explanation:**\n\n1. **Patch Analysis**: The code change enhances data size checks, adding multiple conditions and detailed error messages to handle larger data sizes, preventing potential overflows.\n\n2. **Security Assessment**: While preventing overflows is important, the patch's intent seems more about handling larger files rather than fixing a security vulnerability.\n\n3. **Classification**: The changes are functional improvements addressing data handling issues, fitting under Defect Remediation.\n\n4. **Confidence**: Moderate confidence due to the lack of explicit security context in the commit message.\n\n**Final Output:**\nAnalysis: The patch modifies data size checks to prevent overflow by comparing multiple sizes against a max limit, enhancing error handling. It addresses potential issues with large data sizes but lacks explicit security context.\n\nFinal Classification: Defect Remediation & Feature Upgrades\nConfidence Score: 0.7"
}