{
  "cve_id": "CVE-2018-1000880",
  "cwe_ids": [
    "CWE-119"
  ],
  "cvss_vector": "AV:N/AC:M/Au:N/C:N/I:N/A:P",
  "cvss_is_v3": false,
  "repo_name": "libarchive",
  "commit_msg": "warc: consume data once read\n\nThe warc decoder only used read ahead, it wouldn't actually consume\ndata that had previously been printed. This means that if you specify\nan invalid content length, it will just reprint the same data over\nand over and over again until it hits the desired length.\n\nThis means that a WARC resource with e.g.\nContent-Length: 666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666665\nbut only a few hundred bytes of data, causes a quasi-infinite loop.\n\nConsume data in subsequent calls to _warc_read.\n\nFound with an AFL + afl-rb + qsym setup.",
  "commit_hash": "9c84b7426660c09c18cc349f6d70b5f8168b5680",
  "git_url": "https://github.com/libarchive/libarchive/commit/9c84b7426660c09c18cc349f6d70b5f8168b5680",
  "file_path": "libarchive/archive_read_support_format_warc.c",
  "func_name": "_warc_read",
  "func_before": "static int\n_warc_read(struct archive_read *a, const void **buf, size_t *bsz, int64_t *off)\n{\n\tstruct warc_s *w = a->format->data;\n\tconst char *rab;\n\tssize_t nrd;\n\n\tif (w->cntoff >= w->cntlen) {\n\teof:\n\t\t/* it's our lucky day, no work, we can leave early */\n\t\t*buf = NULL;\n\t\t*bsz = 0U;\n\t\t*off = w->cntoff + 4U/*for \\r\\n\\r\\n separator*/;\n\t\tw->unconsumed = 0U;\n\t\treturn (ARCHIVE_EOF);\n\t}\n\n\trab = __archive_read_ahead(a, 1U, &nrd);\n\tif (nrd < 0) {\n\t\t*bsz = 0U;\n\t\t/* big catastrophe */\n\t\treturn (int)nrd;\n\t} else if (nrd == 0) {\n\t\tgoto eof;\n\t} else if ((size_t)nrd > w->cntlen - w->cntoff) {\n\t\t/* clamp to content-length */\n\t\tnrd = w->cntlen - w->cntoff;\n\t}\n\t*off = w->cntoff;\n\t*bsz = nrd;\n\t*buf = rab;\n\n\tw->cntoff += nrd;\n\tw->unconsumed = (size_t)nrd;\n\treturn (ARCHIVE_OK);\n}",
  "abstract_func_before": "static int\n_warc_read(struct archive_read *VAR_0, const void **VAR_1, size_t *VAR_2, int64_t *VAR_3)\n{\n\tstruct warc_s *VAR_4 = VAR_0->format->data;\n\tconst char *VAR_5;\n\tssize_t VAR_6;\n\n\tif (VAR_4->cntoff >= VAR_4->cntlen) {\n\teof:\n\t\t/* COMMENT_0 */\n\t\t*VAR_1 = NULL;\n\t\t*VAR_2 = 0U;\n\t\t*VAR_3 = VAR_4->cntoff + 4U/* COMMENT_1 */;\n\t\tVAR_4->unconsumed = 0U;\n\t\treturn (VAR_7);\n\t}\n\n\tVAR_5 = __archive_read_ahead(VAR_0, 1U, &VAR_6);\n\tif (VAR_6 < 0) {\n\t\t*VAR_2 = 0U;\n\t\t/* COMMENT_2 */\n\t\treturn (int)VAR_6;\n\t} else if (VAR_6 == 0) {\n\t\tgoto eof;\n\t} else if ((size_t)VAR_6 > VAR_4->cntlen - VAR_4->cntoff) {\n\t\t/* COMMENT_3 */\n\t\tVAR_6 = VAR_4->cntlen - VAR_4->cntoff;\n\t}\n\t*VAR_3 = VAR_4->cntoff;\n\t*VAR_2 = VAR_6;\n\t*VAR_1 = VAR_5;\n\n\tVAR_4->cntoff += VAR_6;\n\tVAR_4->unconsumed = (size_t)VAR_6;\n\treturn (VAR_8);\n}",
  "func_graph_path_before": "libarchive/9c84b7426660c09c18cc349f6d70b5f8168b5680/archive_read_support_format_warc.c/vul/before/0.json",
  "func": "static int\n_warc_read(struct archive_read *a, const void **buf, size_t *bsz, int64_t *off)\n{\n\tstruct warc_s *w = a->format->data;\n\tconst char *rab;\n\tssize_t nrd;\n\n\tif (w->cntoff >= w->cntlen) {\n\teof:\n\t\t/* it's our lucky day, no work, we can leave early */\n\t\t*buf = NULL;\n\t\t*bsz = 0U;\n\t\t*off = w->cntoff + 4U/*for \\r\\n\\r\\n separator*/;\n\t\tw->unconsumed = 0U;\n\t\treturn (ARCHIVE_EOF);\n\t}\n\n\tif (w->unconsumed) {\n\t\t__archive_read_consume(a, w->unconsumed);\n\t\tw->unconsumed = 0U;\n\t}\n\n\trab = __archive_read_ahead(a, 1U, &nrd);\n\tif (nrd < 0) {\n\t\t*bsz = 0U;\n\t\t/* big catastrophe */\n\t\treturn (int)nrd;\n\t} else if (nrd == 0) {\n\t\tgoto eof;\n\t} else if ((size_t)nrd > w->cntlen - w->cntoff) {\n\t\t/* clamp to content-length */\n\t\tnrd = w->cntlen - w->cntoff;\n\t}\n\t*off = w->cntoff;\n\t*bsz = nrd;\n\t*buf = rab;\n\n\tw->cntoff += nrd;\n\tw->unconsumed = (size_t)nrd;\n\treturn (ARCHIVE_OK);\n}",
  "abstract_func": "static int\n_warc_read(struct archive_read *VAR_0, const void **VAR_1, size_t *VAR_2, int64_t *VAR_3)\n{\n\tstruct warc_s *VAR_4 = VAR_0->format->data;\n\tconst char *VAR_5;\n\tssize_t VAR_6;\n\n\tif (VAR_4->cntoff >= VAR_4->cntlen) {\n\teof:\n\t\t/* COMMENT_0 */\n\t\t*VAR_1 = NULL;\n\t\t*VAR_2 = 0U;\n\t\t*VAR_3 = VAR_4->cntoff + 4U/* COMMENT_1 */;\n\t\tVAR_4->unconsumed = 0U;\n\t\treturn (VAR_7);\n\t}\n\n\tif (VAR_4->unconsumed) {\n\t\t__archive_read_consume(VAR_0, VAR_4->unconsumed);\n\t\tVAR_4->unconsumed = 0U;\n\t}\n\n\tVAR_5 = __archive_read_ahead(VAR_0, 1U, &VAR_6);\n\tif (VAR_6 < 0) {\n\t\t*VAR_2 = 0U;\n\t\t/* COMMENT_2 */\n\t\treturn (int)VAR_6;\n\t} else if (VAR_6 == 0) {\n\t\tgoto eof;\n\t} else if ((size_t)VAR_6 > VAR_4->cntlen - VAR_4->cntoff) {\n\t\t/* COMMENT_3 */\n\t\tVAR_6 = VAR_4->cntlen - VAR_4->cntoff;\n\t}\n\t*VAR_3 = VAR_4->cntoff;\n\t*VAR_2 = VAR_6;\n\t*VAR_1 = VAR_5;\n\n\tVAR_4->cntoff += VAR_6;\n\tVAR_4->unconsumed = (size_t)VAR_6;\n\treturn (VAR_8);\n}",
  "func_graph_path": "libarchive/9c84b7426660c09c18cc349f6d70b5f8168b5680/archive_read_support_format_warc.c/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,11 @@\n \t\t*off = w->cntoff + 4U/*for \\r\\n\\r\\n separator*/;\n \t\tw->unconsumed = 0U;\n \t\treturn (ARCHIVE_EOF);\n+\t}\n+\n+\tif (w->unconsumed) {\n+\t\t__archive_read_consume(a, w->unconsumed);\n+\t\tw->unconsumed = 0U;\n \t}\n \n \trab = __archive_read_ahead(a, 1U, &nrd);",
  "diff_line_info": {
    "deleted_lines": [],
    "added_lines": [
      "\t}",
      "",
      "\tif (w->unconsumed) {",
      "\t\t__archive_read_consume(a, w->unconsumed);",
      "\t\tw->unconsumed = 0U;"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/libarchive/libarchive/pull/1105",
  "description": {
    "pr_info": {
      "title": "Fix various crash, memory corruption and infinite loop conditions",
      "number": 1105
    },
    "comment": [
      "I have found some hangs, crashes and memory corruption issues in libarchive.\r\n\r\nTwo are in the RAR decoder. The first (patch 1) is a double-free via a `realloc(area, 0)`. This leads to a crash.\r\n\r\nThe second (patch 2) is memory corruption which seems to arise in ppmd7 decoding. The code can be made to read and write to a previously freed ppmd buffer by tricking the read-ahead code around multi-part archives. (This can be done even with a single archive file.) My gut feeling is that someone more skilled than I could cause arbitrary code execution with this, but I cannot say for certain.\r\n\r\nThere is a crash in ACL parsing for tar archives (patch 3). This is a simple NULL dereference leading to a crash.\r\n\r\nThe last of this batch is a quasi-infinite loop in the warc code (patch 4), where data isn't consumed after being written out, so a large Content-Length can be used to consume almost limitless time and space, leading to a DoS condition.\r\n\r\nThese were found with a combination of AFL, afl-rb and qsym.",
      "There are some test cases at https://bugs.launchpad.net/ubuntu/+source/libarchive/+bug/1794909\r\n\r\n",
      "I have requested CVEs for these issues through the Distributed Weakness Filing project.",
      "In case someone else is looking for the CVEs, it looks like the assignments are :\r\n- CVE-2018-1000877 for https://github.com/libarchive/libarchive/commit/021efa522ad729ff0f5806c4ce53e4a6cc1daa31\r\n- CVE-2018-1000878 for https://github.com/libarchive/libarchive/commit/bfcfe6f04ed20db2504db8a254d1f40a1d84eb28\r\n- CVE-2018-1000879 for https://github.com/libarchive/libarchive/commit/15bf44fd2c1ad0e3fd87048b3fcc90c4dcff1175\r\n- CVE-2018-1000880 for https://github.com/libarchive/libarchive/commit/9c84b7426660c09c18cc349f6d70b5f8168b5680"
    ]
  },
  "Bug Filter": "Security Vulnerability Fix",
  "Bug Filter Confidence": 0.9,
  "Bug Filter Response": "Final Classification: Security Vulnerability Fix  \nConfidence: 0.9\n\n**Reasoning:**\nThe commit addresses an infinite loop caused by incorrect data handling in the WARC decoder, which is described as a security issue in the vulnerability report, leading to a denial-of-service condition. The code change ensures data is consumed properly, resolving the security flaw."
}