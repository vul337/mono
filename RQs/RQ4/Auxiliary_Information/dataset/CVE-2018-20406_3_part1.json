{
  "cve_id": "CVE-2018-20406",
  "cwe_ids": [
    "CWE-190"
  ],
  "cvss_vector": "AV:N/AC:L/Au:N/C:N/I:N/A:P",
  "cvss_is_v3": false,
  "repo_name": "python/cpython",
  "commit_msg": "closes bpo-34656: Avoid relying on signed overflow in _pickle memos. (GH-9261)",
  "commit_hash": "a4ae828ee416a66d8c7bf5ee71d653c2cc6a26dd",
  "git_url": "https://github.com/python/cpython/commit/a4ae828ee416a66d8c7bf5ee71d653c2cc6a26dd",
  "file_path": "Modules/_pickle.c",
  "func_name": "PyMemoTable_Set",
  "func_before": "static int\nPyMemoTable_Set(PyMemoTable *self, PyObject *key, Py_ssize_t value)\n{\n    PyMemoEntry *entry;\n\n    assert(key != NULL);\n\n    entry = _PyMemoTable_Lookup(self, key);\n    if (entry->me_key != NULL) {\n        entry->me_value = value;\n        return 0;\n    }\n    Py_INCREF(key);\n    entry->me_key = key;\n    entry->me_value = value;\n    self->mt_used++;\n\n    /* If we added a key, we can safely resize. Otherwise just return!\n     * If used >= 2/3 size, adjust size. Normally, this quaduples the size.\n     *\n     * Quadrupling the size improves average table sparseness\n     * (reducing collisions) at the cost of some memory. It also halves\n     * the number of expensive resize operations in a growing memo table.\n     *\n     * Very large memo tables (over 50K items) use doubling instead.\n     * This may help applications with severe memory constraints.\n     */\n    if (!(self->mt_used * 3 >= (self->mt_mask + 1) * 2))\n        return 0;\n    return _PyMemoTable_ResizeTable(self,\n        (self->mt_used > 50000 ? 2 : 4) * self->mt_used);\n}",
  "abstract_func_before": "static int\nPyMemoTable_Set(PyMemoTable *VAR_0, PyObject *VAR_1, Py_ssize_t VAR_2)\n{\n    PyMemoEntry *VAR_3;\n\n    assert(VAR_1 != NULL);\n\n    VAR_3 = _PyMemoTable_Lookup(VAR_0, VAR_1);\n    if (VAR_3->me_key != NULL) {\n        VAR_3->me_value = VAR_2;\n        return 0;\n    }\n    Py_INCREF(VAR_1);\n    VAR_3->me_key = VAR_1;\n    VAR_3->me_value = VAR_2;\n    VAR_0->mt_used++;\n\n    /* COMMENT_0 */\n                                                                           \n      \n                                                             \n                                                                       \n                                                                         \n      \n                                                                    \n                                                                 \n       \n    if (!(VAR_0->mt_used * 3 >= (VAR_0->mt_mask + 1) * 2))\n        return 0;\n    return _PyMemoTable_ResizeTable(VAR_0,\n        (VAR_0->mt_used > 50000 ? 2 : 4) * VAR_0->mt_used);\n}",
  "func_graph_path_before": "python/cpython/a4ae828ee416a66d8c7bf5ee71d653c2cc6a26dd/_pickle.c/vul/before/4.json",
  "func": "static int\nPyMemoTable_Set(PyMemoTable *self, PyObject *key, Py_ssize_t value)\n{\n    PyMemoEntry *entry;\n\n    assert(key != NULL);\n\n    entry = _PyMemoTable_Lookup(self, key);\n    if (entry->me_key != NULL) {\n        entry->me_value = value;\n        return 0;\n    }\n    Py_INCREF(key);\n    entry->me_key = key;\n    entry->me_value = value;\n    self->mt_used++;\n\n    /* If we added a key, we can safely resize. Otherwise just return!\n     * If used >= 2/3 size, adjust size. Normally, this quaduples the size.\n     *\n     * Quadrupling the size improves average table sparseness\n     * (reducing collisions) at the cost of some memory. It also halves\n     * the number of expensive resize operations in a growing memo table.\n     *\n     * Very large memo tables (over 50K items) use doubling instead.\n     * This may help applications with severe memory constraints.\n     */\n    if (SIZE_MAX / 3 >= self->mt_used && self->mt_used * 3 < self->mt_allocated * 2) {\n        return 0;\n    }\n    // self->mt_used is always < PY_SSIZE_T_MAX, so this can't overflow.\n    size_t desired_size = (self->mt_used > 50000 ? 2 : 4) * self->mt_used;\n    return _PyMemoTable_ResizeTable(self, desired_size);\n}",
  "abstract_func": "static int\nPyMemoTable_Set(PyMemoTable *VAR_0, PyObject *VAR_1, Py_ssize_t VAR_2)\n{\n    PyMemoEntry *VAR_3;\n\n    assert(VAR_1 != NULL);\n\n    VAR_3 = _PyMemoTable_Lookup(VAR_0, VAR_1);\n    if (VAR_3->me_key != NULL) {\n        VAR_3->me_value = VAR_2;\n        return 0;\n    }\n    Py_INCREF(VAR_1);\n    VAR_3->me_key = VAR_1;\n    VAR_3->me_value = VAR_2;\n    VAR_0->mt_used++;\n\n    /* COMMENT_0 */\n                                                                           \n      \n                                                             \n                                                                       \n                                                                         \n      \n                                                                    \n                                                                 \n       \n    if (VAR_4 / 3 >= VAR_0->mt_used && VAR_0->mt_used * 3 < VAR_0->mt_allocated * 2) {\n        return 0;\n    }\n    /* COMMENT_9 */\n    size_t VAR_5 = (VAR_0->mt_used > 50000 ? 2 : 4) * VAR_0->mt_used;\n    return _PyMemoTable_ResizeTable(VAR_0, VAR_5);\n}",
  "func_graph_path": "python/cpython/a4ae828ee416a66d8c7bf5ee71d653c2cc6a26dd/_pickle.c/vul/after/4.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -25,8 +25,10 @@\n      * Very large memo tables (over 50K items) use doubling instead.\n      * This may help applications with severe memory constraints.\n      */\n-    if (!(self->mt_used * 3 >= (self->mt_mask + 1) * 2))\n+    if (SIZE_MAX / 3 >= self->mt_used && self->mt_used * 3 < self->mt_allocated * 2) {\n         return 0;\n-    return _PyMemoTable_ResizeTable(self,\n-        (self->mt_used > 50000 ? 2 : 4) * self->mt_used);\n+    }\n+    // self->mt_used is always < PY_SSIZE_T_MAX, so this can't overflow.\n+    size_t desired_size = (self->mt_used > 50000 ? 2 : 4) * self->mt_used;\n+    return _PyMemoTable_ResizeTable(self, desired_size);\n }",
  "diff_line_info": {
    "deleted_lines": [
      "    if (!(self->mt_used * 3 >= (self->mt_mask + 1) * 2))",
      "    return _PyMemoTable_ResizeTable(self,",
      "        (self->mt_used > 50000 ? 2 : 4) * self->mt_used);"
    ],
    "added_lines": [
      "    if (SIZE_MAX / 3 >= self->mt_used && self->mt_used * 3 < self->mt_allocated * 2) {",
      "    }",
      "    // self->mt_used is always < PY_SSIZE_T_MAX, so this can't overflow.",
      "    size_t desired_size = (self->mt_used > 50000 ? 2 : 4) * self->mt_used;",
      "    return _PyMemoTable_ResizeTable(self, desired_size);"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/python/cpython/pull/9261",
  "description": {
    "pr_info": {
      "title": "bpo-34656: Avoid relying on signed overflow in _pickle memos.",
      "number": 9261
    },
    "comment": [
      "<!--\r\nThanks for your contribution!\r\nPlease read this comment in its entirety. It's quite important.\r\n\r\n# Pull Request title\r\n\r\nIt should be in the following format:\r\n\r\n```\r\nbpo-NNNN: Summary of the changes made\r\n```\r\n\r\nWhere: bpo-NNNN refers to the issue number in the https://bugs.python.org.\r\n\r\nMost PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.\r\n\r\n# Backport Pull Request title\r\n\r\nIf this is a backport PR (PR made against branches other than `master`),\r\nplease ensure that the PR title is in the following format:\r\n\r\n```\r\n[X.Y] <title from the original PR> (GH-NNNN)\r\n```\r\n\r\nWhere: [X.Y] is the branch name, e.g. [3.6].\r\n\r\nGH-NNNN refers to the PR number from `master`.\r\n\r\n-->\r\n\n\n<!-- issue-number: [bpo-1621](https://www.bugs.python.org/issue1621) -->\nhttps://bugs.python.org/issue1621\n<!-- /issue-number -->\n",
      "Thanks @benjaminp for the PR üåÆüéâ.. I'm working now to backport this PR to: 3.6, 3.7.\nüêçüçí‚õèü§ñ ",
      "[GH-9465](https://github.com/python/cpython/pull/9465) is a backport of this pull request to the [3.7 branch](https://github.com/python/cpython/tree/3.7).",
      "[GH-9466](https://github.com/python/cpython/pull/9466) is a backport of this pull request to the [3.6 branch](https://github.com/python/cpython/tree/3.6)."
    ]
  },
  "Bug Filter": "Security Vulnerability Fix",
  "Bug Filter Confidence": 0.9,
  "Bug Filter Response": "**Final Classification:** Security Vulnerability Fix; **Confidence:** 0.9  \n\n**Rationale:** The patch addresses a signed overflow in the _pickle module, a known security issue. The code changes include checks to prevent overflow, confirming it's a security fix. High confidence due to clear and direct evidence."
}