{
  "cve_id": "CVE-2023-31438",
  "cwe_ids": [
    "CWE-354"
  ],
  "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N",
  "cvss_is_v3": true,
  "repo_name": "systemd",
  "commit_msg": "journalctl: verify sealed log epochs are continuous\n\nCurrently empty epochs are not sealed. This allows an attacker to truncate\na sealed log and continue it without any problems showing when verifying the\nlog.\n\nThis partially addresses CVE-2023-31438. One way to extend this change to\naddress CVE-2023-31438 completely, would be to verify that there is exactly\none seal per epoch (and not sealing when the epoch has not ended yet).\n\nthe change also adds a journal-file flag: HEADER_COMPATIBLE_SEALED_CONTINUOUS\nthis flag indicates that a journal file is sealed continuously and decides whether\nany missing crypto epochs should trigger a warning or an error.",
  "commit_hash": "8d7b0958cdb505047e5a66029468b8d12b8a7add",
  "git_url": "https://github.com/systemd/systemd/commit/8d7b0958cdb505047e5a66029468b8d12b8a7add",
  "file_path": "src/journal/journald-server.c",
  "func_name": "server_archive_offline_user_journals",
  "func_before": "static int server_archive_offline_user_journals(Server *s) {\n        _cleanup_closedir_ DIR *d = NULL;\n        int r;\n\n        assert(s);\n\n        d = opendir(s->system_storage.path);\n        if (!d) {\n                if (errno == ENOENT)\n                        return 0;\n\n                return log_ratelimit_error_errno(errno, JOURNAL_LOG_RATELIMIT,\n                                                 \"Failed to open %s: %m\", s->system_storage.path);\n        }\n\n        for (;;) {\n                _cleanup_free_ char *full = NULL;\n                _cleanup_close_ int fd = -EBADF;\n                struct dirent *de;\n                JournalFile *f;\n                uid_t uid;\n\n                errno = 0;\n                de = readdir_no_dot(d);\n                if (!de) {\n                        if (errno != 0)\n                                log_ratelimit_warning_errno(errno, JOURNAL_LOG_RATELIMIT,\n                                                            \"Failed to enumerate %s, ignoring: %m\",\n                                                            s->system_storage.path);\n                        break;\n                }\n\n                r = journal_file_parse_uid_from_filename(de->d_name, &uid);\n                if (r < 0) {\n                        /* Don't warn if the file is not an online or offline user journal. */\n                        if (r != -EREMOTE)\n                                log_warning_errno(r, \"Failed to parse UID from file name '%s', ignoring: %m\", de->d_name);\n                        continue;\n                }\n\n                /* Already rotated in the above loop? i.e. is it an open user journal? */\n                if (ordered_hashmap_contains(s->user_journals, UID_TO_PTR(uid)))\n                        continue;\n\n                full = path_join(s->system_storage.path, de->d_name);\n                if (!full)\n                        return log_oom();\n\n                fd = openat(dirfd(d), de->d_name, O_RDWR|O_CLOEXEC|O_NOCTTY|O_NOFOLLOW|O_NONBLOCK);\n                if (fd < 0) {\n                        log_ratelimit_full_errno(IN_SET(errno, ELOOP, ENOENT) ? LOG_DEBUG : LOG_WARNING,\n                                                 errno, JOURNAL_LOG_RATELIMIT,\n                                                 \"Failed to open journal file '%s' for rotation: %m\", full);\n                        continue;\n                }\n\n                /* Make some room in the set of deferred close()s */\n                server_vacuum_deferred_closes(s);\n\n                /* Open the file briefly, so that we can archive it */\n                r = journal_file_open(\n                                fd,\n                                full,\n                                O_RDWR,\n                                (s->compress.enabled ? JOURNAL_COMPRESS : 0) |\n                                (s->seal ? JOURNAL_SEAL : 0), /* strict order does not matter here */\n                                0640,\n                                s->compress.threshold_bytes,\n                                &s->system_storage.metrics,\n                                s->mmap,\n                                /* template= */ NULL,\n                                &f);\n                if (r < 0) {\n                        log_ratelimit_warning_errno(r, JOURNAL_LOG_RATELIMIT,\n                                                    \"Failed to read journal file %s for rotation, trying to move it out of the way: %m\",\n                                                    full);\n\n                        r = journal_file_dispose(dirfd(d), de->d_name);\n                        if (r < 0)\n                                log_ratelimit_warning_errno(r, JOURNAL_LOG_RATELIMIT,\n                                                            \"Failed to move %s out of the way, ignoring: %m\",\n                                                            full);\n                        else\n                                log_debug(\"Successfully moved %s out of the way.\", full);\n\n                        continue;\n                }\n\n                TAKE_FD(fd); /* Donated to journal_file_open() */\n\n                r = journal_file_archive(f, NULL);\n                if (r < 0)\n                        log_debug_errno(r, \"Failed to archive journal file '%s', ignoring: %m\", full);\n\n                journal_file_initiate_close(TAKE_PTR(f), s->deferred_closes);\n        }\n\n        return 0;\n}",
  "abstract_func_before": "static int server_archive_offline_user_journals(Server *VAR_0) {\n        _cleanup_closedir_ VAR_1 *VAR_2 = NULL;\n        int VAR_3;\n\n        assert(VAR_0);\n\n        VAR_2 = opendir(VAR_0->system_storage.path);\n        if (!VAR_2) {\n                if (VAR_4 == VAR_5)\n                        return 0;\n\n                return log_ratelimit_error_errno(VAR_4, VAR_6,\n                                                 \"Failed to open %s: %m\", VAR_0->system_storage.path);\n        }\n\n        for (;;) {\n                _cleanup_free_ VAR_7 *VAR_8 = NULL;\n                _cleanup_close_ int VAR_9 = -VAR_10;\n                struct dirent *VAR_11;\n                JournalFile *VAR_12;\n                uid_t VAR_13;\n\n                VAR_4 = 0;\n                VAR_11 = readdir_no_dot(VAR_2);\n                if (!VAR_11) {\n                        if (VAR_4 != 0)\n                                log_ratelimit_warning_errno(VAR_4, VAR_6,\n                                                            \"Failed to enumerate %s, ignoring: %m\",\n                                                            VAR_0->system_storage.path);\n                        break;\n                }\n\n                VAR_3 = journal_file_parse_uid_from_filename(VAR_11->d_name, &VAR_13);\n                if (VAR_3 < 0) {\n                        /* COMMENT_0 */\n                        if (VAR_3 != -VAR_14)\n                                log_warning_errno(VAR_3, \"Failed to parse UID from file name '%s', ignoring: %m\", VAR_11->d_name);\n                        continue;\n                }\n\n                /* COMMENT_1 */\n                if (ordered_hashmap_contains(VAR_0->user_journals, UID_TO_PTR(VAR_13)))\n                        continue;\n\n                VAR_8 = path_join(VAR_0->system_storage.path, VAR_11->d_name);\n                if (!VAR_8)\n                        return log_oom();\n\n                VAR_9 = openat(dirfd(VAR_2), VAR_11->d_name, VAR_15|VAR_16|VAR_17|VAR_18|VAR_19);\n                if (VAR_9 < 0) {\n                        log_ratelimit_full_errno(IN_SET(VAR_4, VAR_20, VAR_5) ? VAR_21 : VAR_22,\n                                                 VAR_4, VAR_6,\n                                                 \"Failed to open journal file '%s' for rotation: %m\", VAR_8);\n                        continue;\n                }\n\n                /* COMMENT_2 */\n                server_vacuum_deferred_closes(VAR_0);\n\n                /* COMMENT_3 */\n                VAR_3 = journal_file_open(\n                                VAR_9,\n                                VAR_8,\n                                VAR_15,\n                                (VAR_0->compress.enabled ? VAR_23 : 0) |\n                                (VAR_0->seal ? VAR_24 : 0), /* COMMENT_4 */\n                                0640,\n                                VAR_0->compress.threshold_bytes,\n                                &VAR_0->system_storage.metrics,\n                                VAR_0->mmap,\n                                /* COMMENT_5 */ NULL,\n                                &VAR_12);\n                if (VAR_3 < 0) {\n                        log_ratelimit_warning_errno(VAR_3, VAR_6,\n                                                    \"Failed to read journal file %s for rotation, trying to move it out of the way: %m\",\n                                                    VAR_8);\n\n                        VAR_3 = journal_file_dispose(dirfd(VAR_2), VAR_11->d_name);\n                        if (VAR_3 < 0)\n                                log_ratelimit_warning_errno(VAR_3, VAR_6,\n                                                            \"Failed to move %s out of the way, ignoring: %m\",\n                                                            VAR_8);\n                        else\n                                log_debug(\"Successfully moved %s out of the way.\", VAR_8);\n\n                        continue;\n                }\n\n                TAKE_FD(VAR_9); /* COMMENT_6 */\n\n                VAR_3 = journal_file_archive(VAR_12, NULL);\n                if (VAR_3 < 0)\n                        log_debug_errno(VAR_3, \"Failed to archive journal file '%s', ignoring: %m\", VAR_8);\n\n                journal_file_initiate_close(TAKE_PTR(VAR_12), VAR_0->deferred_closes);\n        }\n\n        return 0;\n}",
  "func_graph_path_before": "systemd/8d7b0958cdb505047e5a66029468b8d12b8a7add/journald-server.c/vul/before/0.json",
  "func": "static int server_archive_offline_user_journals(Server *s) {\n        _cleanup_closedir_ DIR *d = NULL;\n        int r;\n\n        assert(s);\n\n        d = opendir(s->system_storage.path);\n        if (!d) {\n                if (errno == ENOENT)\n                        return 0;\n\n                return log_ratelimit_error_errno(errno, JOURNAL_LOG_RATELIMIT,\n                                                 \"Failed to open %s: %m\", s->system_storage.path);\n        }\n\n        for (;;) {\n                _cleanup_free_ char *full = NULL;\n                _cleanup_close_ int fd = -EBADF;\n                struct dirent *de;\n                JournalFile *f;\n                uid_t uid;\n\n                errno = 0;\n                de = readdir_no_dot(d);\n                if (!de) {\n                        if (errno != 0)\n                                log_ratelimit_warning_errno(errno, JOURNAL_LOG_RATELIMIT,\n                                                            \"Failed to enumerate %s, ignoring: %m\",\n                                                            s->system_storage.path);\n                        break;\n                }\n\n                r = journal_file_parse_uid_from_filename(de->d_name, &uid);\n                if (r < 0) {\n                        /* Don't warn if the file is not an online or offline user journal. */\n                        if (r != -EREMOTE)\n                                log_warning_errno(r, \"Failed to parse UID from file name '%s', ignoring: %m\", de->d_name);\n                        continue;\n                }\n\n                /* Already rotated in the above loop? i.e. is it an open user journal? */\n                if (ordered_hashmap_contains(s->user_journals, UID_TO_PTR(uid)))\n                        continue;\n\n                full = path_join(s->system_storage.path, de->d_name);\n                if (!full)\n                        return log_oom();\n\n                fd = openat(dirfd(d), de->d_name, O_RDWR|O_CLOEXEC|O_NOCTTY|O_NOFOLLOW|O_NONBLOCK);\n                if (fd < 0) {\n                        log_ratelimit_full_errno(IN_SET(errno, ELOOP, ENOENT) ? LOG_DEBUG : LOG_WARNING,\n                                                 errno, JOURNAL_LOG_RATELIMIT,\n                                                 \"Failed to open journal file '%s' for rotation: %m\", full);\n                        continue;\n                }\n\n                /* Make some room in the set of deferred close()s */\n                server_vacuum_deferred_closes(s);\n\n                /* Open the file briefly, so that we can archive it */\n                r = journal_file_open(\n                                fd,\n                                full,\n                                O_RDWR,\n                                (s->compress.enabled ? JOURNAL_COMPRESS : 0) |\n                                (s->seal ? JOURNAL_SEAL : 0), /* strict order does not matter here */\n                                0640,\n                                s->compress.threshold_bytes,\n                                &s->system_storage.metrics,\n                                s->mmap,\n                                /* template= */ NULL,\n                                &f);\n                if (r < 0) {\n                        log_ratelimit_warning_errno(r, JOURNAL_LOG_RATELIMIT,\n                                                    \"Failed to read journal file %s for rotation, trying to move it out of the way: %m\",\n                                                    full);\n\n                        r = journal_file_dispose(dirfd(d), de->d_name);\n                        if (r < 0)\n                                log_ratelimit_warning_errno(r, JOURNAL_LOG_RATELIMIT,\n                                                            \"Failed to move %s out of the way, ignoring: %m\",\n                                                            full);\n                        else\n                                log_debug(\"Successfully moved %s out of the way.\", full);\n\n                        continue;\n                }\n\n                TAKE_FD(fd); /* Donated to journal_file_open() */\n\n                journal_file_write_final_tag(f);\n                r = journal_file_archive(f, NULL);\n                if (r < 0)\n                        log_debug_errno(r, \"Failed to archive journal file '%s', ignoring: %m\", full);\n\n                journal_file_initiate_close(TAKE_PTR(f), s->deferred_closes);\n        }\n\n        return 0;\n}",
  "abstract_func": "static int server_archive_offline_user_journals(Server *VAR_0) {\n        _cleanup_closedir_ VAR_1 *VAR_2 = NULL;\n        int VAR_3;\n\n        assert(VAR_0);\n\n        VAR_2 = opendir(VAR_0->system_storage.path);\n        if (!VAR_2) {\n                if (VAR_4 == VAR_5)\n                        return 0;\n\n                return log_ratelimit_error_errno(VAR_4, VAR_6,\n                                                 \"Failed to open %s: %m\", VAR_0->system_storage.path);\n        }\n\n        for (;;) {\n                _cleanup_free_ VAR_7 *VAR_8 = NULL;\n                _cleanup_close_ int VAR_9 = -VAR_10;\n                struct dirent *VAR_11;\n                JournalFile *VAR_12;\n                uid_t VAR_13;\n\n                VAR_4 = 0;\n                VAR_11 = readdir_no_dot(VAR_2);\n                if (!VAR_11) {\n                        if (VAR_4 != 0)\n                                log_ratelimit_warning_errno(VAR_4, VAR_6,\n                                                            \"Failed to enumerate %s, ignoring: %m\",\n                                                            VAR_0->system_storage.path);\n                        break;\n                }\n\n                VAR_3 = journal_file_parse_uid_from_filename(VAR_11->d_name, &VAR_13);\n                if (VAR_3 < 0) {\n                        /* COMMENT_0 */\n                        if (VAR_3 != -VAR_14)\n                                log_warning_errno(VAR_3, \"Failed to parse UID from file name '%s', ignoring: %m\", VAR_11->d_name);\n                        continue;\n                }\n\n                /* COMMENT_1 */\n                if (ordered_hashmap_contains(VAR_0->user_journals, UID_TO_PTR(VAR_13)))\n                        continue;\n\n                VAR_8 = path_join(VAR_0->system_storage.path, VAR_11->d_name);\n                if (!VAR_8)\n                        return log_oom();\n\n                VAR_9 = openat(dirfd(VAR_2), VAR_11->d_name, VAR_15|VAR_16|VAR_17|VAR_18|VAR_19);\n                if (VAR_9 < 0) {\n                        log_ratelimit_full_errno(IN_SET(VAR_4, VAR_20, VAR_5) ? VAR_21 : VAR_22,\n                                                 VAR_4, VAR_6,\n                                                 \"Failed to open journal file '%s' for rotation: %m\", VAR_8);\n                        continue;\n                }\n\n                /* COMMENT_2 */\n                server_vacuum_deferred_closes(VAR_0);\n\n                /* COMMENT_3 */\n                VAR_3 = journal_file_open(\n                                VAR_9,\n                                VAR_8,\n                                VAR_15,\n                                (VAR_0->compress.enabled ? VAR_23 : 0) |\n                                (VAR_0->seal ? VAR_24 : 0), /* COMMENT_4 */\n                                0640,\n                                VAR_0->compress.threshold_bytes,\n                                &VAR_0->system_storage.metrics,\n                                VAR_0->mmap,\n                                /* COMMENT_5 */ NULL,\n                                &VAR_12);\n                if (VAR_3 < 0) {\n                        log_ratelimit_warning_errno(VAR_3, VAR_6,\n                                                    \"Failed to read journal file %s for rotation, trying to move it out of the way: %m\",\n                                                    VAR_8);\n\n                        VAR_3 = journal_file_dispose(dirfd(VAR_2), VAR_11->d_name);\n                        if (VAR_3 < 0)\n                                log_ratelimit_warning_errno(VAR_3, VAR_6,\n                                                            \"Failed to move %s out of the way, ignoring: %m\",\n                                                            VAR_8);\n                        else\n                                log_debug(\"Successfully moved %s out of the way.\", VAR_8);\n\n                        continue;\n                }\n\n                TAKE_FD(VAR_9); /* COMMENT_6 */\n\n                journal_file_write_final_tag(VAR_12);\n                VAR_3 = journal_file_archive(VAR_12, NULL);\n                if (VAR_3 < 0)\n                        log_debug_errno(VAR_3, \"Failed to archive journal file '%s', ignoring: %m\", VAR_8);\n\n                journal_file_initiate_close(TAKE_PTR(VAR_12), VAR_0->deferred_closes);\n        }\n\n        return 0;\n}",
  "func_graph_path": "systemd/8d7b0958cdb505047e5a66029468b8d12b8a7add/journald-server.c/vul/after/0.json",
  "diff_func": "--- func_before\n+++ func_after\n@@ -88,6 +88,7 @@\n \n                 TAKE_FD(fd); /* Donated to journal_file_open() */\n \n+                journal_file_write_final_tag(f);\n                 r = journal_file_archive(f, NULL);\n                 if (r < 0)\n                         log_debug_errno(r, \"Failed to archive journal file '%s', ignoring: %m\", full);",
  "diff_line_info": {
    "deleted_lines": [],
    "added_lines": [
      "                journal_file_write_final_tag(f);"
    ]
  },
  "is_vul": true,
  "pr_url": "https://github.com/systemd/systemd/pull/28886",
  "description": {
    "pr_info": {
      "title": "journalctl: verify sealed log epochs are continuous",
      "number": 28886
    },
    "comment": [
      "Currently empty epochs are not sealed. This allows an attacker to truncate a sealed log and continue it without any problems showing when verifying the log.\r\n\r\nThis partially addresses CVE-2023-31438. One way to extend this change to address CVE-2023-31438 completely, would be to verify that there is exactly one seal per epoch (and not sealing when the epoch has not ended yet). I didn't remove the premature sealing, as it is implemented purposefully although I don't understand the purpose.\r\nSee https://github.com/kastel-security/Journald/blob/main/journald-publication.pdf for more background.\r\n\r\nThis change adjusts what journald writes into a log file but is compatible in the sense that old `journalctl` versions will successfully verify new journals, but the new `journalctl --verify` will refuse to accept a journal created with old journald if there are gaps in the sealed epochs.\r\n\r\nSee also #28433\n\n<!-- devel-freezer = {\"comment-id\":\"1801865051\",\"freezing-tag\":\"v255-rc1\"} -->",
      "looks good, but i am a bit concerned about the compat with this, see comment above",
      "Good idea. I added a draft version of a `SEALED_CONTINOUS`-flag to change the error message to a warning. Thinking more closely about it: We cannot guarantee completeness for old journal files regardless of whether the epochs are continuous or not, due to the fact that journald seals an epoch prematurely when closed. Because that allows an attacker to drop the second seal, when the epoch actually ended, and claim the premature seal is the only correct one.\r\n\r\nSo I think we should drop premature sealing and then this should be the behavior:\r\nWhen not `SEALED_CONTINOUS` we should issue a warning, that we cannot guarantee consistency, unconditionally. (And for the rest of the verification, fall back to verifying the more loose constraint).\r\n\r\nWould you be fine with dropping premature sealing, that is this block:\r\nhttps://github.com/systemd/systemd/blob/1ffa5cfb38b3d30d269259c531300fc629816ea9/src/journal/managed-journal-file.c#L395\r\nor can you tell my why it is needed?",
      "I've gone ahead and removed the premature sealing. The only remaining gap is now between rotated journal files.",
      "Please rebase and squash commits.",
      "So @yuwata you do not want to do a final review and merge this, but we let it sit again until someone else picks it up?",
      "lgtm. just some minor things.",
      "An -rc1 tag has been created and a release is being prepared, so please note that PRs introducing new features and APIs will be held back until the new version has been released.\n"
    ]
  },
  "Bug Filter": "Security Vulnerability Fix",
  "Bug Filter Confidence": 0.95,
  "Bug Filter Response": "**Final Classification:** Security Vulnerability Fix  \n**Confidence:** 0.95"
}